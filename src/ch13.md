## 演習 13.1

![](https://i.imgur.com/OVMrByu.png)
![](https://i.imgur.com/Gq9roJ7.png)

8.2節で議論した有向分離のテクニックを使って図13.3に示す全部で$N$個のノードをもつマルコフモデルが、$n=2, \ldots, N$について条件付き独立性

$$
p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right)=p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}\right) \tag{13.3}
$$

を満たすことを示せ．同様に、図13.4のグラフで記述される全部で$N$個のノードをもつモデルが、$n=3,\ldots,N$について以下の条件付き独立性を満たすことを示せ．

$$
p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right)=p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}, \mathbf{x}_{n-2}\right) \tag{13.122}
$$

----

.![](https://i.imgur.com/G2ZfBBt.png)

※8.2.2 有向分離の節で用いられた手法で考える。図のように$A, B, C$の部分集合を指定する。$A$に属する任意のノードから$B$に属するノードへの可能な経路は必ず$C$を通ることになる。
今、$C$は観測されており、head-to-tailとなっているので、P.91の議論から$A$から$B$への経路は$C$で遮断されており、$A \perp \!\!\! \perp B \mid C$が成立する。これより

$$
\begin{aligned}
p(A,B\mid C) &= p(A\mid C)p(B\mid C) \\
\end{aligned}
$$

が成立する。両辺に$p(C)$をかけると

$$
\begin{aligned}
p(A,B, C) &= p(A,C)p(B\mid C) \\
\end{aligned}
$$

となる。

問題は今$p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right) = p(B\mid A, C)$なので

$$
\begin{aligned}
p(B\mid A, C) &= \frac{p(A, B, C)}{p(A,C)} \\
&=p(B\mid C)
\end{aligned}
$$

これを書き直すと

$$
p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right)=p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}\right) \tag{13.3}
$$

が得られる。

![](https://i.imgur.com/BPSwm9c.png)

二次マルコフ連鎖の場合、$n=3$について$(13.122)$式は自明に成立する。
$n=4,\ldots,N$の二次マルコフ連鎖の場合は上の図のようになる。このとき、同様に$A$から$B$への経路は$C$に含まれるすべてのノードで遮断されている。つまり$A \perp \!\!\! \perp B \mid C$が成立する。これより


$$
\begin{aligned}
p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right) &= p(B\mid A, C) \\
&= \frac{p(A, B, C)}{p(A,C)} \\
&=p(B\mid C) \\
&=p(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}, \mathbf{x}_{n-2})
\end{aligned}
$$

よって$(13.122)$式が導かれた。

## 演習 13.2

図13.3の有向グラフに対応する同時確率分布

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}\right)=p\left(\mathbf{x}_{1}\right) \prod_{n=2}^{N} p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}\right) \tag{13.2}
$$

について考えよう。確率の加法・乗法定理を用い、この同時確率が$n=2, \ldots, N$について条件付き独立性

$$
p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right)=p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}\right) \tag{13.3}
$$

を満たすことを示せ。同様に、同時分布

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}\right)=p\left(\mathbf{x}_{1}\right) p\left(\mathbf{x}_{2} \mid \mathbf{x}_{1}\right) \prod_{n=3}^{N} p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}, \mathbf{x}_{n-2}\right) \tag{13.4}
$$

によって記述される二次マルコフモデルが、$n=3,\ldots,N$について以下の条件付き独立性を満たすことを示せ。

$$
p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right)=p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}, \mathbf{x}_{n-2}\right) \tag{13.123}
$$

----

$(13.3)$の左辺を展開し、$\mathbf{x}_{n}$で周辺化しておく。

$$
\begin{aligned}
p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right) &= \frac{p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right)}{p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right)} \\
&= \frac{p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right)}{\sum_{\mathbf{x}_{n}} p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right)}
\end{aligned}
$$

そこで、$(13.2)$式を利用して$p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right)$を求める。

$$
\begin{aligned} p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right) &=\sum_{\mathbf{x}_{n+1}} \cdots \sum_{\mathbf{x}_{N}} p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}\right) \\ &=\sum_{\mathbf{x}_{n+1}} \cdots \sum_{\mathbf{x}_{N}} p\left(\mathbf{x}_{1}\right) \prod_{m=2}^{N} p\left(\mathbf{x}_{m} \mid \mathbf{x}_{m-1}\right) \\ &=p\left(\mathbf{x}_{1}\right) \prod_{m=2}^{n} p\left(\mathbf{x}_{m} \mid \mathbf{x}_{m-1}\right) \end{aligned}
$$

と書けるので、もう一度$p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right)$を計算すると

$$
\begin{aligned}
p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right) &= \frac{p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right)}{\sum_{\mathbf{x}_{n}} p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right)} \\
&= \frac{p\left(\mathbf{x}_{1}\right) \prod_{m=2}^{n} p\left(\mathbf{x}_{m} \mid \mathbf{x}_{m-1}\right)}{\sum_{\mathbf{x}_{n}} p\left(\mathbf{x}_{1}\right) \prod_{m=2}^{n} p\left(\mathbf{x}_{m} \mid \mathbf{x}_{m-1}\right)} \\
&= \frac{p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}\right)}{\sum_{\mathbf{x}_{n}} p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}\right)} \\
&= p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}\right)
\end{aligned}
$$

途中で$\mathbf{x}_{n}$に依存する項以外が分母分子でキャンセルされることを用いた。これより、$(13.3)$の右辺が得られた。

二次マルコフモデルについても同様に行うと、$(13.4)$の同時分布からはじめて

$$
\begin{aligned} p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right) &=\sum_{\mathbf{x}_{n+1}} \cdots \sum_{\mathbf{x}_{N}} p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}\right) \\ &=\sum_{\mathbf{x}_{n+1}} \cdots \sum_{\mathbf{x}_{N}} p\left(\mathbf{x}_{1}\right) p\left(\mathbf{x}_{2} \mid \mathbf{x}_{1}\right) \prod_{m=3}^{N} p\left(\mathbf{x}_{m} \mid \mathbf{x}_{m-1}, \mathbf{x}_{m-2}\right) \\ &=p\left(\mathbf{x}_{1}\right) p\left(\mathbf{x}_{2} \mid \mathbf{x}_{1}\right) \prod_{m=3}^{n} p\left(\mathbf{x}_{m} \mid \mathbf{x}_{m-1}, \mathbf{x}_{m-2}\right) \end{aligned}
$$

となるので、

$$
\begin{aligned} p\left(\mathbf{x}_{n} \mid \mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\right) &=\frac{p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right)}{\sum_{\mathbf{x}_{n}} p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right)} \\ &=\frac{p\left(\mathbf{x}_{1}\right) p\left(\mathbf{x}_{2} \mid \mathbf{x}_{1}\right) \prod_{m=3}^{n} p\left(\mathbf{x}_{m} \mid \mathbf{x}_{m-1}, \mathbf{x}_{m-2}\right)}{\sum_{\mathbf{x}_{n}} p\left(\mathbf{x}_{1}\right) p\left(\mathbf{x}_{2} \mid \mathbf{x}_{1}\right) \prod_{m=3}^{n} p\left(\mathbf{x}_{m} \mid \mathbf{x}_{m-1}, \mathbf{x}_{m-2}\right)} \\
&= \frac{p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}, \mathbf{x}_{n-2}\right)}{\sum_{\mathbf{x}_{n}} p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}, \mathbf{x}_{n-2}\right)} \\
&= p\left(\mathbf{x}_{n} \mid \mathbf{x}_{n-1}, \mathbf{x}_{n-2}\right)
\end{aligned}
$$

を得る。

## 演習 13.3

![](https://i.imgur.com/GRbf8ob.png)
有向分離を用いて、図13.5の有向グラフで表現される状態空間モデルにおける観測データの分布$p(\mathbf{x}_1,\ldots,\mathbf{x}_N )$が何の条件付き独立性も満足せず、したがって、どのような有限次数のマルコフ性ももたないことを示せ.

----

図13.5によると、任意の2つの変数$\mathbf{x}_n$と$\mathbf{x}_m$, $m \neq n$について、それぞれのノード間には直接的な経路は存在せず、$\mathbf{z}$変数に対応する1つ以上のノードを通過する経路が存在している。これらのノードはいずれも観測データの分布$p(\mathbf{x}_1,\ldots,\mathbf{x}_N )$の条件集合に含まれていない。したがって、$\mathbf{x}_n$と$\mathbf{x}_m$の間には遮断されていない経路が存在し、モデルは条件付き独立性または有限次マルコフ性を満たさないことになる。

## 演習 13.4

線形回帰モデルやニューラルネットワークのように、出力密度がパラメトリックなモデル$p(\mathbf{x}\mid \mathbf{z},\mathbf{w})$で表される隠れマルコフモデルを考えよう。ここで、$\mathbf{w}$は適応パラメータのベクトルである。データから最尤推定によってパラメータ$\mathbf{w}$を学習する方法を述べよ.

----

教科書p.330に記載されている、「隠れマルコフモデルとして離散分布、ガウス分布、混合ガウス分布といった広い範囲の出力分布に加えて、ニューラルネットワークなどの識別的モデルを利用することも可能」という記述への補足のための演習問題。

教科書では、出力分布$p(\mathbf{x}_n|\phi_k)$としてガウス分布（p.335）や離散多項分布（p.336）の例が記載されている。このパラメータ$\phi$を$\mathbf{w}$で置き換えると、識別的モデルにおいても同様の定式化が可能。

実際の更新式の形は、回帰モデルの形や、回帰モデルがどのように使われているかに依って異なる。一例としては、図13.8（p.351）では$\mathbf{x}$の生成密度が、隠れ変数$\mathbf{z}$だけでなく観測変数系列$\mathbf{u}$に依存する。
この場合、回帰モデルは$\mathbf{u}$から$\mathbf{x}$への写像（写像の関数形が$\mathbf{z}$に応じて異なる）とみなすことができる。
ニューラルネットワークのような非線形な関数形では、Mステップにおける$\mathbf{w}$の最適解が解析的に解けないことが多い。


## 演習 13.5

隠れマルコフモデルの初期状態確率と遷移確率のパラメータについてのMステップの方程式

$$
\pi_{k}=\frac{\gamma\left(z_{1 k}\right)}{\sum_{j=1}^{K} \gamma\left(z_{1 j}\right)} \tag{13.18}
$$

$$
A_{j k}=\frac{\sum_{n=2}^{N} \xi\left(z_{n-1, j}, z_{n k}\right)}{\sum_{l=1}^{K} \sum_{n=2}^{N} \xi\left(z_{n-1, j}, z_{n l}\right)} \tag{13.19}
$$

を、完全データに対する対数尤度関数の期待値

$$
\begin{aligned} Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text {old }}\right)=& \sum_{k=1}^{K} \gamma\left(z_{1 k}\right) \ln \pi_{k}+\sum_{n=2}^{N} \sum_{j=1}^{K} \sum_{k=1}^{K} \xi\left(z_{n-1, j}, z_{n k}\right) \ln A_{j k} \\ &+\sum_{n=1}^{N} \sum_{k=1}^{K} \gamma\left(z_{n k}\right) \ln p\left(\mathbf{x}_{n} \mid \phi_{k}\right) \end{aligned} \tag{13.17}
$$

を最大化することにより確かめよ。その際、適当なラグランジュ乗数を用いて$\boldsymbol{\pi}$と$\mathbf{A}$の成分に対する和の制約を与えること.

----

P.334~335参照。Mステップの更新式に相当する。

$\displaystyle \sum_{l=1}^{K} \pi_{l}=1$の条件下で$Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text {old }}\right)$を$\pi_{l}$について最大化する。

$$
\begin{aligned}
&\frac{\partial}{\partial \pi_{k}}\left[Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text {old }}\right)-\lambda\left(\sum_{l=1}^{K} \pi_{l}-1\right)\right] \\
=&\ \gamma\left(z_{1 k}\right) \cdot \frac{1}{\pi_{k}}-\lambda(=0)
\end{aligned}
$$

両辺に$\pi_{k}$を乗じて、$k$について和をとって整理すると、

$$
\sum_{k=1}^{K}\gamma(z_{1k}) = \lambda \underbrace{\sum_{k=1}^{K}\pi_{k}}_{=1}
$$

よって、$\displaystyle \lambda = \sum_{k=1}^{K}\gamma(z_{1k})$。これを代入して

$$
\pi_{k}=\frac{1}{\lambda} \gamma\left(z_{1 k}\right)=\frac{\gamma\left(z_{1 k}\right)}{\sum_{j=1}^{K} \gamma\left(z_{1 j}\right)} \tag{13.18}
$$

次に、$\displaystyle \sum_{k=1}^{K}A_{jk} = 1$の条件下で$Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text {old }}\right)$を$A_{jk}$について最大化する。

$$
\begin{aligned}
&\frac{\partial}{\partial A_{j k}}\left[Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text {old }}\right)-\sum_{l} \mu_{l}\left(\sum_{m} A_{j m}-1\right)\right] \\
=&\ \sum_{n=2}^{N} \sum_{l} \sum_{m} \xi\left(z_{n-1, l}, z_{n m}\right) \cdot \frac{1}{A_{lm}} \cdot \delta_{j l} \delta_{k m} - \mu_{l}\delta_{jl} \\
=&\ \sum_{n=2}^{N} \xi\left(\varepsilon_{n-1, j}, z_{n k}\right) \cdot \frac{1}{A_{j k}}-\mu_{j}(=0)
\end{aligned}
$$

両辺に$A_{jk}$を乗じて$k$について和をとって整理すると

$$
\sum_{k=1}^{K} \sum_{n=2}^{N} \xi\left(z_{n-1, j}, z_{n k}\right)=\mu_{j} \underbrace{\sum_{k}A_{jk}}_{=1}
$$

求めた$\mu_{j}$を代入して

$$
A_{j k} =\frac{1}{\mu_{j}} \sum_{n=2}^{N} \xi\left(z_{n-1, j}, z_{n k}\right) = \frac{\sum_{n=2}^{N} \xi\left(z_{n-1, j}, z_{n k}\right)}{\sum_{l=1}^{K} \sum_{n=2}^{N} \xi\left(z_{n-1, j}, z_{n l}\right)} \tag{13.19}
$$

を得る。

## 演習 13.6

もし、隠れマルコフモデルのパラメータ$\boldsymbol{\pi}$か$\mathbf{A}$のいずれかの要素が最初に0に設定された場合、それらの要素素はEMアルゴリズムのその後に続く更新において0のままであることを示せ。

----

まずパラメータ$\mathbf{\pi}$について考える．
$\mathbf{\pi}$の特定の要素$\pi_k$が0に初期化されているとする.最初のEステップでは, $\alpha(z_{1k})$は (13.37)から以下のようにかける.

$$
\mathbf{\alpha}(z_{1k})=\pi_k p(\mathbf{x}_1\mid\phi_k)\tag{13.37}
$$

$\pi_k$が0に初期化されているためこの値は0であることがわかる.また(13.33)から,

$$
\gamma(z_{1k})=\frac{\alpha(z_{1k})\beta(z_{1k})}{p(\mathbf{x})}\tag{13.33}
$$

$\gamma(z_{1k})$も0になる．また次のMステップで

$$
\pi_{k}=\frac{\gamma\left(z_{1 k}\right)}{\sum_{j=1}^{K} \gamma\left(z_{1 j}\right)}\tag
{13.18}
$$

により更新される$\pi_k$の値は再び0となることがわかる。これはその後のEM step に当てはまるので、この$\pi_k$の値は0のままである.

次に$\mathbf{A}$の要素$A_{jk}$が0で初期化されているとする。

$$
\begin{aligned}
\xi &\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)=p\left(\mathbf{z}_{n-1}, \mathbf{z}_{n} \mid \mathbf{X}\right) \\
&=\frac{\left.\alpha\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \beta\left(\mathbf{z}_{n}\right)\right)}{p(\mathbf{X})} .
\end{aligned}
$$

(13.43)の式中で、遷移行列部分の$p(z_{nk}\mid z_{n-1,j})=A_{jk}$が0であり、$\xi \left(\mathbf{z}_{n-1,k}, \mathbf{z}_{nj}\right)$が0になることがわかる。続くMステップでは、$A_{jk}$の新しい値は

$$
A_{j k}=\frac{\sum_{n=2}^{N} \xi\left(z_{n-1, j}, z_{n k}\right)}{\sum_{l=1}^{K} \sum_{n=2}^{N} \xi\left(z_{n-1, j}, z_{n l}\right)}
$$

で与えられ、これも0になりことがわかる．以上により示された．


## 演習 13.7

ガウス出力密度をもつ隠れマルコフモデルを考える。ガウス分布の平均と共分散のパラメータについての関数$Q(\boldsymbol{\theta},\boldsymbol{\theta}^{\mathrm{old}})$の最大化が、Mステップの方程式

$$
\boldsymbol{\mu}_{k}=\frac{\sum_{n=1}^{N} \gamma\left(z_{n k}\right) \mathbf{x}_{n}}{\sum_{n=1}^{N} \gamma\left(z_{n k}\right)} \tag{13.20}
$$

と

$$
\mathbf{\Sigma}_{k}=\frac{\sum_{n=1}^{N} \gamma\left(z_{n k}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}}}{\sum_{n=1}^{N} \gamma\left(z_{n k}\right)} \tag{13.21}
$$

を導くことを示せ。

----

P.335の後半を参照。$Q(\boldsymbol{\theta},\boldsymbol{\theta}^{\mathrm{old}})$を$\boldsymbol{\phi}_{k}$に関して最大化する場合、$(13.17)$の最後の項だけが$\boldsymbol{\phi}_{k}$に依存している。パラメータ$\boldsymbol{\phi}_{k}$が成分ごとに独立ならば、この項は$k$の各々の値ごとの項の和に分解され、そのそれぞれの項は独立に最大化することができる。出力分布がガウス密度分布の場合には$p\left(\mathbf{x} \mid \boldsymbol{\phi}_{k}\right)=\mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right)$と書けて、「$\boldsymbol{\phi}_{k}$に関しての最大化」をガウス分布の平均$\boldsymbol{\mu}_{k}$と分散$\mathbf{\Sigma}_{k}$についての最大化に分けて考える。

$$
\begin{aligned}
& \sum_{n=1}^{N} \sum_{k=1}^{K} \gamma\left(z_{n k}\right) \ln p\left(\mathbf{x}_{n} \mid \phi_{k}\right)=\sum_{n=1}^{N} \sum_{k=1}^{K} \gamma\left(z_{n k}\right) \ln \mathcal{N}\left(\mathbf{x}_{n} \mid \boldsymbol{\mu}_{k}, \mathbf{\Sigma}_{k}\right) \\
=& \sum_{n=1}^{N} \sum_{k=1}^{K} \gamma\left(z_{n k}\right)\left\{-\frac{D}{2} \ln (2 \pi)-\frac{1}{2} \ln \left|\mathbf{\Sigma}_{k}\right|-\frac{1}{2}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}} \mathbf{\Sigma}_{k}^{-1}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right\}
\end{aligned}
$$

(1) $\boldsymbol{\mu}_{k}$について最大化する。

$$
\begin{aligned}
\frac{\partial}{\partial \boldsymbol{\mu}_{k}} Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text {old }}\right) &=\frac{\partial}{\partial \boldsymbol{\mu}_{k}}\left\{\sum_{n=1}^{N} \sum_{k=1}^{K} \gamma\left(z_{n k}\right) \cdot\left(-\frac{1}{2}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}} \mathbf{\Sigma}_{k}^{-1}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right)\right\} \\
&=\sum_{n=1}^{N} \gamma\left(z_{n k}\right) \mathbf{\Sigma}_{k}^{-1}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)=0
\end{aligned}
$$

$$
\sum_{n=1}^{N} \gamma\left(z_{n k}\right) \mathbf{\Sigma}_{k}^{-1} \boldsymbol{\mu}_{k} = \sum_{n=1}^{N} \gamma\left(z_{n k}\right) \mathbf{\Sigma}_{k}^{-1} \mathbf{x}_{n}
$$

両辺に$\mathbf{\Sigma}_{k}$を乗じて整理すると

$$
\boldsymbol{\mu}_{k}=\frac{\sum_{n=1}^{N} \gamma\left(z_{n k}\right) \mathbf{x}_{n}}{\sum_{n=1}^{N} \gamma\left(z_{n k}\right)} \tag{13.20}
$$

を得る。

(2) $\mathbf{\Sigma}_{k}$について最大化する。

$$
\begin{aligned}
\frac{\partial}{\partial \mathbf{\Sigma}_{k}} Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text {old }}\right) &=\frac{\partial}{\partial \mathbf{\Sigma}_{k}} \sum_{n=1}^{N} \sum_{k=1}^{K} \gamma\left(z_{n k}\right)\left\{-\frac{1}{2} \ln \left|\mathbf{\Sigma}_{k}\right|-\frac{1}{2}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}} \mathbf{\Sigma}_{k}^{-1}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right\} \\
&=\sum_{n=1}^{N} \gamma\left(z_{n k}\right)\left\{-\frac{1}{2}\left(\mathbf{\Sigma}_{k}^{-1}\right)^{\mathrm{T}}-\frac{1}{2} \frac{\partial}{\partial \mathbf{\Sigma}_{k}} \operatorname{Tr}\left(\mathbf{\Sigma}_{k}^{-1}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}}\right)\right\} \\
&=-\frac{1}{2} \sum_{n=1}^{N} \gamma\left(z_{n k}\right)\left\{\mathbf{\Sigma}_{k}^{-1}-\mathbf{\Sigma}_{k}^{-1}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}} \mathbf{\Sigma}_{k}^{-1}\right\}=0 \end{aligned}
$$

上式について左と右から1回ずつ$\mathbf{\Sigma}_{k}$を乗じて整理すると、

$$
\sum_{n=1}^{N} \gamma\left(z_{n k}\right)\mathbf{\Sigma}_{k} = \sum_{n=1}^{N} \gamma\left(z_{n k}\right)\mathbf{\Sigma}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}}
$$

$$
\mathbf{\Sigma}_{k} = \frac{\sum_{n=1}^{N} \gamma\left(z_{n k}\right)\mathbf{\Sigma}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}}}{\sum_{n=1}^{N} \gamma\left(z_{n k}\right)} \tag{13.21}
$$

を得る。

## 演習 13.8

多項分布に従う離散観測値をもつ隠れマルコフモデルにおいて、隠れ変数を与えたときの観測値の条件付き分布が

$$
p(\mathbf{x} \mid \mathbf{z})=\prod_{i=1}^{D} \prod_{k=1}^{K} \mu_{i k}^{x_{i} z_{k}} \tag{13.22}
$$

で与えられ、また対応するMステップの方程式が

$$
\mu_{i k}=\frac{\sum_{n=1}^{N} \gamma\left(z_{n k}\right) x_{n i}}{\sum_{n=1}^{N} \gamma\left(z_{n k}\right)} \tag{13.23}
$$

で与えられることを示せ。同様に、複数の二値の出力変数をもち、そのそれぞれがベルヌーイ条件付き分布に従う隠れマルコフモデルについて、条件付き分布についての式とMステップの方程式を書き下せ。
ヒント：必要に応じて、2.1節と2.2節における、独立同分布に従うデータに対する最尤推定の解法についての、対応する議論を参照せよ。

----

  (13.17)  の $Q\left(\theta, \theta^{\text {old }}\right)$ のうち、$\mu$ に依存しているのは最終項のみなので、最終項のみを考える.

$$
\sum_{n=1}^{N} \sum_{k=1}^{K} \gamma\left(z_{n k}\right) \ln p\left(\mathbf{x}_{n} \mid \phi_{k}\right)=\sum_{n=1}^{N} \sum_{k=1}^{K} \gamma\left(z_{n k}\right) \sum_{i=1}^{D} x_{n i} \ln \mu_{k i}
$$

ラグランジュの未定乗数法を用いると、最大化すべき関数は、

$$
\sum_{n=1}^{N} \sum_{k=1}^{K} \gamma\left(z_{n k}\right) \sum_{i=1}^{D} x_{n i} \ln \mu_{k i}+\sum_{k=1}^{K} \lambda_{k}\left(\sum_{i=1}^{D} \mu_{k i}-1\right)
$$

$\mu$に関して微分して、

$$
0=\sum_{n=1}^{N} \gamma\left(z_{n k}\right) \frac{x_{n i}}{\mu_{k i}}+\lambda_{k}
$$

$\mu_{k i}$を両辺にかけて, $i$で和を取って, $\sum_{i} x_{n i}=1$と$\sum_{i} \mu_{n i}=1$ を利用して

$$
\lambda_{k}=-\sum_{n=1}^{N} \gamma\left(z_{n k}\right)
$$

$\lambda_{k}$を

$$
0=\sum_{n=1}^{N} \gamma\left(z_{n k}\right) \frac{x_{n i}}{\mu_{k i}}+\lambda_{k}
$$

に代入して、整理すると、

$$
\mu_{i k}=\frac{\sum_{n=1}^{N} \gamma\left(z_{n k}\right) x_{n i}}{\sum_{n=1}^{N} \gamma\left(z_{n k}\right)} \tag{13.23}
$$

を得る.

## 演習 13.9

隠れマルコフモデルの

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}, \mathbf{z}_{1}, \ldots, \mathbf{z}_{N}\right)=p\left(\mathbf{z}_{1}\right)\left[\prod_{n=2}^{N} p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)\right] \prod_{n=1}^{N} p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) \tag{13.6}
$$

で定義される同時分布が条件付き独立性$(13.24)-(13.31)$

$$
\begin{aligned}
p\left(\mathbf{X} \mid \mathbf{z}_{n}\right) =\ &p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n} \mid \mathbf{z}_{n}\right) \times \\
&p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n}\right)
\end{aligned}
\tag{13.24}
$$

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{x}_{n}, \mathbf{z}_{n}\right)= p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n}\right) \tag{13.25}
$$

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n}\right)= p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n-1}\right) \tag{13.26}
$$

$$
p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n}, \mathbf{z}_{n+1}\right)= p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n+1}\right) \tag{13.27}
$$

$$
p\left(\mathbf{x}_{n+2}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n+1}, \mathbf{x}_{n+1}\right)= p\left(\mathbf{x}_{n+2}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n+1}\right) \tag{13.28}
$$

$$
\begin{aligned}
p\left(\mathbf{X} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n}\right) =\ &p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n-1}\right) \times \\
& p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n}\right)
\end{aligned}\tag{13.29}
$$

$$
p\left(\mathbf{x}_{N+1} \mid \mathbf{X}, \mathbf{z}_{N+1}\right)= p\left(\mathbf{x}_{N+1} \mid \mathbf{z}_{N+1}\right) \tag{13.30}
$$

$$
p\left(\mathbf{z}_{N+1} \mid \mathbf{z}_{N}, \mathbf{X}\right)= p\left(\mathbf{z}_{N+1} \mid \mathbf{z}_{N}\right) \tag{13.31}
$$

を満たすことを、有向分離の規準を用いて確かめよ。

----

P.84, 85の条件付き独立性とP.90の有向分離の規準を復習すると、任意の重複しないノード集合$A, B, C$があり、$A$の任意のノードから$B$の任意のノードへのすべての経路を考えたときに$C$がP.90の(a), (b)の条件を満たすとき、「$A$は$C$によって$B$から有向分離されている」と呼び、$A \perp \!\!\! \perp B \mid C$で表す。このとき、

$$
p(A\mid B, C) = p(A\mid C) \iff p(B\mid A, C) = p(B\mid C) \iff p(A,B\mid C) = p(A\mid C)p(B\mid C)
$$

が成立する。日本語でまとめると、

- $A$と$B$が$C$を与えたもとで条件付き独立
- $C$が分かっている状況で新たに$B$が分かっても、$A$に関する情報は得られない
- $C$が分かっている状況で新たに$A$が分かっても、$B$に関する情報は得られない

隠れマルコフモデルのグラフィカルモデルは

![](https://i.imgur.com/GRbf8ob.png)

これを踏まえて$(13.24)-(13.31)$を1つずつ示していく。

$(13.24)$について、$\{\mathbf{x}_{1},\ldots,\mathbf{x}_{n}\}$の任意のノードから$\{\mathbf{x}_{n+1},\ldots,\mathbf{x}_{N}\}$の任意のノードへの経路は$\mathbf{z}_{n}$によって遮断されている。なぜなら、$\mathbf{z}_{n}$でhead-to-tailまたはtail-to-tail($\mathbf{x}_{n}$のみ)となっているからである。すなわち$\{\mathbf{x}_{1},\ldots,\mathbf{x}_{n}\} \perp \!\!\! \perp \{\mathbf{x}_{n+1},\ldots,\mathbf{x}_{N}\} \mid \mathbf{z}_{n}$と書けるので、

$$
\begin{aligned}
p\left(\mathbf{X} \mid \mathbf{z}_{n}\right) =\ &p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n} \mid \mathbf{z}_{n}\right) \times \\
&p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n}\right)
\end{aligned}
$$

となる。

$(13.25)$について、$\{\mathbf{x}_{1},\ldots,\mathbf{x}_{n-1}\}$の任意のノードから$\mathbf{x}_{n}$のノードへの経路は$\mathbf{z}_{n}$でhead-to-tailになっているので遮断されている。すなわち$\{\mathbf{x}_{1},\ldots,\mathbf{x}_{n-1}\} \perp \!\!\! \perp \mathbf{x}_{n} \mid \mathbf{z}_{n}$と書けるので、

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{x}_{n}, \mathbf{z}_{n}\right)= p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n}\right)
$$

となる。

$(13.26)$について、$\{\mathbf{x}_{1},\ldots,\mathbf{x}_{n-1}\}$の任意のノードから$\mathbf{z}_{n}$のノードへの経路は$\mathbf{z}_{n-1}$でhead-to-tail（$\mathbf{x}_{n-1}$以外）またはtail-to-tail（$\mathbf{x}_{n-1}$のみ）になっているので遮断されている。すなわち$\{\mathbf{x}_{1},\ldots,\mathbf{x}_{n-1}\} \perp \!\!\! \perp \mathbf{z}_{n} \mid \mathbf{z}_{n-1}$と書けるので、

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n}\right) = p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n}, \mathbf{z}_{n-1}\right)= p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n-1}\right)
$$

となる。

$(13.27)$について、ノード$\mathbf{z}_{n}$から$\{\mathbf{x}_{n+1},\ldots,\mathbf{x}_{N}\}$の任意のノードへの経路は$\mathbf{z}_{n+1}$でhead-to-tailになっているので遮断されている。すなわち$\mathbf{z}_{n} \perp \!\!\! \perp \{\mathbf{x}_{n+1},\ldots,\mathbf{x}_{N}\} \mid \mathbf{z}_{n+1}$と書けるので、

$$
p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n}, \mathbf{z}_{n+1}\right)= p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n+1}\right)
$$

$(13.28)$について、ノード$\mathbf{x}_{n+1}$から$\{\mathbf{x}_{n+2},\ldots,\mathbf{x}_{N}\}$の任意のノードへの経路は$\mathbf{z}_{n+1}$でtail-to-tailになっているので遮断されている。すなわち$\mathbf{x}_{n+1} \perp \!\!\! \perp \{\mathbf{x}_{n+2},\ldots,\mathbf{x}_{N}\} \mid \mathbf{z}_{n+1}$と書けるので、

$$
p\left(\mathbf{x}_{n+2}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n+1}, \mathbf{x}_{n+1}\right)= p\left(\mathbf{x}_{n+2}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n+1}\right)
$$

$(13.29)$について、まずノード$\{\mathbf{x}_{1},\ldots,\mathbf{x}_{n-1}\}$から$\{\mathbf{x}_{n},\ldots,\mathbf{x}_{N}\}$の任意のノードへの経路は$\mathbf{z}_{n-1}, \mathbf{z}_{n}$でhead-to-tailまたはtail-to-tailになっているので遮断されている。すなわち$\mathbf{x}_{1}, \ldots ,\mathbf{x}_{n-1} \perp \!\!\! \perp \mathbf{x}_{n}, \ldots , \mathbf{x}_{N} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n}$と書けるので、

$$
p\left(\mathbf{X} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n} \right) = p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n-1},\mathbf{z}_{n} \right)p\left(\mathbf{x}_{n}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n-1},\mathbf{z}_{n} \right)
$$

右辺第一項は$\{\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1}\}$から$\mathbf{z}_{n}$までの経路が$\mathbf{z}_{n-1}$で遮断されているので$\{\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N}\} \perp \!\!\! \perp \mathbf{z}_{n} \mid \mathbf{z}_{n-1}$となり

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n-1},\mathbf{z}_{n} \right) = p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n-1} \right)
$$

右辺第二項は$\mathbf{x}_{n}$から$\{\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N}\}$までの経路が$\mathbf{z}_{n}$で遮断されているので

$$
p\left(\mathbf{x}_{n}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n-1},\mathbf{z}_{n} \right) = p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n} \right)p\left(\mathbf{x}_{n+1},\ldots,\mathbf{x}_{N} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n} \right)
$$

さらにこの右辺について、同様に考えると、$\mathbf{z}_{n-1}\perp \!\!\! \perp \mathbf{x}_{n} \mid \mathbf{z}_{n}$と$\mathbf{z}_{n-1}\perp \!\!\! \perp \{\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N}\}\mid \mathbf{z}_n$が成立しているので、

$$
\begin{aligned}
p\left(\mathbf{x}_{n}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n-1},\mathbf{z}_{n} \right) &= p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n} \right)p\left(\mathbf{x}_{n+1},\ldots,\mathbf{x}_{N} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n} \right) \\
&= p(\mathbf{x}_{n} \mid \mathbf{z}_{n})p(\mathbf{x}_{n+1},\ldots,\mathbf{x}_{N} \mid \mathbf{z}_{n})
\end{aligned}
$$

以上を合わせて

$$
\begin{aligned}
p\left(\mathbf{X} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n}\right) =\ &p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n-1}\right) \times \\
& p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n}\right)
\end{aligned}
$$

$(13.30)$について、$\mathbf{x}_{N+1}$ノードから任意の$\mathbf{X}$ノードへは$\mathbf{z}_{N+1}$で遮断されている。$\mathbf{X} \perp \!\!\! \perp \mathbf{x}_{N+1} \mid \mathbf{z}_{N+1}$なので、

$$
p\left(\mathbf{x}_{N+1} \mid \mathbf{X}, \mathbf{z}_{N+1}\right)= p\left(\mathbf{x}_{N+1} \mid \mathbf{z}_{N+1}\right)
$$

$(13.31)$について、任意の$\mathbf{X}$ノードから$\mathbf{z}_{N+1}$ノードへは$\mathbf{z}_{N}$で遮断されている。$\mathbf{X} \perp \!\!\! \perp \mathbf{z}_{N+1} \mid \mathbf{z}_{N}$なので、

$$
p\left(\mathbf{z}_{N+1} \mid \mathbf{z}_{N}, \mathbf{X}\right)= p\left(\mathbf{z}_{N+1} \mid \mathbf{X}, \mathbf{z}_{N}\right) = p\left(\mathbf{z}_{N+1} \mid \mathbf{z}_{N}\right)
$$

## 演習 13.10

隠れマルコフモデルの

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}, \mathbf{z}_{1}, \ldots, \mathbf{z}_{N}\right)=p\left(\mathbf{z}_{1}\right)\left[\prod_{n=2}^{N} p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)\right] \prod_{n=1}^{N} p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) \tag{13.6}
$$

で定義される同時分布が条件付き独立性$(13.24)-(13.31)$を満たすことを、確率の加法乗法定理を用いて確かめよ。

----

$(13.24)$を加法・乗法定理から求める

$$
\begin{aligned}
p\left(\mathbf{x}_{1}, \ldots \mathbf{x}_{n}, \mathbf{z}_{n}\right)&=\sum_{\mathbf{x}_{n+1}} \cdots \sum_{\mathbf{x}_{N}} p\left(\mathbf{X}, \mathbf{Z}_{n}\right)=\sum_{\mathbf{x}_{n+1}} \cdots \sum_{\mathbf{x}_{N}} \sum_{\mathbf{Z}_{/n}} p(\mathbf{X}, \mathbf{Z}) \\
&=\sum_{\mathbf{x}_{n+1}} \cdots \sum_{\mathbf{x}_{N}} \sum_{\mathbf{Z}_{/n}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{Z}_{/n}} \sum_{\mathbf{x}_{n+1}} \ldots \sum_{\mathbf{x}_{N}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{Z}_{/n}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \sum_{\mathbf{x}_{n+1}} \ldots \sum_{\mathbf{x}_{N}} \prod_{i= n+1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{Z}_{/n}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \prod_{i=n+1}^{N} \underbrace{\sum_{\mathbf{x}_{i}} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)}_{=1} \\
&=\sum_{\mathbf{Z}_{/n}} p\left(\mathbf{z}_{i}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{z}_{1}} \cdots \sum_{\mathbf{z}_{n-1}} \sum_{\mathbf{z}_{n+1}} \cdots \sum_{\mathbf{z}_{N}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{z}_{1}} \ldots \sum_{\mathbf{z}_{n-1}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)\left(\sum_{\mathbf{z}_{n+1}} \cdots \sum_{\mathbf{z}_{N}}\left[\prod_{i=n+1}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right]\right) \\
&=\sum_{\mathbf{z}_{1}} \cdots \sum_{\mathbf{z}_{n-1}} p\left(\mathbf{z}_{i}\right)\left[\prod_{i=2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)
\end{aligned}
$$

となる。同様に

$$
\begin{aligned}
p\left(\mathbf{x}_{n+1}, \cdots \mathbf{x}_{N}, \mathbf{z}_{n}\right)&=\sum_{\mathbf{x}_{1}} \cdots \sum_{\mathbf{x}_{n}} \sum_{\mathbf{Z}_{/n}} p(\mathbf{X}, \mathbf{Z}) \\
&=\sum_{\mathbf{x}_{1}} \ldots \sum_{\mathbf{x}_{n}} \sum_{\mathbf{Z}_{/n}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{Z}_{/n}} p\left(\mathbf{z}_{i}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=n+1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \underbrace{\sum_{\mathbf{x}_{1}} \sum_{\mathbf{x}_{n}} \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)}_{1} \\
&=\sum_{\mathbf{Z}_{/n}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=n+1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{z}_{n+1}} \sum_{\mathbf{z}_{N}}\left[\prod_{i=n+1}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=n+1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \sum_{\mathbf{z}_{1}} \cdots \sum_{\mathbf{z}_{n-1}} p\left(\mathbf{z}_{i}\right)\left[\prod_{1-2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \\
&=\left(\sum_{\mathbf{z}_{n+1}} \cdots \sum_{\mathbf{z}_{N}}\left[\prod_{i=n+1}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=n+1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)\right)\left(\sum_{\mathbf{z}_{1}} \cdots \sum_{\mathbf{z}_{n-1}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right]\right)
\end{aligned}
$$

となる。ここで

$$
\begin{aligned}
p\left(\mathbf{z}_{n}\right)=\sum_{\mathbf{X}} \sum_{\mathbf{Z}_{/n}} p\left(\mathbf{X}, \mathbf{z}\right)&=\sum_{\mathbf{X}} \sum_{\mathbf{Z}_{/n}} p\left(\mathbf{z}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{Z}_{/n}} p\left(\mathbf{z}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \underbrace{\sum_{\mathbf{x}_{i=1}}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i}\right)}_{=1} \\
&=\sum_{\mathbf{Z}_{/n}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \\
&=\sum_{\mathbf{z}_{1}} \cdots \sum_{\mathbf{z}_{n-1}} \sum_{\mathbf{z}_{n+1}} \cdots \sum_{\mathbf{z}_{N}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \\
&=\sum_{\mathbf{z}} \cdots \sum_{\mathbf{z}_{n-1}} p\left(\mathbf{z}\right)\left[\prod_{i=2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \underbrace{\sum_{\mathbf{z}_{n+1}}\cdots\sum_{\mathbf{z}_{N}}\left[\prod_{i=n+1}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right]}_{=1}\\
&=\sum_{\mathbf{z}} \cdots \sum_{\mathbf{z}_{n-1}} p\left(\mathbf{z}\right)\left[\prod_{i=2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right]
\end{aligned}
$$

なので

$$
\begin{aligned}
&p\left(\mathbf{x}_{n+1}{ }, \ldots, \mathbf{x}_{N}, \mathbf{z}_{n}\right)=\left(\sum_{\mathbf{z}_{n+1}}\cdots \sum_{\mathbf{z}_{N}}\left[\prod_{i=n+1}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=n+1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)\right) p\left(\mathbf{z}_{n}\right) \\
&\left.\therefore p\left(\mathbf{x}_{n+1}{ }, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n}\right)=\ \sum_{\mathbf{z}_{n+1}} \ldots \sum_{\mathbf{z}_{N}}\left[\prod_{i=n+1}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=n+1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)\right)
\end{aligned}
$$

よって

$$
\begin{aligned}
& p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}, \mathbf{z}_{n}\right) p\left(\mathbf{x}_{n+1}, \ldots,\mathbf{x}_{N} \mid \mathbf{z}_{n}\right) \\
=&\ \left(\sum_{\mathbf{z}_{1}} \ldots \sum_{\mathbf{z}_{n-1}} p\left(\mathbf{z}\right)\left[\prod_{i=2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)\right)\left(\sum_{\mathbf{z}_{n+1}} \sum_{\mathbf{z}_{N}}\left[\prod_{i=n+1}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=n+1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)\right) \\
=&\ \sum_{\mathbf{z}_{n+1}}\cdots\sum_{\mathbf{z}_{N}}\left(\sum_{\mathbf{z}_{1}}\cdots\sum_{\mathbf{z}_{n-1}} p\left(\mathbf{z}\right)\left[\prod_{i=2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)\right) \underbrace{\left.\prod_{i=n+1}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=n+1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)}) \\
=&\ \sum_{\mathbf{z}_{n+1}} \cdots \sum_{\mathbf{z}_{N}}\left(\sum_{\mathbf{z}_{1}} \cdots \sum_{\mathbf{z}_{n-1}} p\left(\mathbf{z}\right)\left[\prod_{i=2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)\left[\prod_{i=n+1}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=n+1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right)\right) \\
=&\ \sum_{\mathbf{z}} \cdots \sum_{\mathbf{z}_{n-1}} \sum_{\mathbf{z}_{n+1}} \cdots \sum_{\mathbf{z}_{N}} p\left(\mathbf{z}\right)\left[\prod_{i=2}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{N} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
=&\ \sum_{\mathbf{Z}_{/n}} p(\mathbf{X}, \mathbf{Z}) = p\left(\mathbf{X}, \mathbf{z}_{n}\right)
\end{aligned}
$$

を得る。両辺を$p\left(\mathbf{z}_{n}\right)$で割ると

$$
\frac{p\left(\mathbf{x}_{1} \ldots \mathbf{x}_{n}, \mathbf{z}_{n}\right) p\left(\mathbf{x}_{n+1} \ldots \mathbf{x}_{N} \mid \mathbf{z}_{n}\right)}{p\left(\mathbf{z}_{n}\right)}=\frac{p\left(\mathbf{X}, \mathbf{z}_{n}\right)}{p\left(\mathbf{z}_{n}\right)}
$$

$$
\therefore p\left(\mathbf{x}_{1} \ldots \mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{x}_{n+1} \cdots \mathbf{x}_{N} \mid \mathbf{z}_{n}\right)=p\left(\mathbf{X} \mid \mathbf{z}_{n}\right) \tag{13.24}
$$

## 演習 13.11

因子グラフにおける一つの因子における変数の周辺分布の表現

$$
p\left(\mathbf{x}_{s}\right)=f_{s}\left(\mathbf{x}_{s}\right) \prod_{i \in \operatorname{ne}\left(f_{s}\right)} \mu_{x_{i} \rightarrow f_{s}}\left(x_{i}\right) \tag{8.72}
$$

を出発点として、13.2.3節で得られた積和アルゴリズムにおけるメッセージの結果も用いて、隠れマルコフモデルにおける2つの連続した潜在変数上の同時事後確率分布の結果$(13.43)$

$$
\begin{aligned}
\xi\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)&=p\left(\mathbf{z}_{n-1}, \mathbf{z}_{n} \mid \mathbf{X}\right) \\
&=\frac{p\left(\mathbf{X} \mid \mathbf{z}_{n-1}, \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)}{p(\mathbf{X})} \\
&=\frac{p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n-1} \mid \mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) p\left(\mathbf{z}_{n-1}\right)}{p(\mathbf{X})} \\
&=\frac{\alpha\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \beta\left(\mathbf{z}_{n}\right)}{p(\mathbf{X})}
\end{aligned}
$$

を導け.

----

考え方としては、pp.344-345がノード$\mathbf{z}_{n}$ 1つについてHMMの積和アルゴリズムを用いて$\gamma(\mathbf{z}_{n})$を求めているのを参考しながら、図13.15の因子$f_{n}$に結合している$\mathbf{z}_{n-1}, \mathbf{z}_{n}$ 2つの変数ノードについて計算すれば良い。注意として、$\mathbf{X} = \{\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}\}$は与えられており、条件付きの形で考える必要がある。

![](https://i.imgur.com/7JHcpzo.png)

まず定義から$\xi\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)=p\left(\mathbf{z}_{n-1}, \mathbf{z}_{n} \mid \mathbf{X}\right)$である。pp.344-345の議論のように、$\mathbf{X}$が与えられている状態で単純化された因子グラフを書くと図13.15のようになる。

$(13.50)$と$(13.52)$で見たように、$\alpha(\mathbf{z}_{n}), \beta(\mathbf{z}_{n})$は

$$
\alpha\left(\mathbf{z}_{n}\right)=\mu_{f_{n} \rightarrow \mathbf{z}_{n}}\left(\mathbf{z}_{n}\right) \tag{13.50}
$$

$$
\beta\left(\mathbf{z}_{n}\right)=\mu_{f_{n+1} \rightarrow \mathbf{z}_{n}}\left(\mathbf{z}_{n}\right) \tag{13.52}
$$

と定義できるので、これを用いて$(8.72)$を利用してある因子$f_{n}$に関連する変数ノード$\mathbf{z}_{n-1}, \mathbf{z}_{n}$全体上の周辺分布を求めると、すでに$\mathbf{X} = \{\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}\}$で条件付けられていることに注意して

$$
\begin{aligned}
p\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}, \mathbf{X}\right) &=f_{n}\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right) \mu_{\mathbf{z}_{n-1} \rightarrow f_{n}}\left(\mathbf{z}_{n-1}\right) \mu_{\mathbf{z}_{n} \rightarrow f_{n}}\left(\mathbf{z}_{n}\right) \\
&=p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) \mu_{f_{n-1} \rightarrow \mathbf{z}_{n-1}}\left(\mathbf{z}_{n-1}\right) \mu_{f_{n+1} \rightarrow \mathbf{z}_{n}}\left(\mathbf{z}_{n}\right) \\
&=\alpha\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \beta\left(\mathbf{z}_{n}\right)
\end{aligned}
$$

となる。この式変形では

$$
\begin{aligned}
\mu_{x_{m} \rightarrow f_{s}}\left(x_{m}\right) &=\prod_{l \in \operatorname{ne}\left(x_{m}\right) \backslash f_{s}}\left[\sum_{X_{l m}} F_{l}\left(x_{m}, X_{l m}\right)\right] \\
&=\prod_{l \in \operatorname{ne}\left(x_{m}\right) \backslash f_{s}} \mu_{f_{l} \rightarrow x_{m}}\left(x_{m}\right)
\end{aligned} \tag{8.69}
$$

も利用した。これについて両辺を$p(\mathbf{X})$で割ると

$$
\begin{aligned}
\xi\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)&=p\left(\mathbf{z}_{n-1}, \mathbf{z}_{n} \mid \mathbf{X}\right) \\
&= \frac{\alpha\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \beta\left(\mathbf{z}_{n}\right)}{p(\mathbf{X})}
\end{aligned}\tag{13.43}
$$

を得る。

## 演習 13.12

隠れマルコフモデルを$R$個の独立した観測系列から構成されるデータを用いた最尤推定で学習したいとする。ここで、これらの観測行列を$\mathbf{X}^{(r)}, r=1, \ldots, R$で表す。EMアルゴリズムのEステップにおいて潜在変数の事後確率を求めるためには、各々の系列に対して独立に$\alpha$再帰と$\beta$再帰を実行すればよいことを示せ。また、Mステップにおいては、初期確率と遷移確率のパラメータは

$$
\pi_{k}=\frac{\gamma\left(z_{1 k}\right)}{\sum_{j=1}^{K} \gamma\left(z_{1 j}\right)} \tag{13.18}
$$

$$
A_{j k}=\frac{\sum_{n=2}^{N} \xi\left(z_{n-1, j}, z_{n k}\right)}{\sum_{l=1}^{K} \sum_{n=2}^{N} \xi\left(z_{n-1, j}, z_{n l}\right)} \tag{13.19}
$$

を以下のように修正した式で再推定されることを示せ.

$$
\pi_{k}= \frac{\sum_{r=1}^{R} \gamma\left(z_{1 k}^{(r)}\right)}{\sum_{r=1}^{R} \sum_{j=1}^{K} \gamma\left(z_{1 j}^{(r)}\right)} \tag{13.124}
$$

$$
A_{j k}= \frac{\sum_{r=1}^{R} \sum_{n=2}^{N} \xi\left(z_{n-1, j}^{(r)}, z_{n, k}^{(r)}\right)}{\sum_{r=1}^{R} \sum_{l=1}^{K} \sum_{n=2}^{N} \xi\left(z_{n-1, j}^{(r)}, z_{n, l}^{(r)}\right)} \tag{13.125}
$$

ここで、表記を簡単にするために、系列はすべて同じ長さをもつと仮定した(長さの異なる系列への一般化は簡単である) 。同様に、ガウス出力モデルの平均の再推定のためのMステップの方程式が以下の形で与えられることを示せ。

$$
\boldsymbol{\mu}_{k}=\frac{\sum_{r=1}^{R} \sum_{n=1}^{N} \gamma\left(z_{n k}^{(r)}\right) \mathbf{x}_{n}^{(r)}}{\sum_{r=1}^{R} \sum_{n=1}^{N} \gamma\left(z_{n k}^{(r)}\right)}
$$

他の出力モデルパラメータや出力分布に対するMステップの方程式も類似の形になることに注意せよ。

----

隠れマルコフモデルの定義から、観察値$\mathbf{X}^{(r)}$には対応する潜在変数$\mathbf{Z}^{(r)}$が存在する。よって、その同時分布は以下のように表せる

$$
\begin{aligned}
p(\mathbf{X}, \mathbf{Z}|\boldsymbol{\theta}) = \prod_r^R p(\mathbf{X}^{(r)}, \mathbf{Z}^{(r)}|\boldsymbol{\theta})
\end{aligned}
$$

そして、Eステップでは、事後分布を求める。

$$
\begin{aligned}
p(\mathbf{Z}|\mathbf{X}, \boldsymbol{\theta}) &= \frac{p(\mathbf{X}, \mathbf{Z}|\boldsymbol{\theta})}{\sum_{\mathbf{Z}} p(\mathbf{X}, \mathbf{Z}|\boldsymbol{\theta})} \\
&= \frac{\prod_r p(\mathbf{X}^{(r)}, \mathbf{Z}^{(r)}|\boldsymbol{\theta})}{\sum_{\mathbf{Z}^{(1)}} \cdots \sum_{\mathbf{Z}^{(R)}}\prod_r p(\mathbf{X}^{(r)}, \mathbf{Z}^{(r)}|\boldsymbol{\theta})}\\
&= \prod_r \frac{p(\mathbf{X}^{(r)}, \mathbf{Z}^{(r)}|\boldsymbol{\theta})}{\sum_{\mathbf{Z}^{(r)}} p(\mathbf{X}^{(r)}, \mathbf{Z}^{(r)}|\boldsymbol{\theta})}\\
&= \prod_r  p( \mathbf{Z}^{(r)}|\mathbf{X}^{(r)},\boldsymbol{\theta})
\end{aligned}
$$

ここで、

$$
\begin{aligned}
p( \mathbf{Z}^{(r)}|\mathbf{X}^{(r)}) &= p( \mathbf{z}_{N}^{(r)}| \mathbf{z}_{N-1}^{(r)}, \cdots \mathbf{z}_{1}^{(r)}, \mathbf{X}^{(r)}) p( \mathbf{z}_{N-1}^{(r)}, \cdots \mathbf{z}_{1}^{(r)}|\mathbf{X}^{(r)}) \\
&= p( \mathbf{z}_{N}^{(r)}| \mathbf{z}_{N-1}^{(r)}, \mathbf{X}^{(r)}) p( \mathbf{z}_{N-1}^{(r)}, \cdots \mathbf{z}_{1}^{(r)}|\mathbf{X}^{(r)}) \\
&= p( \mathbf{z}_{N}^{(r)}| \mathbf{z}_{N-1}^{(r)}, \mathbf{X}^{(r)})  \cdots p( \mathbf{z}_{2}^{(r)}|\mathbf{z}_{1}^{(r)}\mathbf{X}^{(r)}) p( \mathbf{z}_{1}^{(r)}|\mathbf{X}^{(r)}) \\
&= \frac{p( \mathbf{z}_{N}^{(r)}, \mathbf{z}_{N-1}^{(r)}|\mathbf{X}^{(r)})}{p( \mathbf{z}_{N-1}^{(r)}|\mathbf{X}^{(r)}) } \cdots \frac{p( \mathbf{z}_{2}^{(r)}, \mathbf{z}_{1}^{(r)}|\mathbf{X}^{(r)})}{p( \mathbf{z}_{1}^{(r)}|\mathbf{X}^{(r)}) }p( \mathbf{z}_{1}^{(r)}|\mathbf{X}^{(r)}) \\
&= \frac{\xi^{(r)}(\mathbf{z}_{N}^{(r)}, \mathbf{z}_{N-1}^{(r)})}{\gamma^{(r)}(\mathbf{z}_{N-1}^{(r)})} \cdots \frac{\xi^{(r)}(\mathbf{z}_{2}^{(r)}, \mathbf{z}_{1}^{(r)})}{\gamma^{(r)}(\mathbf{z}_{1}^{(r)})}\gamma^{(r)}(\mathbf{z}_{1}^{(r)})\\
&= \frac{\prod_{n=2}^N  \xi^{(r)}(\mathbf{z}_{n}^{(r)}, \mathbf{z}_{n-1}^{(r)})}{\prod_{n=2}^{N-1} \gamma^{(r)}(\mathbf{z}_{n}^{(r)})}
\end{aligned}
$$

である。

よって、

$$
\begin{aligned}
p( \mathbf{Z}|\mathbf{X}, \boldsymbol{\theta}) &= \prod_r \frac{\prod_{n=2}  \xi^{(r)}(\mathbf{z}_{n}^{(r)}, \mathbf{z}_{n-1}^{(r)})}{\prod_{n=2} \gamma^{(r)}(\mathbf{z}_{n}^{(r)})}
\end{aligned}
$$

これより、Eステップで求める事後分布は$\xi$と$\gamma$により計算できる。また、$\xi$と$\gamma$はそれぞれ$\alpha^{(r)}(\mathbf{z}_n)$と$\beta^{(r)}(\mathbf{z}_n)$を再帰で求めることができる。

次にMステップを考える。Eステップで求めた事後分布と$\theta_{old}$を用いて、完全データ対数尤度の期待値を求める。

$$
\begin{aligned}
Q(\boldsymbol{\theta}, \boldsymbol{\theta_{old}}) &= E_{\mathbf{Z}} [\ln p(\mathbf{X, Z}|\boldsymbol{\theta}) ] \\
&=  E_{\mathbf{Z}} [\sum_r^R \ln p(\mathbf{X}^{(r)}, \mathbf{Z}^{(r)}|\boldsymbol{\theta}) ] \\
&= \sum_r^R p( \mathbf{Z}^{(r)}|\mathbf{X}^{(r)},\boldsymbol{\theta}_{old})  \ln p(\mathbf{X}, \mathbf{Z}|\boldsymbol{\theta}) \\
&= \sum_r^R \sum_k^K \gamma(z_{1k}^{(r)}) \ln \pi_k + \sum_r^R \sum_N^n \sum_j^K \sum_k^K \xi(z_{n-1, j}^{(r)}, z_{n, k}^{(r)}) \ln A_{jk}+ \sum_r^R \sum_N^n \sum_k^K \gamma(z_{nk}^{(r)}) \ln p(\mathbf{x}_n^{(r)}|\phi_k) &(EX13.12.1)
\end{aligned}
$$

最後の形は、いつも通りラグランジュ乗数法を用いて$\pi$と$\mathbf{A}$について最大化することができる。よって(13.124)、(13.125)が導かれる。詳細は http://sioramen.sub.jp/prml_wiki/lib/exe/fetch.php/wiki/13.12.pdf

次に、出力分布をガウス分布とする。すなわち、

$$
\begin{aligned}
p(\mathbf{x}_n^{(r)}|\phi_k) = N(\mathbf{x}_n^{(r)}|\mathbf{\mu}_k, \mathbf{\Sigma}_k)
\end{aligned}
$$

とする。

この時、$Q(\boldsymbol{\theta}, \boldsymbol{\theta_{old}})$は(EX13.12.1)を用いて、$\mathbf{\mu}_k$を含まない部分は$C$にまとめて、

$$
\begin{aligned}
Q(\boldsymbol{\theta}, \boldsymbol{\theta_{old}}) &= C+\sum_r^R \sum_N^n \sum_k^K \gamma(z_{nk}^{(r)}) \ln p(\mathbf{x}_n^{(r)}|\phi_k) \\
&= C+\sum_r^R \sum_N^n \sum_k^K \gamma(z_{nk}^{(r)}) \ln \frac{1}{(2\pi)^{D/2}}\frac{1}{|\mathbf{\Sigma}_k|^{1/2}} \exp\{ -\frac{1}{2}(\mathbf{x}_n^{(r)}-\mathbf{\mu}_k)^T \mathbf{\Sigma}_k^{-1}(\mathbf{x}_n^{(r)}-\mathbf{\mu}_k)\} \\
&= C+\sum_r^R \sum_N^n \sum_k^K \gamma(z_{nk}^{(r)}) \{ -\frac{1}{2}(\mathbf{x}_n^{(r)}-\mathbf{\mu}_k)^T \mathbf{\Sigma}_k^{-1}(\mathbf{x}_n^{(r)}-\mathbf{\mu}_k)\}
\end{aligned}
$$

なお、最後の式変形は、$\ln$の後の一部を$C$にまとめた。あとはいつも通り$\mathbf{\mu}_k$について停留条件を求めると、Mステップの方程式が得られる。

## 演習 13.13

因子グラフにおける因子ノードから変数ノードへ渡されるメッセージの定義

$$
\mu_{f_{s} \rightarrow x}(x) \equiv \sum_{X_{s}} F_{s}\left(x, X_{s}\right) \tag{8.64}
$$

と隠れマルコフモデルの同時分布の表現

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}, \mathbf{z}_{1}, \ldots, \mathbf{z}_{N}\right)=p\left(\mathbf{z}_{1}\right)\left[\prod_{n=2}^{N} p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)\right] \prod_{n=1}^{N} p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) \tag{13.6}
$$

を用いて、$\alpha$メッセージの定義

$$
\alpha\left(\mathbf{z}_{n}\right)=\mu_{f_{n} \rightarrow \mathbf{z}_{n}}\left(\mathbf{z}_{n}\right) \tag{13.50}
$$

が

$$
\alpha\left(\mathbf{z}_{n}\right) \equiv p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}, \mathbf{z}_{n}\right) \tag{13.34}
$$

の定義と同一であることを示せ。

----

$(8.64)$の定義からスタートする。

$$
\begin{aligned}
\alpha\left(\mathbf{z}_{n}\right) &=\mu_{f_{n} \rightarrow \mathbf{z}_{n}}\left(\mathbf{z}_{n}\right) \\
&=\sum_{\mathbf{z}_{n-1}} f_{n}\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right) \mu_{\mathbf{z}_{n-1}\to f_{n}}\left(\mathbf{z}_{n-1}\right) \\
&=\sum_{\mathbf{z}_{n-1}} f_{n}\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right) \mu_{f_{n-1} \rightarrow \mathbf{z}_{n-1}}\left(\mathbf{z}_{n-1}\right)\\
&=\cdots \\
&=\sum_{\mathbf{z}_{1},\ldots,\mathbf{z}_{n-1}} h\left(\mathbf{z}_{1}\right) \prod_{i=2}^{n} f_{i}\left(\mathbf{z}_{i-1}, \mathbf{z}_{i}\right)
\end{aligned}
$$

ここで、図13.15の因子グラフでは

$$
h\left(\mathbf{z}_{1}\right) =p\left(\mathbf{z}_{1}\right) p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}\right) \tag{13.45}
$$

$$
f_{n}\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right) =p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) \tag{13.46}
$$

が成立しているので、これを利用して更に変形すると、周辺化を利用して

$$
\begin{aligned}
\alpha\left(\mathbf{z}_{n}\right) &=\sum_{\mathbf{z}_{1}, \cdots, \mathbf{z}_{n-1}} p\left(\mathbf{z}_{1}\right) p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}\right) \prod_{i=2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right) p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{z}_{1}, \cdots, \mathbf{z}_{n-1}} p\left(\mathbf{z}_{1}\right)\left[\prod_{i=2}^{n} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right)\right] \prod_{i=1}^{n} p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{z}_{1}, \cdots, \mathbf{z}_{n-1}} p\left(\mathbf{x}_{1}, \cdots, \mathbf{x}_{n}, \mathbf{z}_{1}, \cdots, \mathbf{z}_{n}\right)\ (\because (13.6))\\
&=p\left(\mathbf{x}_{1}, \cdots, \mathbf{x}_{n}, \mathbf{z}_{n}\right)
\end{aligned}
$$

となり、$(13.34)$の定義が得られる。

## 演習 13.14

因子グラフにおける因子ノードから変数ノードへ渡されるメッセージの定義

$$
\mu_{f_{s} \rightarrow x}(x) \equiv \sum_{\mathbf{x}_{s}} F_{s}\left(x, \mathbf{x}_{s}\right) \tag{8.64}
$$

と隠れマルコフモデルの同時分布の表現

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}, \mathbf{z}_{1}, \ldots, \mathbf{z}_{N}\right)=p\left(\mathbf{z}_{1}\right)\left[\prod_{n=2}^{N} p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)\right] \prod_{n=1}^{N} p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) \tag{13.6}
$$

を用いて、$\beta$メッセージの定義

$$
\beta\left(\mathbf{z}_{n}\right)=\mu_{f_{n+1} \rightarrow \mathbf{z}_{n}}\left(\mathbf{z}_{n}\right) \tag{13.52}
$$

が

$$
\beta\left(\mathbf{z}_{n}\right) \equiv p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n}\right) \tag{13.35}
$$

の定義と同一であることを示せ.

----

演習問題13.13と似たような問題だが、最後の式変形が少し難しくなる。同様に図13.15の因子グラフを用いて考える。

$(13.52)$の定義からスタートして

$$
\begin{aligned}
\beta\left(\mathbf{z}_{n}\right) &=\mu_{f_{n+1} \rightarrow \mathbf{z}_{n}}\left(\mathbf{z}_{n}\right) \\
&=\sum_{\mathbf{z}_{n+1}} f_{n+1}\left(\mathbf{z}_{n}, \mathbf{z}_{n+1}\right) \mu_{\mathbf{z}_{n+1}\to f_{n+1}}\left(\mathbf{z}_{n+1}\right) \\
&=\sum_{\mathbf{z}_{n+1}} f_{n+1}\left(\mathbf{z}_{n}, \mathbf{z}_{n+1}\right) \mu_{f_{n+2}\to\mathbf{z}_{n+1}}\left(\mathbf{z}_{n+1}\right) \\
&=\cdots \\
&=\sum_{\mathbf{z}_{n+1}, \cdots, \mathbf{z}_{N}} \prod_{i=n+1}^{N}f_{i}\left(\mathbf{z}_{i-1}, \mathbf{z}_{i}\right) \underbrace{\mu_{\mathbf{z}_{N}\to f_{N}}\left(\mathbf{z}_{N}\right)}_{=1} \\
&=\sum_{\mathbf{z}_{n+1}, \cdots, \mathbf{z}_{N}} \prod_{i=n+1}^{N}f_{i}\left(\mathbf{z}_{i-1}, \mathbf{z}_{i}\right) \\
&=\sum_{\mathbf{z}_{n+1}, \cdots, \mathbf{z}_{N}} \prod_{i=n+1}^{N} p\left(\mathbf{z}_{i} \mid \mathbf{z}_{i-1}\right) p\left(\mathbf{x}_{i} \mid \mathbf{z}_{i}\right) \quad (\because (13.46))\\
&=\sum_{\mathbf{z}_{n+1}, \cdots, \mathbf{z}_{N}} p\left(\mathbf{z}_{n+1} \mid \mathbf{z}_{n}\right) p\left(\mathbf{x}_{n+1} \mid \mathbf{z}_{n+1}\right) \cdots p\left(\mathbf{z}_{N} \mid \mathbf{z}_{N-1}\right) p\left(\mathbf{x}_{N} \mid \mathbf{z}_{N}\right) \\
&=\sum_{\mathbf{z}_{n+1}, \cdots, \mathbf{z}_{N}} p\left(\mathbf{z}_{n+1} \mid \mathbf{z}_{n}\right) p\left(\mathbf{x}_{n+1} \mid \mathbf{z}_{n}, \mathbf{z}_{n+1}\right) p\left(\mathbf{z}_{n+2} \mid \mathbf{z}_{n+1}\right) p\left(\mathbf{x}_{n+2} \mid \mathbf{z}_{n+2}\right)\cdots p\left(\mathbf{z}_{N} \mid \mathbf{z}_{N-1}\right) p\left(\mathbf{x}_{N} \mid \mathbf{z}_{N}\right) \quad (\because (13.27)) \\
&=\sum_{\mathbf{z}_{n+1}, \cdots, \mathbf{z}_{N}} p\left(\mathbf{x}_{n+1}, \mathbf{z}_{n+1} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n+2} \mid \mathbf{x}_{n+1}, \mathbf{z}_{n+1}\right) p\left(\mathbf{x}_{n+2} \mid \mathbf{x}_{n+1}, \mathbf{z}_{n+1}, \mathbf{z}_{n+2}\right) \cdots p\left(\mathbf{x}_{N} \mid \mathbf{x}_{N-1}, \mathbf{z}_{n+1}, \cdots, \mathbf{z}_{N}\right)\quad (\because (13.28)) \\
&=\sum_{\mathbf{z}_{n+1}, \cdots, \mathbf{z}_{N}} p\left(\mathbf{x}_{n+1}, \cdots, \mathbf{x}_{N}, \mathbf{z}_{n+1}, \cdots, \mathbf{z}_{N} \mid \mathbf{z}_{n}\right) \\
&=p\left(\mathbf{x}_{n+1}, \cdots, \mathbf{x}_{N} \mid \mathbf{z}_{n}\right)
\end{aligned}
$$

以上で$(13.35)$式が示された。

## 演習 13.15

隠れマルコフモデルの周辺分布の表現

$$
\gamma\left(\mathbf{z}_{n}\right)=\frac{p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}, \mathbf{z}_{n}\right) p\left(\mathbf{x}_{n+1}, \ldots, \mathbf{x}_{N} \mid \mathbf{z}_{n}\right)}{p(\mathbf{X})}=\frac{\alpha\left(\mathbf{z}_{n}\right) \beta\left(\mathbf{z}_{n}\right)}{p(\mathbf{X})} \tag{13.33}
$$

と

$$
\xi(\mathbf{z}_{n-1}, \mathbf{z}_{n}) = p(\mathbf{z}_{n-1}, \mathbf{z}_{n} \mid \mathbf{X}) = \frac{\alpha\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \beta\left(\mathbf{z}_{n}\right)}{p(\mathbf{X})} \tag{13.43}
$$

を用いて、スケーリングされた変数についての対応する結果

$$
\gamma\left(\mathbf{z}_{n}\right) =\widehat{\alpha}\left(\mathbf{z}_{n}\right) \widehat{\beta}\left(\mathbf{z}_{n}\right) \tag{13.64}
$$

$$
\xi\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right) =\left(c_{n}\right)^{-1} \widehat{\alpha}\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \widehat{\beta}\left(\mathbf{z}_{n}\right) \tag{13.65}
$$

を導け.

----

$$
\begin{aligned}
\gamma\left(\mathbf{z}_{n}\right)&=\frac{\alpha\left(\mathbf{z}_{n}\right) \beta\left(\mathbf{z}_{n}\right)}{p(\mathbf{X})} \\
&=\frac{p(\mathbf{x}_1,\cdots , \mathbf{x}_n)\widehat{\alpha}\left(\mathbf{z}_{n}\right) \cdot \left( \prod_{m=n+1}^N c_m\right) \widehat{\beta}\left(\mathbf{z}_{n}\right)}{\prod_{m=1}^N c_m } \\
&= \frac{\left(\prod_{m=1}^n c_m \right) \widehat{\alpha}\left(\mathbf{z}_{n}\right) \cdot \left( \prod_{m=n+1}^N c_m\right) \widehat{\beta}\left(\mathbf{z}_{n}\right)}{\prod_{m=1}^N c_m } \\
&=\widehat{\alpha}\left(\mathbf{z}_{n}\right) \widehat{\beta}\left(\mathbf{z}_{n}\right)
\end{aligned}
$$

$$
\begin{aligned}
\xi\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right) &=\frac{\alpha\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \beta\left(\mathbf{z}_{n}\right)}{p(\mathbf{X})}\\
&=\frac{\left(\prod_{m=1}^{n-1} c_m \right) \widehat{\alpha}\left(\mathbf{z}_{n-1}\right) \cdot
p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \cdot \left(\prod_{m=n+1}^{N} c_m \right)
\widehat{\beta}\left(\mathbf{z}_{n}\right)}{\prod_{m=1}^{N} c_m }\\
&=\left(c_{n}\right)^{-1} \widehat{\alpha}\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \widehat{\beta}\left(\mathbf{z}_{n}\right) \end{aligned}
$$

## 演習 13.16

この演習問題では、Viterbiアルゴリズムのフォワードメッセージパッシングの式を同時分布の表現

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}, \mathbf{z}_{1}, \ldots, \mathbf{z}_{N}\right)=p\left(\mathbf{z}_{1}\right)\left[\prod_{n=2}^{N} p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)\right] \prod_{n=1}^{N} p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) \tag{13.6}
$$

から直接導く。これは、すべての隠れ変数$\mathbf{z}_1,\ldots,\mathbf{z}_{N}$についての最大化を含む。対数を取り、最大化と和の順序を交換することにより、再帰式

$$
\omega\left(\mathbf{z}_{n+1}\right)=\ln p\left(\mathbf{x}_{n+1} \mid \mathbf{z}_{n+1}\right)+\max _{\mathbf{z}_{n}}\left\{\ln p\left(\mathbf{z}_{n+1} \mid \mathbf{z}_{n}\right)+\omega\left(\mathbf{z}_{n}\right)\right\} \tag{13.68}
$$

を求めよ。ここで、$\omega(\mathbf{z}_n)$は

$$
\omega\left(\mathbf{z}_{n}\right)=\max _{\mathbf{z}_{1}, \ldots, \mathbf{z}_{n-1}} \ln p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}, \mathbf{z}_{1}, \ldots, \mathbf{z}_{n}\right) \tag{13.70}
$$

で定義される。この再帰式の初期条件が

$$
\omega\left(\mathbf{z}_{1}\right)=\ln p\left(\mathbf{z}_{1}\right)+\ln p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}\right) \tag{13.69}
$$

で与えられることを示せ。

----

(13.6)を書き換えて

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}, \mathbf{z}_{1}, \ldots, \mathbf{z}_{N}\right)=p\left(\mathbf{z}_{1}\right) p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}\right) \prod_{n=2}^{N} p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)
$$

を得る．この式のlogをとると

$$
\begin{aligned}
\ln p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N},\right.&\left.\mathbf{z}_{1}, \ldots, \mathbf{z}_{N}\right)
=\ln p\left(\mathbf{z}_{1}\right)+\ln p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}\right)+\sum_{n=2}^{N}\left(\ln p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right)+\ln p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)\right)
\end{aligned}
$$

となる．ここで最初の2項は(13.69)式で書き換えられる．この式を$\mathbf{z}_1,\dots,\mathbf{z}_N$について最大化すると

$$
\begin{aligned}
\max _{\mathbf{z}_{1}, \ldots, \mathbf{z}_{N}} &\left\{\omega\left(\mathbf{z}_{1}\right)+\sum_{n=2}^{N}\left[\ln p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right)+\ln p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)\right]\right\} \\
=& \max _{\mathbf{z}_{2}, \ldots, \mathbf{z}_{N}}\left\{\ln p\left(\mathbf{x}_{2} \mid \mathbf{z}_{2}\right)+\max _{\mathbf{z}_{1}}\left\{\ln p\left(\mathbf{z}_{2} \mid \mathbf{z}_{1}\right)+\omega\left(\mathbf{z}_{1}\right)\right\}\right.
\left.+\sum_{n=3}^{N}\left[\ln p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right)+\ln p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)\right]\right\} \\
=& \max _{\mathbf{z}_{2}, \ldots, \mathbf{z}_{N}}\left\{\omega\left(\mathbf{z}_{2}\right)+\sum_{n=3}^{N}\left[\ln p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right)+\ln p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)\right]\right\}
\end{aligned}
$$

ここで最大化と総和の順序を入れ替えて、$n = 2$ の (13.68) を得た。この式の最初の行と最後の行は添字$n$が一つ増えただけで同じ形であり、これによってすべての n > 2 について再帰的に(13.68)が成り立つことがわかる。

## 演習 13.17

![](https://i.imgur.com/JBSYbFA.png)

![](https://i.imgur.com/IADpE0Q.png)

図13.18のinput-output隠れマルコフモデルに対する有向グラフが図13.15に示す形の木構造因子グラフで表現されることを示せ。そして、初期因子$h(\mathbf{z}_{1})$と一般的な因子$f_{n}(\mathbf{z}_{n-1}, \mathbf{z}_{n})$を書き下せ。ここで、$2\leqslant n \leqslant N$である。

----

教科書の図8.42あたりの記述も参考にする。$h$や因子$f_{n}(\mathbf{z}_{n-1}, \mathbf{z}_{n})$は出力確率$\mathbf{x}_{n}$や入力確率$\mathbf{u}_{n}$を吸収した形になる。図13.14, 13.15と同様のやり方を踏まえれば

$$
h\left(\mathbf{z}_{1}\right)=p\left(\mathbf{z}_{1} \mid \mathbf{u}_{1}\right) p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}, \mathbf{u}_{1}\right)
$$

$$
f\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)=p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}, \mathbf{u}_{n}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}, \mathbf{u}_{n}\right)
$$

とすればよい。

## 演習 13.18

演習問題13.17の結果を用いて、図13.18に示すinput-output隠れマルコフモデルのフォワード-バックワードアルゴリズムの再帰式を初期条件とともに導け.

----

フォワード-バックワードアルゴリズムの再帰式は$(13.36)$,$(13.38)$のような式のこと。また、演習13.17で得た結果

$$
f\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)=p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}, \mathbf{u}_{n}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}, \mathbf{u}_{n}\right)
$$

を利用すれば簡単である。まず$\alpha(\mathbf{z}_{n})$について考えると、$(13.49), (13.50)$を参考にして

$$
\begin{aligned}
\alpha\left(\mathbf{z}_{n}\right) &=\mu_{f_{n} \rightarrow \mathbf{z}_{n}}\left(\mathbf{z}_{n}\right) \\
&=\sum_{\mathbf{z}_{n-1}} f_{n}\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right) \underbrace{\mu_{f_{n-1} \rightarrow \mathbf{z}_{n-1}}\left(\mathbf{z}_{n-1}\right)}_{\alpha\left(\mathbf{z}_{n-1}\right)} \\
&=\sum_{\mathbf{z}_{n-1}} p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}, \mathbf{u}_{n}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}, \mathbf{u}_{n}\right) \alpha\left(\mathbf{z}_{n-1}\right)
\end{aligned}
$$


となる。ここで、初期条件$\alpha(\mathbf{z}_{1})$は演習13.17で求めたように

$$
\alpha(\mathbf{z}_{1}) = h\left(\mathbf{z}_{1}\right)=p\left(\mathbf{z}_{1} \mid \mathbf{u}_{1}\right) p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}, \mathbf{u}_{1}\right)
$$

である。同様に$\beta(\mathbf{z}_{n})$について

$$
\begin{aligned}
\beta\left(\mathbf{z}_{n}\right) &=\mu_{f_{n+1} \rightarrow \mathbf{z}_{n}}\left(\mathbf{z}_{n}\right) \\
&=\sum_{\mathbf{z}_{n+1}} f_{n+1}\left(\mathbf{z}_{n}, \mathbf{z}_{n+1}\right) \underbrace{\mu_{f_{n+2} \rightarrow \mathbf{z}_{n+1}}\left(\mathbf{z}_{n+1}\right)}_{\beta(\mathbf{z}_{n+1})} \\
&=\sum_{\mathbf{z}_{n+1}} p\left(\mathbf{z}_{n+1} \mid \mathbf{z}_{n}, \mathbf{u}_{n+1}\right) p\left(\mathbf{x}_{n+1} \mid \mathbf{z}_{n+1}, \mathbf{u}_{n+1}\right) \beta\left(\mathbf{z}_{n+1}\right)
\end{aligned}
$$

となる。初期条件（最初のメッセージ）は$\beta(\mathbf{z}_{N})=1$のままで、これは入力確率$\mathbf{u}_{n}$が存在する場合でも同じである。

## 演習 13.19

線形動的システムにおいては、すべての観測変数により条件付けられた個々の潜在変数に対する事後分布を、カルマンフィルタとカルマンスムーザの方程式を用いて効率的に求めることができる。これらの事後分布の各々を独立に最大化することにより得られる潜在変数の系列が、潜在変数の値の最も確からしい系列と同ーであることを示せ。これを実行する際に、線形動的システムにおいては、すべての潜在変数と観測変数の同時分布はガウス分布であり、したがって、すべての条件付き分布と周辺分布もガウス分布であることに注意して、

$$
p\left(\mathbf{x}_{a}\right)=\mathcal{N}\left(\mathbf{x}_{a} \mid \boldsymbol{\mu}_{a}, \Sigma_{a a}\right) \tag{2.98}
$$

の結果を用いよ.

----

線形動的システムにおいては全ての潜在変数と観測変数の同時分布はガウス分布であるため，任意の変数の組について事後分布を最大化することができる．したがってすべての潜在変数の同時分布を最大化することも、各潜在変数についての周辺分布を個別に最大化することも可能である。しかし、(2.98)から、結果の平均はどちらの場合も同じになることがわかり、ガウス分布では平均と潜在変数の最も確からしい値は一致するので、潜在変数の事後分布をそれぞれに最大化した系列でも潜在変数の同時分布を最大化した系列でも、同じ結果になることがわかる。

## 演習 13.20

$$
p(\mathbf{y})=\mathcal{N}\left(\mathbf{y} \mid \mathbf{A} \boldsymbol{\mu}+\mathbf{b}, \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right) \tag{2.115}
$$

の結果を用いて

$$
\begin{array}{c}\int \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \mathbf{z}_{n-1}, \boldsymbol{\Gamma}\right) \mathcal{N}\left(\mathbf{z}_{n-1} \mid \boldsymbol{\mu}_{n-1}, \mathbf{V}_{n-1}\right) \mathrm{d} \mathbf{z}_{n-1} \\ =\mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \boldsymbol{\mu}_{n-1}, \mathbf{P}_{n-1}\right)\end{array} \tag{13.87}
$$

を証明せよ.

----


(2.113)~(2.115)の議論の結果を変数の対応をとりながら利用することができる

$\mathbf{x}$ の周辺ガウス分布と, $\mathbf{x}$ が与えられたときの $\mathbf{y}$ の条件付きガウス分布が次式で 与えられたとする.

$$
\begin{aligned}
p(\mathbf{x}) &=\mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu}, \boldsymbol{\Lambda}^{-1}\right) \\
p(\mathbf{y} \mid \mathbf{x}) &=\mathcal{N}\left(\mathbf{y} \mid \mathbf{A} \mathbf{x}+\mathbf{b}, \mathbf{L}^{-1}\right)
\end{aligned}
$$

$\mathbf{y}$ の周辺分布は

$$
p(\mathbf{y})=\mathcal{N}\left(\mathbf{y} \mid \mathbf{A} \boldsymbol{\mu}+\mathbf{b}, \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right)
$$

これと今回の変数の対応を考えると，$\mathbf{x}\rightarrow\mathbf{z}_{n-1},\mathbf{\mu}\rightarrow\mathbf{\mu}_{n-1},\boldsymbol{\Lambda}^{-1}\rightarrow\mathbf{V}_{n-1},\mathbf{y}\rightarrow\mathbf{z}_n,\mathbf{A}\rightarrow\mathbf{A},\mathbf{b}\rightarrow\mathbf{0},\mathbf{L}^{-1}\rightarrow\boldsymbol{\Gamma}$となる．この結果を用いると(13.87)が示される．

## 演習 13.21

$$
p(\mathbf{y})=\mathcal{N}\left(\mathbf{y} \mid \mathbf{A} \boldsymbol{\mu}+\mathbf{b}, \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right) \tag{2.115}
$$

$$
p(\mathbf{x} \mid \mathbf{y}) =\mathcal{N}\left(\mathbf{x} \mid \Sigma\left\{\mathbf{A}^{\mathrm{T}} \mathbf{L}(\mathbf{y}-\mathbf{b})+\mathbf{\Lambda} \mu\right\}, \boldsymbol{\Sigma}\right) \tag{2.116}
$$

の結果と、

$$
\left(\mathbf{P}^{-1}+\mathbf{B}^{\mathrm{T}} \mathbf{R}^{-1} \mathbf{B}\right)^{-1} \mathbf{B}^{\mathrm{T}} \mathbf{R}^{-1}=\mathbf{P B}^{\mathrm{T}}\left(\mathbf{B P B}^{\mathrm{T}}+\mathbf{R}\right)^{-1} \tag{C.5}
$$

$$
\left(\mathbf{A}+\mathbf{B D}^{-1} \mathbf{C}\right)^{-1}=\mathbf{A}^{-1}-\mathbf{A}^{-1} \mathbf{B}\left(\mathbf{D}+\mathbf{C A}^{-1} \mathbf{B}\right)^{-1} \mathbf{C A}^{-1} \tag{C.7}
$$

の行列恒等式をともに用いて

$$
\boldsymbol{\mu}_{n} =\mathbf{A} \boldsymbol{\mu}_{n-1}+\mathbf{K}_{n}\left(\mathbf{x}_{n}-\mathbf{C A} \boldsymbol{\mu}_{n-1}\right) \tag{13.89}
$$

$$
\mathbf{V}_{n} =\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{P}_{n-1} \tag{13.90}
$$

$$
c_{n} =\mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{C A} \boldsymbol{\mu}_{n-1}, \mathbf{C P}_{n-1} \mathbf{C}^{\mathrm{T}}+\Sigma\right) \tag{13.91}
$$

の結果を導け。ここで、カルマン利得行列$\mathbf{K}_{n}$は

$$
\mathbf{K}_{n}=\mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}\left(\mathbf{C P}_{n-1} \mathbf{C}^{\mathrm{T}}+\mathbf{\Sigma}\right)^{-1} \tag{13.92}
$$

で定義される.

----

(2.113)~(2.117)の議論より$\mathbf{x}$ の周辺ガウス分布と, $\mathbf{x}$ が与えられたときの $\mathbf{y}$ の条件付きガウス分布が次式で 与えられたとする.

$$
p(\mathbf{x}) =\mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu}, \boldsymbol{\Lambda}^{-1}\right)\tag{2.113}
$$

$$
p(\mathbf{y} \mid \mathbf{x}) =\mathcal{N}\left(\mathbf{y} \mid \mathbf{A} \mathbf{x}+\mathbf{b}, \mathbf{L}^{-1}\right)\tag{2.114}
$$

$\mathbf{y}$ の周辺分布と , $\mathbf{y}$ が与えられたときの $\mathbf{x}$ の条件付き分布は

$$
p(\mathbf{y}) =\mathcal{N}\left(\mathbf{y} \mid \mathbf{A} \boldsymbol{\mu}+\mathbf{b}, \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right) \tag{2.115}
$$

$$
p(\mathbf{x} \mid \mathbf{y}) =\mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\Sigma}\left\{\mathbf{A}^{\mathrm{T}} \mathbf{L}(\mathbf{y}-\mathbf{b})+\boldsymbol{\Lambda} \boldsymbol{\mu}\right\}, \boldsymbol{\Sigma}\right)\tag{2.116}
$$

で与えられる. ただし,

$$
\Sigma=\left(\Lambda+\mathrm{A}^{\mathrm{T}} \mathbf{L} \mathbf{A}\right)^{-1}\tag{2.117}
$$

である．(13.87)の周辺分布の計算結果を用いて(13.86)を書き直すと以下のようになる．

$$
c_{n} \mathcal{N}\left(\mathbf{z}_{n} \mid \boldsymbol{\mu}_{n}, \mathbf{V}_{n}\right)=\mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{C} \mathbf{z}_{n}, \mathbf{\Sigma}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \boldsymbol{\mu}_{n-1}, \mathbf{P}_{n-1}\right)
$$

この式の右辺は$\mathbf{x}_n$と$\mathbf{z}_n$の同時分布で，$\mathbf{z}_n$を与えられたときの$\mathbf{x}_n$の条件付き分布と$\mathbf{z}_n$の分布の積の形で表されている．これらはそれぞれ(2.114)と(2.113)に対応している．
ここで右辺の同時分布の分解を$\mathbf{x}_n$を与えられたときの$\mathbf{z}_n$の条件付き分布と$\mathbf{x}_n$の分布の積の形に書き換える．このときそれぞれ(2.116)と(2.115)に対応することになる

$$
\begin{array}{ll}
\mathbf{x} \Rightarrow \mathbf{z}_{n} \quad \boldsymbol{\mu} \Rightarrow \mathbf{A} \boldsymbol{\mu}_{n-1} \quad \mathbf{\Lambda}^{-1} \Rightarrow \mathbf{P}_{n-1} \\
\mathbf{y} \Rightarrow \mathbf{x}_{n} \quad \mathbf{A} \Rightarrow \mathbf{C} \quad \mathbf{b} \Rightarrow \mathbf{0} \quad \mathbf{L}^{-1} \Rightarrow \boldsymbol{\Sigma} &
\end{array}
$$

これらを代入すると

$(2.113)$,$(2.114),(2.115)$ により $(13.91)$の右辺を得る

また(2.116)から

$$
p\left(\mathbf{z}_{n} \mid \mathbf{x}_{n}\right)=\mathcal{N}\left(\mathbf{z}_{n} \mid \boldsymbol{\mu}_{n}, \mathbf{V}_{n}\right)=\mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{M}\left(\mathbf{C}^{\mathrm{T}} \boldsymbol{\Sigma}^{-1} \mathbf{x}_{n}+\mathbf{P}_{n-1}^{-1} \mathbf{A} \boldsymbol{\mu}_{n-1}\right), \mathbf{M}\right)\tag{1}
$$

ただし(2.117)を用いて$\mathbf{M}$を以下のように定めた．

$$
\mathbf{M}=\left(\mathbf{P}_{n-1}^{-1}+\mathbf{C}^{\mathrm{T}} \boldsymbol{\Sigma}^{-1} \mathbf{C}\right)^{-1}\tag{2}
$$

(C.7)と(13.92)を使って, (2)を書き換えると

$$
\begin{aligned}
\mathbf{M} &=\left(\mathbf{P}_{n-1}^{-1}+\mathbf{C}^{\mathrm{T}} \boldsymbol{\Sigma}^{-1} \mathbf{C}\right)^{-1} \\
&=\mathbf{P}_{n-1}-\mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}\left(\boldsymbol{\Sigma}+\mathbf{C P}_{n-1} \mathbf{C}^{\mathrm{T}}\right)^{-1} \mathbf{C P}_{n-1} \\
&=\left(\mathbf{I}-\mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}\left(\boldsymbol{\Sigma}+\mathbf{C P}_{n-1} \mathbf{C}^{\mathrm{T}}\right)^{-1} \mathbf{C}\right) \mathbf{P}_{n-1} \\
&=\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{P}_{n-1},
\end{aligned}
$$

となり，これは(13.90)の右辺と一致する

(2), (C.5),(13.92)を用いて

$$
\begin{aligned}
\mathbf{M} \mathbf{C}^{\mathrm{T}} \boldsymbol{\Sigma}^{-1} &=\left(\mathbf{P}_{n-1}^{-1}+\mathbf{C}^{\mathrm{T}} \boldsymbol{\Sigma}^{-1} \mathbf{C}\right)^{-1} \mathbf{C}^{\mathrm{T}} \boldsymbol{\Sigma}^{-1} \\
&=\mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}\left(\mathbf{C} \mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}+\mathbf{\Sigma}\right)^{-1}=\mathbf{K}_{n}
\end{aligned}
$$

これと(13.90)を用いると, (1)の平均を書き換えることができて

$$
\begin{aligned}
\mathbf{M}\left(\mathbf{C}^{\mathrm{T}} \boldsymbol{\Sigma}^{-1} \mathbf{x}_{n}+\mathbf{P}_{n-1}^{-1} \mathbf{A} \boldsymbol{\mu}_{n-1}\right) &=\mathbf{M} \mathbf{C}^{\mathrm{T}} \boldsymbol{\Sigma}^{-1} \mathbf{x}_{n}+\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{A} \boldsymbol{\mu}_{n-1} \\
&=\mathbf{K}_{n} \mathbf{x}_{n}+\mathbf{A} \boldsymbol{\mu}_{n-1}-\mathbf{K}_{n} \mathbf{C A} \boldsymbol{\mu}_{n-1} \\
&=\mathbf{A} \boldsymbol{\mu}_{n-1}+\mathbf{K}_{n}\left(\mathbf{x}_{n}-\mathbf{C A} \boldsymbol{\mu}_{n-1}\right)
\end{aligned}
$$

を得る．これは(13.89)である．

## 演習 13.22

$$
c_{1} \widehat{\alpha}\left(\mathbf{z}_{1}\right)=p\left(\mathbf{z}_{1}\right) p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}\right) \tag{13.93}
$$

を、

$$
p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right)=\mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{Cz}_{n}, \mathbf{\Sigma}\right) \tag{13.76}
$$

$$
p\left(\mathbf{z}_{1}\right)=\mathcal{N}\left(\mathbf{z}_{1} \mid \boldsymbol{\mu}_{0}, \mathbf{P}_{0}\right) \tag{13.77}
$$

の定義と、

$$
p(\mathbf{y})=\mathcal{N}\left(\mathbf{y} \mid \mathbf{A} \boldsymbol{\mu}+\mathbf{b}, \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right) \tag{2.115}
$$

の結果とともに用いて

$$
c_{1}=\mathcal{N}\left(\mathbf{x}_{1} \mid \mathbf{C} \boldsymbol{\mu}_{0}, \mathbf{CP}_{0} \mathbf{C}^{\mathrm{T}}+\mathbf{\Sigma}\right) \tag{13.96}
$$

を導け

----

$(13.57)$の定義からスケーリング係数$c_{1}$は$c_{1} = p(\mathbf{x}_{1})$である。$(13.93)$と比較すれば$\widehat{\alpha}\left(\mathbf{z}_{1}\right) = p(\mathbf{z}_{1}\mid \mathbf{x}_{1})$である。PRMLの上巻P.90の議論を用いれば、$p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}\right)$と$p(\mathbf{z}_{1})$が与えられていればこれらの値を求めることができる。

$$
\begin{aligned}
c_1 = p(\mathbf{x}_{1}) &= p\left(\mathbf{z}_{1}\right) p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}\right) \\
&= \mathcal{N}\left(\mathbf{z}_{1} \mid \boldsymbol{\mu}_{0}, \mathbf{P}_{0}\right) \mathcal{N}\left(\mathbf{x}_{1} \mid \mathbf{Cz}_{1}, \mathbf{\Sigma}\right) \\
&=\mathcal{N}\left(\mathbf{x}_{1} \mid \mathbf{C} \boldsymbol{\mu}_{0}, \mathbf{CP}_{0} \mathbf{C}^{\mathrm{T}}+\mathbf{\Sigma}\right)
\end{aligned}
$$

## 演習 13.23

$$
c_{1} \widehat{\alpha}\left(\mathbf{z}_{1}\right)=p\left(\mathbf{z}_{1}\right) p\left(\mathbf{x}_{1} \mid \mathbf{z}_{1}\right) \tag{13.93}
$$

を、

$$
p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right)=\mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{Cz}_{n}, \mathbf{\mathbf{\Sigma}}\right) \tag{13.76}
$$

$$
p\left(\mathbf{z}_{1}\right)=\mathcal{N}\left(\mathbf{z}_{1} \mid \boldsymbol{\mu}_{0}, \mathbf{P}_{0}\right) \tag{13.77}
$$

の定義と、

$$
p(\mathbf{x} \mid \mathbf{y})=\mathcal{N}\left(\mathbf{x} \mid \mathbf{\mathbf{\Sigma}}\left\{\mathbf{A}^{\mathrm{T}} \mathbf{L}(\mathbf{y}-\mathbf{b})+\mathbf{\Lambda} \boldsymbol{\mu}\right\}, \mathbf{\mathbf{\Sigma}}\right) \tag{2.116}
$$

の結果とともに用いて、

$$
\boldsymbol{\mu}_{1} =\boldsymbol{\mu}_{0}+\mathbf{K}_{1}\left(\mathbf{x}_{1}-\mathbf{C} \boldsymbol{\mu}_{0}\right) \tag{13.94}
$$

$$
\mathbf{V}_{1} =\left(\mathbf{I}-\mathbf{K}_{1} \mathbf{C}\right) \mathbf{P}_{0} \tag{13.95}
$$

$$
\mathbf{K}_{1} =\mathbf{P}_{0} \mathbf{C}^{\mathrm{T}}\left(\mathbf{CP}_{0} \mathbf{C}^{\mathrm{T}}+\mathbf{\mathbf{\Sigma}}\right)^{-1} \tag{13.97}
$$

を導け.

----

力技の計算問題。

$\widehat{\alpha}\left(\mathbf{z}_{1}\right)=p(\mathbf{z}_{1}\mid\mathbf{x}_{1})=\mathcal{N}(\mathbf{z}_{1}\mid \boldsymbol{\mu}_{1},\mathbf{V}_{1})$を$(2.116)$の公式と$(C.7)$を用いて求める。

$$
p\left(\mathbf{z}_{1} \mid \mathbf{x}_{1}\right)=\mathcal{N}\left(\mathbf{z}_{1} \mid\left(\mathbf{P}_{0}^{-1}+\mathbf{C}^{\mathrm T} \mathbf{\Sigma}^{-1} \mathbf{C}\right)^{-1}\left\{\mathbf{C}^{\mathrm T} \mathbf{\Sigma}^{-1} \mathbf{x}_{1}+\mathbf{P}_{0}^{-1} \boldsymbol{\mu}_{0}\right\}, \left(\mathbf{P}_{0}^{-1}+\mathbf{C}^{\mathrm T} \mathbf{\Sigma}^{-1} \mathbf{C}\right)^{-1}\right)
$$

これより

$$
\begin{aligned}
\mathbf{V}_{1} &=\left(\mathbf{P}_{0}^{-1}+\mathbf{C}^{\mathrm{T}} \mathbf{\Sigma}^{-1} \mathbf{C}\right)^{-1} \\
&=\mathbf{P}_{0}-\mathbf{P}_{0} \mathbf{C}^{\mathrm{T}}\left(\mathbf{\Sigma}+\mathbf{C P}_{0} \mathbf{C}^{\mathrm{T}}\right)^{-1} \mathbf{C P}_{0} \\
&=\left(\mathbf{I}-\mathbf{K}_{1} \mathbf{C}\right) \mathbf{P}_{0}
\end{aligned}
$$

また、今求めた$\mathbf{V}_{1}$を用いて、

$$
\begin{aligned}
\boldsymbol{\mu}_{1} &=\mathbf{V}_{1}\left(\mathbf{C}^{\mathrm T} \mathbf{\Sigma}^{-1} \mathbf{x}_{1}+\mathbf{P}_{0}^{-1} \boldsymbol{\mu}_{0}\right) \\
&=\left(\mathbf{I}-\mathbf{K}_{1} \mathbf{C}\right) \mathbf{P}_{0}\left(\mathbf{C}^{\mathrm T} \mathbf{\Sigma}^{-1} \mathbf{x}_{1}+\mathbf{P}_{0}^{-1} \boldsymbol{\mu}_{0}\right) \\
&=\boldsymbol{\mu}_{0}-\mathbf{K}_{1} \mathbf{C} \boldsymbol{\mu}_{0}+\mathbf{V}_{1} \mathbf{C}^{\mathrm T} \mathbf{\Sigma}^{-1} \mathbf{x}_{1} \\
&=\boldsymbol{\mu}_{0}+\mathbf{K}_{1}\left(\mathbf{x}_{1}-\mathbf{C} \boldsymbol{\mu}_{0}\right)
\end{aligned}
$$

この変形での$\mathbf{V}_{1} \mathbf{C}^{\mathrm T} \mathbf{\Sigma}^{-1}$部分は

$$
\begin{aligned} \mathbf{V}_{1} \mathbf{C}^{\mathrm{T}} \mathbf{\Sigma}^{-1}=& \mathbf{P}_{0} \mathbf{C}^{\mathrm{T}} \mathbf{\Sigma}^{-1}-\mathbf{K}_{1} \mathbf{C} \mathbf{P}_{0} \mathbf{C}^{\mathrm{T}} \mathbf{\Sigma}^{-1} \\=& \mathbf{P}_{0} \mathbf{C}^{\mathrm{T}}\left(\mathbf{I}-\left(\mathbf{\Sigma}+\mathbf{C P}_{0} \mathbf{C}^{\mathrm{T}}\right)^{-1} \mathbf{C P}_{0} \mathbf{C}^{\mathrm{T}}\right) \mathbf{\Sigma}^{-1} \\
=& \mathbf{P}_{0} \mathbf{C}^{\mathrm T}\left(\left(\mathbf{\Sigma}+\mathbf{CP}_{0} \mathbf{C}^{\mathrm T}\right)^{-1}\left(\mathbf{\Sigma}+\mathbf{CP}_{0} \mathbf{C}^{\mathrm T}\right)-\left(\mathbf{\Sigma}+\mathbf{CP}_{0} \mathbf{C}^{\mathrm T}\right)^{-1} \mathbf{CP}_{0} \mathbf{C}^{\mathrm T}\right) \mathbf{\Sigma}^{-1}
\\
=& \mathbf{P}_{0} \mathbf{C}^{\mathrm T}\left( \left(\mathbf{\Sigma}+\mathbf{CP}_{0} \mathbf{C}^{\mathrm T}\right)^{-1} \mathbf{\Sigma} \right) \mathbf{\Sigma}^{-1} \\
=& \mathbf{P}_{0} \mathbf{C}^{\mathrm{T}}\left(\mathbf{\Sigma}+\mathbf{C P}_{0} \mathbf{C}^{\mathrm{T}}\right)^{-1}=\mathbf{K}_{1} \end{aligned}
$$

となることを利用した。

## 演習 13.24

以下の式で表されるようなガウス平均の定数$\mathbf{a}$と$\mathbf{c}$を含んだ、

$$
p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)=\mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A z}_{n-1}, \mathbf{\Gamma}\right) \tag{13.75}
$$

$$
p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right)=\mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{Cz}_{n}, \mathbf{\mathbf{\Sigma}}\right) \tag{13.76}
$$

の一般化について考える.

$$
p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) =\mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \mathbf{z}_{n-1}+\mathbf{a}, \boldsymbol{\Gamma}\right) \tag{13.127}
$$

$$
p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) =\mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{C} \mathbf{z}_{n}+\mathbf{c}, \mathbf{\Sigma}\right) \tag{13.128}
$$

1に固定された付加的な項をもつ状態ベクトル$\mathbf{z}$を定義して、パラメータ$\mathbf{a}$と$\mathbf{c}$に対応した列を行列$\mathbf{A}$と$\mathbf{C}$に付け加えることにより、この拡張された式がこの章で議論した枠組みの中で説明できることを示せ。

----

$$
\boldsymbol{\mu}_{0}^{\prime}=\left[\begin{array}{c}\boldsymbol{\mu}_{0} \\ 1\end{array}\right] \quad \mathbf{V}_{0}^{\prime}=\left[\begin{array}{ll}\mathbf{V}_{0} & \mathbf{0} \\ \mathbf{0} & 0\end{array}\right] \quad \boldsymbol{\Gamma}^{\prime}=\left[\begin{array}{ll}\mathbf{\Gamma} & \mathbf{0} \\ \mathbf{0} & 0\end{array}\right]
$$

$$
\mathbf{A}^{\prime}=\left[\begin{array}{ll}\mathbf{A} & \mathbf{a} \\ \mathbf{0} & 1\end{array}\right] \quad \mathbf{C}^{\prime}=\left[\begin{array}{ll}\mathbf{C} & \mathbf{c}\end{array}\right]
$$

に、各変数を置き換えると、1に固定された$\mathbf{z_n}$の付加項によって(13.127), (13.128)が実現できる。
このようにしてほとんどの枠組みが実現できるが、$\mathbf{z_n}$の付加項が分散0であるという事実が、分散の逆行列を考慮する場合にのみ効いてきて(式13.92など)、正しくは

$$
\left(\mathbf{P}_{n-1}^{\prime}\right)^{-1}=\left[\begin{array}{cc}\mathbf{P}_{n-1}^{-1} & \mathbf{0} \\ \mathbf{0} & 0\end{array}\right]
$$

のようにする必要がある。

## 演習 13.25

この演習問題では、カルマンフィル夕方程式が独立の観測に対し用いられたときに、それらが2.3節で与えた単一ガウス分布の最尤推定法の結果に帰着することを示そう。独立の観測値の集合$\left\{x_{1}, \ldots, x_{N}\right\}$が与えられたときに、単ーガウス分布に従う確率変数$x$の平均$\mu$を求める問題を考える。これをモデル化するために、

$$
p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)=\mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A z}_{n-1}, \mathbf{\Gamma}\right) \tag{13.75}
$$

$$
p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right)=\mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{Cz}_{n}, \mathbf{\Sigma}\right) \tag{13.76}
$$

で支配される線形動的システムを使うことができる。ここで、潜在変数$\left\{z_{1}, \ldots, z_{N}\right\}$において、各々の観測が互いに独立なため、<s>Cは単位行列であり、遷移確率A=0</s>$\mathbf{C}=1,\mathbf{A}=1,\mathbf{\Gamma}=0$となる。最初の状態のパラメータ$\boldsymbol{\mu}_{0}, \mathbf{P}_{0}$を、それぞれ$\mu_0, \sigma_{0}^2$と書くことにし、$\mathbf{\Sigma}$は$\sigma^2$になると考える。対応するカルマンフィル夕方程式を、一般的な結果

$$
\boldsymbol{\mu}_{n} =\mathbf{A} \boldsymbol{\mu}_{n-1}+\mathbf{K}_{n}\left(\mathbf{x}_{n}-\mathbf{C A} \boldsymbol{\mu}_{n-1}\right) \tag{13.89}
$$

$$
\mathbf{V}_{n} =\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{P}_{n-1} \tag{13.90}
$$

から出発し、

$$
\boldsymbol{\mu}_{1} =\boldsymbol{\mu}_{0}+\mathbf{K}_{1}\left(\mathbf{x}_{1}-\mathbf{C} \boldsymbol{\mu}_{0}\right) \tag{13.94}
$$

$$
\mathbf{V}_{1} =\left(\mathbf{I}-\mathbf{K}_{1} \mathbf{C}\right) \mathbf{P}_{0} \tag{13.95}
$$

を用いて書き下せ。さらに、これが直接独立なデータを考えたときに得られる結果

$$
\mu_{N} =\frac{\sigma^{2}}{N \sigma_{0}^{2}+\sigma^{2}} \mu_{0}+\frac{N \sigma_{0}^{2}}{N \sigma_{0}^{2}+\sigma^{2}} \mu_{\mathrm{ML}} \tag{2.141}
$$

$$
\frac{1}{\sigma_{N}^{2}} =\frac{1}{\sigma_{0}^{2}}+\frac{N}{\sigma^{2}}  \tag{2.142}
$$
と同一であることを示せ。

----

※ 問題文は誤っており、前提条件として$\mathbf{C}=1,\mathbf{A}=1,\mathbf{\Gamma}=0$となる。この上で問題を解く。

まず$\boldsymbol{\mu}_{1}$と$\mathbf{V}_{1}$を求める。初期パラメータは$\boldsymbol{\mu}_{0} = \mu_{0}$と$\mathbf{P}_{0} = \sigma_{0}^{2}$, $\mathbf{\Sigma} = \sigma^2$なので、$(13.97)$式は

$$
K_{1}=\sigma_{0}^{2}\left(\sigma_{0}^{2}+\sigma^{2}\right)^{-1}=\frac{\sigma_{0}^{2}}{\sigma_{0}^{2}+\sigma^{2}}
$$

となり、これを用いて$(13.94)(13.95)$の$\mu_{1}, \mathbf{V}_{1}$を求めると、

$$
\begin{aligned}
\boldsymbol{\mu}_{1} &=\mu_{0}+\frac{\sigma_{0}^{2}}{\sigma_{0}^{2}+\sigma^{2}}\left(x_{1}-\mu_{0}\right) \\
&=\frac{1}{\sigma_{0}^{2}+\sigma^{2}}\left(\sigma_{0}^{2} x_{1}+\sigma^{2} \mu_{0}\right)
\end{aligned}\tag{A}
$$

$$
\begin{aligned}
\mathbf{V}_{1} &=\left(1-\frac{\sigma_{0}^{2}}{\sigma_{0}^{2}+\sigma^{2}}\right) \sigma_{0}^{2} \\
&=\frac{\sigma_{0}^{2} \sigma^{2}}{\sigma_{0}^{2}+\sigma^{2}}
\end{aligned}\tag{B}
$$

となる。これらの結果を、まず$N=1$のときの$(2.141),(2.142)$式と比較する。$(2.143)$式で$\mu_{\textrm{ML}}$はサンプル平均$\displaystyle \mu_{\textrm{ML}}=\frac{1}{N} \sum_{n=1}^{N} x_{n}$と定義されていることに注意して

$$
\begin{aligned}
\mu_{1} &=\frac{\sigma^{2}}{\sigma_{0}^{2}+\sigma^{2}} \mu_{0}+\frac{\sigma_{0}^{2}}{\sigma_{0}^{2}+\sigma^{2}} x_{1} \\
&=\frac{1}{\sigma_{0}^{2}+\sigma^{2}}\left(\sigma_{0}^{2} x_{1}+\sigma^{2} \mu_{0}\right) \\
\sigma_{1}^{2} &=1 /\left(\frac{1}{\sigma_{0}^{2}}+\frac{1}{\sigma^{2}}\right)=\frac{\sigma_{0}^{2} \sigma^{2}}{\sigma_{0}^{2}+\sigma^{2}}
\end{aligned}
$$

より、$\boldsymbol{\mu}_{1} = \mu_{1}$、$\mathbf{V}_{1} = \sigma_{1}^{2}$とすると同じであることがわかる。

そこで、誘導に従って任意の正の整数$N$について$\boldsymbol{\mu}_{N} = \mu_{N}$、$\mathbf{V}_{N} = \sigma_{N}^{2}$が成立していると仮定する。ここで$\mu_{N}$と$\sigma_{N}^{2}$は$(2.141)(2.142)$の式である。数学的帰納法の考えに基づいて、$N+1$のときについて調べると、まず$(13.88)$式の定義から

$$
\begin{aligned}
\mathbf{P}_{N}&=\mathbf{AV}_{N} \mathbf{A}^{\mathrm{T}}+\mathbf{\Gamma} \\
&=\mathbf{V}_{N} = \sigma_{N}^{2}\\
\end{aligned}
$$

が成り立つことに注意して、カルマン利得行列の定義$(13.92)$から

$$
\begin{aligned}
\mathbf{K}_{N+1}&=\mathbf{P}_{N} \mathbf{C}^{\mathrm{T}}\left(\mathbf{CP}_{N} \mathbf{C}^{\mathrm{T}}+\mathbf{\Sigma}\right)^{-1} \\
&=\mathbf{P}_{N}(\mathbf{P}_{N} + \sigma^2)^{-1} \\
&=\frac{\sigma_{N}^{2}}{\sigma_{N}^{2} + \sigma^{2}}
\end{aligned}
$$

となるので、$(13.90)$に代入して$\mathbf{V}_{N+1}$を計算すると

$$
\begin{aligned}
\mathbf{V}_{N+1}&=\left(1-\frac{\sigma_{N}^{2}}{\sigma_{N}^{2}+\sigma^{2}}\right) \sigma_{N}^{2} \\
&=\frac{\sigma^{2} \sigma_{N}^{2}}{\sigma_{N}^{2}+\sigma^{2}} \\
&=\left(\frac{1}{\sigma_{N}^{2}}+\frac{1}{\sigma^{2}}\right)^{-1} \\
&=\left(\frac{1}{\sigma_{0}{ }^{2}}+\frac{N+1}{\sigma^{2}}\right)^{-1} \\
&=\frac{\sigma_{0}{ }^{2} \sigma^{2}}{(N+1) \sigma_{0}{ }^{2}+\sigma^{2}} \\
&=\sigma_{N+1}^{2}
\end{aligned}
$$

また$(13.89)$式への代入から

$$
\begin{aligned}
\boldsymbol{\mu}_{N+1} &=\mu_{N}+\frac{\sigma_{N}^{2}}{\sigma_{N}^{2}+\sigma^{2}}\left(x_{N+1}-\mu_{N}\right) \\
&=\frac{1}{\sigma_{N}^{2}+\sigma^{2}}\left(\sigma_{N}^{2} x_{N+1}+\sigma^{2} \mu_{N}\right) \\
&=\frac{\sigma_{N}^{2}}{\sigma_{N}^{2}+\sigma^{2}}\left(x_{N+1}+\frac{\sigma^{2}}{\sigma_{N}^{2}} \frac{\sigma^{2} \mu_{0}+\sigma_{0}^{2} \sum_{n=1}^{N} x_{n}}{N \sigma_{0}^{2}+\sigma^{2}}\right) \\
&=\frac{\sigma_{0}^{2}}{(N+1) \sigma_{0}^{2}+\sigma^{2}}\left(x_{N+1}+\frac{\sigma^{2}}{\sigma_{0}^{2}} \mu_{0}+\sum_{n=1}^{N} x_{n}\right) \quad (\because \mathbf{V}_{N+1} = \sigma_{N=1}^{2}の途中の式変形 )\\
&=\frac{\sigma^{2} \mu_{0}+(N+1) \sum_{n=1}^{N+1} x_{n}}{(N+1) \sigma_{0}^{2}+\sigma^{2}} \\
&=\mu_{N+1}
\end{aligned}
$$

が得られる。したがって、独立同分布の$N$個の1次元観測値$\left\{x_{1}, \ldots, x_{N}\right\}$が得られている場合のカルマンフィルタ方程式は、$(2.141),(2.142)$式と同型になることが示された。

## 演習 13.26

13.3節の線形動的システムの特別な例について考える。この例は、確率的PCAと等価なものであり、したがって、遷移行列は$\mathbf{A}=\mathbf{0}$、共分散は$\mathbf{\Gamma}=\mathbf{I}$、ノイズの共分散は$\mathbf{\Sigma}=\sigma^2\mathbf{I}$である。行列の恒等式

$$
\left(\mathbf{A}+\mathbf{B D}^{-1} \mathbf{C}\right)^{-1}=\mathbf{A}^{-1}-\mathbf{A}^{-1} \mathbf{B}\left(\mathbf{D}+\mathbf{C A}^{-1} \mathbf{B}\right)^{-1} \mathbf{C A}^{-1} \tag{C.7}
$$

を用いることにより、出力密度行列$\mathbf{C}$を$\mathbf{W}$と書くとき、

$$
\mu_{n} =\mathbf{A} \mu_{n-1}+\mathbf{K}_{n}\left(\mathbf{x}_{n}-\mathbf{C A} \mu_{n-1}\right) \tag{13.89}
$$

$$
\mathbf{V}_{n} =\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{P}_{n-1} \tag{13.90}
$$

で定義される隠れ状態の事後確率が、

$$
p(\mathbf{z} \mid \mathbf{x})=\mathcal{N}\left(\mathbf{z} \mid \mathbf{M}^{-1} \mathbf{W}^{\mathrm{T}}(\mathbf{x}-\boldsymbol{\mu}), \sigma^{2} \mathbf{M}^{-1}\right) \tag{12.42}
$$

で$\boldsymbol{\mu}=\mathbf{0}$の仮定の下での確率的PCAのときの結果$(12.42)$と同じになることを示せ.

----

(13.88)式〜(13.92)式に$\mathbf{A}=\mathbf{O}$、$\mathbf{\Gamma}=\mathbf{I}$、$\mathbf{\Sigma}=\sigma^2\mathbf{I}$、$\mathbf{C}=\mathbf{W}$を代入して、

$$
\begin{aligned}
\mathbf{P}_{n-1}
&= \mathbf{A}\mathbf{V}_{n-1}\mathbf{A}^{\rm T}+\boldsymbol\Gamma \\
&= \mathbf{I}
\end{aligned}\tag{13.88}
$$

$$
\begin{aligned}
\mathbf{K}_n
&= \mathbf{P}_{n-1}\mathbf{C}^{\rm T}(\mathbf{CP}_{n-1}\mathbf{C}^{\rm T}+\boldsymbol\Sigma)^{-1} \\
&= \mathbf{W}^{\rm T} (\mathbf{W}\mathbf{W}^{\rm T}+\sigma^2 \mathbf{I})^{-1}
\end{aligned}\tag{13.92}
$$

$$
\begin{aligned}
\mu_{n}
&=\mathbf{A} \mu_{n-1}+\mathbf{K}_{n}\left(\mathbf{x}_{n}-\mathbf{C A} \mu_{n-1}\right)\quad (13.89) \\
&= \mathbf{W}^{\rm T} (\mathbf{W}\mathbf{W}^{\rm T}+\sigma^2 \mathbf{I})^{-1}\mathbf{x}_{n}\\
&= \frac{1}{\sigma^2}\mathbf{W}^{\rm T} (\mathbf{I}+\frac{1}{\sigma^2} \mathbf{W}\mathbf{W}^{\rm T})^{-1}\mathbf{x}_{n}\\
&= \frac{1}{\sigma^2} (\mathbf{I}+ \mathbf{W}^{\rm T}\frac{1}{\sigma^2}\mathbf{W})^{-1}\mathbf{W}^{\rm T}\mathbf{x}_{n}\ \ \ \because {\rm (C.6)の恒等式}(\mathbf{I+AB)^{-1}A=A(I+BA)^{-1}}\\
&= (\sigma^2\mathbf{I}+ \mathbf{W}^{\rm T}\mathbf{W})^{-1}\mathbf{W}^{\rm T}\mathbf{x}_{n} \\
&= \mathbf{M}^{-1}\mathbf{W}^{\rm T}\mathbf{x}_{n}
\end{aligned}
$$

$$
\begin{aligned}
\mathbf{V}_{n}
&=\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{P}_{n-1} \quad (13.90) \\
&= \mathbf{I}-\{ \mathbf{W}^{\rm T} (\mathbf{W}\mathbf{W}^{\rm T}+\sigma^2 \mathbf{I})^{-1}\}\mathbf{W}\\
&= \left[ \mathbf{I}- \left( -\mathbf{W}^{\rm T}\right) \left\{ \mathbf{W}\mathbf{W}^{\rm T}+\sigma^2\mathbf{I} + \mathbf{W}\left(-\mathbf{W}^{\rm T}\right) \right\}^{-1} \mathbf{W} \right] ^{-1}\ \ \ \because {\rm (C.7)の恒等式}\left(\mathbf{A}+\mathbf{B D}^{-1} \mathbf{C}\right)^{-1}=\mathbf{A}^{-1}-\mathbf{A}^{-1} \mathbf{B}\left(\mathbf{D}+\mathbf{C A}^{-1} \mathbf{B}\right)^{-1} \mathbf{C A}^{-1} \\
&= \left( \mathbf{I} + \mathbf{W}^{\rm T} (\sigma^2)^{-1} \mathbf{W} \right)^{-1}\\
&= \sigma^2 \left( \sigma^2 \mathbf{I} + \mathbf{W}^{\rm T} \mathbf{W} \right)^{-1}\\
&= \sigma^2 \mathbf{M}^{-1}
\end{aligned}
$$

ここで求めた$\mu_n$と$\mathbf{V}_n$は、(12.42)式にて$\mu=\mathbf{0}$とした場合の結果に一致する。
なお、$\mathbf{V}_n$の式変形でWoodburyの公式を適用するときの対応関係は、$\mathbf{A}=\mathbf{I}, \ \mathbf{B}=-\mathbf{W}^{\rm T},\  \mathbf{C}=\mathbf{W}, \ \mathbf{D}=\mathbf{WW}^{\rm T}+\sigma^2\mathbf{I}$である。

## 演習 13.27

13.3節で議論した形式をもつ、ある線形動的システムについて考察する。このシステムは観測されるノイズの大きさが0であり、したがって$\mathbf{\Sigma}=\mathbf{0}$である。$\mathbf{C}=\mathbf{I}$のとき、$\mathbf{z}_{n}$の事後分布は、平均が$\mathbf{x}_{n}$となり、分散が0となることを示せ。これは、もしノイズがなければ、過去のすべての観測を無視して現在の観測値$\mathbf{x}_{n}$を用いて状態変数$\mathbf{z}_{n}$を推定すればよいという我々の直感とつじつまが合う.

----

$\mathbf{z}_n$の事後分布は$\widehat{\alpha}\left(\mathbf{z}_{n}\right)=\mathcal{N}\left(\mathbf{z}_{n} \mid \mu_{n}, \mathbf{V}_{n}\right)$で表されるので，

$$
\mu_{n} =\mathbf{A} \mu_{n-1}+\mathbf{K}_{n}\left(\mathbf{x}_{n}-\mathbf{C A} \boldsymbol{\mu}_{n-1}\right)\tag{13.89}
$$

$$
\mathbf{V}_{n} =\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{P}_{n-1}\tag{13.90}
$$

$$
\mathbf{K}_{n}=\mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}\left(\mathbf{C P}_{n-1} \mathbf{C}^{\mathrm{T}}+\mathbf{\Sigma}\right)^{-1}\tag{13.92}
$$

に$\mathbf{\Sigma}=\mathbf{0}, \mathbf{C}=\mathbf{I}$を代入する．その結果$\mathbf{K}_n=\mathbf{I},\mathbf{V}_n=\mathbf{0},\mu_n=\mathbf{x}_n$が得られ，$\mathbf{z}_{n}$の事後分布は、平均が$\mathbf{x}_{n}$となることがわかる．

## 演習 13.28

13.3節の線形動的システムの特別な例について考える.この例では、状態変数$\mathbf{z}_n$は前の状態の状態変数と等しくなるよう制約されており、したがって、$\mathbf{A}=\mathbf{I}$であり、$\mathbf{\Gamma}=\mathbf{0}$である。簡単のために、さらに$\mathbf{C}=\mathbf{I}$と$\mathbf{P}_{0}\to \infty$を仮定する。この仮定により$\mathbf{z}$の初期条件は重要ではなくなり、予測値はデータのみから決定される。帰納法による証明を用いて、状態$\mathbf{z}_{n}$の事後平均が、$\mathbf{x}_{1},\ldots,\mathbf{x}_{n}$の平均で与えられることを示せ。このことは、もし状態変数が一定なら、最も良い推定値は観測値を平均することにより得られるという直感と一致する。

----

数学的帰納法により証明する．まず$n=1$のとき$(13.75)$,$(13.77)$についてガウス分布の条件付き分布に対する一般的な性質$(2.113)-(2.117)$を適用し$\mathbf{P}_0\rightarrow\infty, \mathbf{C}=\mathbf{I}$を用いると

$$
p\left(\mathbf{z}_{1} \mid \mathbf{x}_{1}\right)=\mathcal{N}\left(\mathbf{z}_{1} \mid \boldsymbol{\mu}_{1}, \mathbf{V}_{1}\right)
$$

が得られる．ただし

$$
\begin{aligned}
\boldsymbol{\mu}_{1} &=\mathbf{V}_{1}\left(\mathbf{C}^{\mathrm{T}} \boldsymbol{\Sigma}^{-1} \mathbf{x}_{1}+\mathbf{P}_{0}^{-1} \boldsymbol{\mu}_{0}\right)=\mathbf{x}_{1} \\
\mathbf{V}_{1} &=\left(\mathbf{P}_{0}^{-1}+\mathbf{C}^{\mathrm{T}} \boldsymbol{\Sigma}^{-1} \mathbf{C}\right)^{-1}=\boldsymbol{\Sigma}
\end{aligned}
$$

である．

いま$N$のとき

$$
\begin{aligned}
\boldsymbol{\mu}_{N} &=\overline{\mathbf{x}}_{N}=\frac{1}{N} \sum_{n=1}^{N} \mathbf{x}_{n} \\
\mathbf{V}_{N} &=\frac{1}{N} \boldsymbol{\Sigma}
\end{aligned}
$$

が成り立つと仮定する．また

$$
\mathbf{P}_{n-1}=\mathbf{A} \mathbf{V}_{n-1} \mathbf{A}^{\mathrm{T}}+\Gamma\tag{13.88}
$$

から$\mathbf{P}_{N}=\mathbf{V}_{N}=\frac{1}{N} \Sigma$が成り立つ．

$\mathbf{C}=\mathbf{I}, \mathbf{\Gamma}=\mathbf{0}$と

$$
\mathbf{K}_{n}=\mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}\left(\mathbf{C P}_{n-1} \mathbf{C}^{\mathrm{T}}+\boldsymbol{\Sigma}\right)^{-1}\tag{13.92}
$$

を用いて$N+1$のとき

$$
\begin{aligned}
\mathbf{K}_{N+1} &=\mathbf{P}_{N} \mathbf{C}^{\mathrm{T}}\left(\mathbf{C P}_{N} \mathbf{C}^{\mathrm{T}}+\boldsymbol{\Sigma}\right)^{-1} \\
&=\mathbf{P}_{N}\left(\mathbf{P}_{N}+\boldsymbol{\Sigma}\right)^{-1} \\
&=\frac{1}{N} \boldsymbol{\Sigma}\left(\frac{1}{N} \boldsymbol{\Sigma}+\boldsymbol{\Sigma}\right)^{-1} \\
&=\frac{1}{N} \boldsymbol{\Sigma}\left(\frac{N+1}{N} \boldsymbol{\Sigma}\right)^{-1} \\
&=\frac{1}{N+1} \mathbf{I}
\end{aligned}
$$

この結果を(13.89)と(13.90)に代入して

$$
\begin{aligned}
\boldsymbol{\mu}_{N+1} &=\mathbf{A} \mu_{N}+\mathbf{K}_{N＋1}\left(\mathbf{x}_{N＋1}-\mathbf{C A} \mu_{N}\right) \\
&=\boldsymbol{\mu}_{N}+\frac{1}{N+1}\left(\mathbf{x}_{N+1}-\boldsymbol{\mu}_{N}\right) \\
&=\overline{\mathbf{x}}_{N}+\frac{1}{N+1}\left(\mathbf{x}_{N+1}-\overline{\mathbf{x}}_{N}\right) \\
&=\frac{1}{N+1} \mathbf{x}_{N+1}+\left(1-\frac{1}{N+1}\right) \frac{1}{N} \sum_{n=1}^{N} \\
&=\frac{1}{N+1} \sum_{n=1}^{N+1} \mathbf{x}_{n}=\overline{\mathbf{x}}_{N+1} \\
\mathbf{V}_{N+1} &=\left(\mathbf{I}-\mathbf{K}_{N+1} \mathbf{C}\right) \mathbf{P}_{N} \\
&=\left(\mathbf{I}-\frac{1}{N+1} \mathbf{I}\right) \frac{1}{N} \boldsymbol{\Sigma} \\
&=\frac{1}{N+1} \boldsymbol{\Sigma}
\end{aligned}
$$

が成り立つ．
以上から$N+1$の場合でも$N$と同様の形式でかけるため全ての$N\geq 1$に対して成り立つ．

## 演習 13.29

ガウシアン線形動的システムにおいて、バックワード再帰式

$$
c_{n+1} \widehat{\beta}\left(\mathbf{z}_{n}\right)=\int \widehat{\beta}\left(\mathbf{z}_{n+1}\right) p\left(\mathbf{x}_{n+1} \mid \mathbf{z}_{n+1}\right) p\left(\mathbf{z}_{n+1} \mid \mathbf{z}_{n}\right) \mathrm{d} \mathbf{z}_{n+1} \tag{13.99}
$$

から出発して、RTS平滑化方程式

$$
\widehat{\boldsymbol{\mu}}_{n}=\boldsymbol{\mu}_{n}+\mathbf{J}_{n}\left(\widehat{\mu}_{n+1}-\mathbf{A} \mu_{n}\right) \tag{13.100}
$$

$$
\widehat{\mathbf{V}}_{n}=\mathbf{V}_{n}+\mathbf{J}_{n}\left(\widehat{\mathbf{V}}_{n+1}-\mathbf{P}_{n}\right) \mathbf{J}_{n}^{\mathrm{T}} \tag{13.101}
$$

を導け.

----

(13.99)の両辺に$\widehat{\alpha}\left(\mathbf{z}_{n}\right)$をかけて$\gamma\left(\mathbf{z}_{n}\right)=\widehat{\alpha}\left(\mathbf{z}_{n}\right) \widehat{\beta}\left(\mathbf{z}_{n}\right)=\mathcal{N}\left(\mathbf{z}_{n} \mid \widehat{\mu}_{n}, \widehat{\mathbf{V}}_{n}\right)$を用いると

$$
c_{n+1} \mathcal{N}\left(\mathbf{z}_{n} \mid \widehat{\boldsymbol{\mu}}_{n}, \widehat{\mathbf{V}}_{n}\right)=\widehat{\alpha}\left(\mathbf{z}_{n}\right) \int \widehat{\beta}\left(\mathbf{z}_{n+1}\right) p\left(\mathbf{x}_{n+1} \mid \mathbf{z}_{n+1}\right) p\left(\mathbf{z}_{n+1} \mid \mathbf{z}_{n}\right) \mathrm{d} \mathbf{z}_{n+1}\tag{1}
$$

が得られる．また

$$
p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)=\mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A z}_{n-1}, \mathbf{\Gamma}\right) \tag{13.75}
$$

と

$$
\widehat{\alpha}\left(\mathbf{z}_{n}\right)=\mathcal{N}\left(\mathbf{z}_{n} \mid \mu_{n}, \mathbf{V}_{n}\right)\tag{13.84}
$$

について(13.75)と(13.84)の辺々かけた式に対して

(2.113)-(2.117)の議論，

『$\mathbf{x}$ の周辺ガウス分布と, $\mathbf{x}$ が与えられたときの $\mathbf{y}$ の条件付きガウス分布が次式で 与えられたとする.

$$
p(\mathbf{x}) =\mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu}, \boldsymbol{\Lambda}^{-1}\right)\tag{2.113}
$$

$$
p(\mathbf{y} \mid \mathbf{x}) =\mathcal{N}\left(\mathbf{y} \mid \mathbf{A} \mathbf{x}+\mathbf{b}, \mathbf{L}^{-1}\right)\tag{2.114}
$$

$\mathbf{y}$ の周辺分布と , $\mathbf{y}$ が与えられたときの $\mathbf{x}$ の条件付き分布は

$$
p(\mathbf{y}) =\mathcal{N}\left(\mathbf{y} \mid \mathbf{A} \boldsymbol{\mu}+\mathbf{b}, \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right) \tag{2.115}
$$

$$
p(\mathbf{x} \mid \mathbf{y}) =\mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\Sigma}\left\{\mathbf{A}^{\mathrm{T}} \mathbf{L}(\mathbf{y}-\mathbf{b})+\boldsymbol{\Lambda} \boldsymbol{\mu}\right\}, \boldsymbol{\Sigma}\right)\tag{2.116}
$$

で与えられる. ただし,

$$
\Sigma=\left(\Lambda+\mathrm{A}^{\mathrm{T}} \mathbf{L} \mathbf{A}\right)^{-1}\tag{2.117}
$$

である．』を適切に変数の対応をとり，$\mathbf{z}_n,\mathbf{z}_{n+1}$の同時分布について$\mathbf{z}_n$が与えられたときの$\mathbf{z}_{n+1}$と$\mathbf{z}_n$の積で表されていた形式をの同時分布について$\mathbf{z}_{n+1}$が与えられたときの$\mathbf{z}_{n}$と$\mathbf{z}_{n+1}$の積で表されていた形式に書き換えると

$$
\begin{aligned}
\widehat{\alpha}\left(\mathbf{z}_{n}\right) p\left(\mathbf{z}_{n+1} \mid \mathbf{z}_{n}\right) &=\mathcal{N}\left(\mathbf{z}_{n} \mid \boldsymbol{\mu}_{n}, \mathbf{V}_{n}\right) \mathcal{N}\left(\mathbf{z}_{n+1} \mid \mathbf{A} \mathbf{z}_{n}, \boldsymbol{\Gamma}\right) \\
&=\mathcal{N}\left(\mathbf{z}_{n+1} \mid \mathbf{A} \boldsymbol{\mu}_{n}, \mathbf{A} \mathbf{V}_{n} \mathbf{A}+\boldsymbol{\Gamma}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{m}_{n}, \mathbf{M}_{n}\right)
\end{aligned}
$$

が得られる．ここで(2.116)に対応する形で$\mathbf{m}_n$は

$$
\mathbf{m}_{n}=\mathbf{M}_{n}\left(\mathbf{A}^{\mathrm{T}} \boldsymbol{\Gamma}^{-1} \mathbf{z}_{n+1}+\mathbf{V}_{n}^{-1} \boldsymbol{\mu}_{n}\right)\tag{2}
$$

と表される．また(C.7)と(13.102) $\mathbf{J}_{n}=\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}}\left(\mathbf{P}_{n}\right)^{-1}$の定義を用いて

$$
\begin{aligned}
\mathbf{M}_{n} &=\left(\mathbf{A}^{\mathrm{T}} \boldsymbol{\Gamma}^{-1} \mathbf{A}+\mathbf{V}_{n}^{-1}\right)^{-1} \\
&=\mathbf{V}_{n}-\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}}\left(\boldsymbol{\Gamma}+\mathbf{A} \mathbf{V}_{n} \mathbf{A}^{\mathrm{T}}\right)^{-1} \mathbf{A V}_{n} \\
&=\mathbf{V}_{n}-\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}} \mathbf{P}_{n}^{-1} \mathbf{A} \mathbf{V}_{n} \\
&=\left(\mathbf{I}-\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}} \mathbf{P}_{n}^{-1} \mathbf{A}\right) \mathbf{V}_{n} \\
&=\left(\mathbf{I}-\mathbf{J}_{n} \mathbf{A}\right) \mathbf{V}_{n}
\end{aligned}
$$

とかける．

(1)の右辺において$\widehat{\alpha}\left(\mathbf{z}_{n}\right)$を積分の中に含め，$\mathbf{M}_n$についての結果を代入して(13.85)-(13.88)と(13.98)を用いて

$$
\begin{aligned}
c_{n+1} \mathcal{N}\left(\mathbf{z}_{n} \mid \widehat{\boldsymbol{\mu}}_{n}, \widehat{\mathbf{V}}_{n}\right) &=\int \widehat{\beta}\left(\mathbf{z}_{n+1}\right) p\left(\mathbf{x}_{n+1} \mid \mathbf{z}_{n+1}\right) \mathcal{N}\left(\mathbf{z}_{n+1} \mid \mathbf{A} \boldsymbol{\mu}_{n}, \mathbf{P}_{n}\right)
\mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{m}_{n}, \mathbf{M}_{n}\right) \mathrm{d} \mathbf{z}_{n+1} & \\
&=\int \widehat{\beta}\left(\mathbf{z}_{n+1}\right) c_{n+1} \widehat{\alpha}\left(\mathbf{z}_{n+1}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{m}_{n}, \mathbf{M}_{n}\right) \mathrm{d} \mathbf{z}_{n+1} \\
&=c_{n+1} \int \gamma\left(\mathbf{z}_{n+1}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{m}_{n}, \mathbf{M}_{n}\right) \mathrm{d} \mathbf{z}_{n+1} \\
&=c_{n+1} \int \mathcal{N}\left(\mathbf{z}_{n+1} \mid \widehat{\boldsymbol{\mu}}_{n}, \widehat{\mathbf{V}}_{n}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{m}_{n}, \mathbf{M}_{n}\right) \mathrm{d} \mathbf{z}_{n+1} .
\end{aligned}
$$

したがって(2)と(2.113)-(2.115)を使って

$$
\widehat{\boldsymbol{\mu}}_{n} =\mathbf{M}_{n}\left(\mathbf{A}^{\mathrm{T}} \boldsymbol{\Gamma}^{-1} \widehat{\boldsymbol{\mu}}_{n+1}+\mathbf{V}_{n}^{-1} \boldsymbol{\mu}_{n}\right) \tag{3}
$$

$$
\widehat{\mathbf{V}}_{n} =\mathbf{M}_{n} \mathbf{A}^{\mathrm{T}} \boldsymbol{\Gamma}^{-1} \widehat{\mathbf{V}}_{n+1} \boldsymbol{\Gamma}^{-1} \mathbf{A} \mathbf{M}_{n}+\mathbf{M}_{n}\tag{4}
$$

と書くことができる．

また$\mathbf{M}_{n}$についての計算の途中で出てきた

$$
\mathbf{M}_{n}=\mathbf{V}_{n}-\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}} \mathbf{P}_{n}^{-1} \mathbf{A} \mathbf{V}_{n}
$$

と(13.102) $\mathbf{J}_{n}=\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}}\left(\mathbf{P}_{n}\right)^{-1}$を使って

$$
\begin{aligned}
\mathbf{M}_{n} \mathbf{A}^{\mathrm{T}} \boldsymbol{\Gamma}^{-1} &=\left(\mathbf{V}_n-\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}} \mathbf{P}_{n}^{-1} \mathbf{A} \mathbf{V}_{n}\right) \mathbf{A}^{\mathrm{T}} \boldsymbol{\Gamma}^{-1} \\
&=\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}}\left(\mathbf{I}-\mathbf{P}_{n}^{-1} \mathbf{A} \mathbf{V}_{n} \mathbf{A}^{\mathrm{T}}\right) \boldsymbol{\Gamma}^{-1} \\
&=\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}}\left(\mathbf{I}-\mathbf{P}_{n}^{-1} \mathbf{A} \mathbf{V}_{n} \mathbf{A}^{\mathrm{T}}-\mathbf{P}_{n}^{-1} \boldsymbol{\Gamma}+\mathbf{P}_{n}^{-1} \boldsymbol{\Gamma}\right) \boldsymbol{\Gamma}^{-1} \\
&=\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}}\left(\mathbf{I}-\mathbf{P}_{n}^{-1} \mathbf{P}_{n}+\mathbf{P}_{n}^{-1} \boldsymbol{\Gamma}\right) \boldsymbol{\Gamma}^{-1} \\
&=\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}} \mathbf{P}_{n}^{-1}=\mathbf{J}_{n}
\end{aligned}
$$

これらの結果から(3)を(13.100)のように書き換えることができる
また(13.102), $\mathbf{M}_{n}=\mathbf{V}_{n}-\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}} \mathbf{P}_{n}^{-1} \mathbf{A} \mathbf{V}_{n}$ と$\mathbf{M}_{n} \mathbf{A}^{\mathrm{T}} \boldsymbol{\Gamma}^{-1}=\mathbf{J}_{n}$を用いて(4)を

$$
\begin{aligned}
\widehat{\mathbf{V}}_{n} &=\mathbf{M}_{n} \mathbf{A}^{\mathrm{T}} \boldsymbol{\Gamma}^{-1} \widehat{\mathbf{V}}_{n+1} \boldsymbol{\Gamma}^{-1} \mathbf{A} \mathbf{M}_{n}+\mathbf{M}_{n} \\
&=\mathbf{J}_{n} \widehat{\mathbf{V}}_{n+1} \mathbf{J}_{n}^{\mathrm{T}}+\mathbf{V}_{n}-\mathbf{V}_{n} \mathbf{A}^{\mathrm{T}} \mathbf{P}_{n}^{-1} \mathbf{A} \mathbf{V}_{n} \\
&=\mathbf{V}_{n}+\mathbf{J}_{n}\left(\widehat{\mathbf{V}}_{n+1}-\mathbf{P}_{n}\right) \mathbf{J}_{n}^{\mathrm{T}}
\end{aligned}
$$

のようにして$(13.101)$の形に書き直すことができる．

## 演習 13.30

状態空間モデルの2つ組の事後周辺分布の結果

$$
\xi\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)=\left(c_{n}\right)^{-1} \widehat{\alpha}\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \widehat{\beta}\left(\mathbf{z}_{n}\right) \tag{13.65}
$$

から出発して、ガウシアン線形動的システムの場合の特別な形式

$$
\begin{aligned}
\xi\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)&=\left(c_{n}\right)^{-1} \widehat{\alpha}\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \widehat{\beta}\left(\mathbf{z}_{n}\right) \\
&=\frac{\mathcal{N}\left(\mathbf{z}_{n-1} \mid \boldsymbol{\mu}_{n-1}, \mathbf{V}_{n-1}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \mathbf{z}_{n-1}, \mathbf{\Gamma}\right) \mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{C z}_{n}, \mathbf{\Sigma} \right) \mathcal{N}\left(\mathbf{z}_{n} \mid \widehat{\boldsymbol{\mu}}_{n}, \widehat{\mathbf{V}}_{n}\right)}{c_{n} \widehat{\alpha}\left(\mathbf{z}_{n}\right)}
\end{aligned} \tag{13.103}
$$

を導け.

----

$(13.65)$式の導出は演習13.15を参照。
これに

$$
\begin{aligned}
p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) &=\mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \mathbf{z}_{n-1}, \Gamma\right)& (13.75) \\
p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) &=\mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{C} \mathbf{z}_{n}, \mathbf{\Sigma}\right)& (13.76) \\
\widehat{\alpha}\left(\mathbf{z}_{n-1}\right)&=\mathcal{N}\left(\mathbf{z}_{n-1} \mid \boldsymbol{\mu}_{n-1}, \mathbf{V}_{n-1}\right) & (13.84) \\
\gamma\left(\mathbf{z}_{n}\right)&=\widehat{\alpha}\left(\mathbf{z}_{n}\right) \widehat{\beta}\left(\mathbf{z}_{n}\right)=\mathcal{N}\left(\mathbf{z}_{n} \mid \widehat{\boldsymbol{\mu}}_{n}, \widehat{\mathbf{V}}_{n}\right) & (13.98)
\end{aligned}
$$

を組み合わせれば

$$
\xi\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)=\frac{\mathcal{N}\left(\mathbf{z}_{n-1} \mid \boldsymbol{\mu}_{n-1}, \mathbf{V}_{n-1}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \mathbf{z}_{n-1}, \mathbf{\Gamma}\right) \mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{C z}_{n}, \mathbf{\Sigma} \right) \mathcal{N}\left(\mathbf{z}_{n} \mid \widehat{\boldsymbol{\mu}}_{n}, \widehat{\mathbf{V}}_{n}\right)}{c_{n} \widehat{\alpha}\left(\mathbf{z}_{n}\right)} \tag{13.103}
$$

が直接導出される。

## 演習 13.31

$$
\begin{aligned}
\xi\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)&=\left(c_{n}\right)^{-1} \widehat{\alpha}\left(\mathbf{z}_{n-1}\right) p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) \widehat{\beta}\left(\mathbf{z}_{n}\right) \\
&=\frac{\mathcal{N}\left(\mathbf{z}_{n-1} \mid \boldsymbol{\mu}_{n-1}, \mathbf{V}_{n-1}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \mathbf{z}_{n-1}, \mathbf{\Gamma}\right) \mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{C z}_{n}, \mathbf{\Sigma}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \widehat{\mu}_{n}, \widehat{\mathbf{V}}_{n}\right)}{c_{n} \widehat{\alpha}\left(\mathbf{z}_{n}\right)}
\end{aligned} \tag{13.103}
$$

の結果から出発し、

$$
\widehat{\alpha}\left(\mathbf{z}_{n}\right)=\mathcal{N}\left(\mathbf{z}_{n} \mid \boldsymbol{\mu}_{n}, \mathbf{V}_{n}\right) \tag{13.84}
$$

を用いて$\widehat{\alpha}\left(\mathbf{z}_{n}\right)$を置き換えることにより、$\mathbf{z}_{n}$と$\mathbf{z}_{n-1}$の間の共分散の結果

$$
\operatorname{cov}\left[\mathbf{z}_{n-1}, \mathbf{z}_{n}\right]=\mathbf{J}_{n-1} \widehat{\mathbf{V}}_{n} \tag{13.104}
$$

を確かめよ。

----


$(2.115)-(2.117)$を使用すると

$$
\begin{aligned}
& \mathcal{N}\left(\mathbf{z}_{n-1} \mid \boldsymbol{\mu}_{n-1}, \mathbf{V}_{n-1}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \mathbf{z}_{n-1}, \mathbf{\Gamma}\right) \\
=& \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \boldsymbol{\mu}_{n-1}, \mathbf{\Gamma}+\mathbf{A} \mathbf{V}_{n-1} \mathbf{A}^{\mathrm T}\right) \times \mathcal{N}\left(\mathbf{z}_{n-1} \mid \mathbf{Y}\left(\mathbf{A}^{\mathrm T} \mathbf{\Gamma}^{-1} \mathbf{z}_{n}+\mathbf{V}_{n-1}^{-1} \boldsymbol{\mu}_{n-1}\right), \mathbf{Y}\right)
\end{aligned}
$$

となる。ただし、

$$
\begin{aligned}
\mathbf{Y}&=\left(\mathbf{V}_{n-1}^{-1}+\mathbf{A}^{\mathrm{T}} \mathbf{\Gamma}^{-1} \mathbf{A}\right)^{-1} \\
&=\mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \mu_{n-1}, \mathbf{P}_{n-1}\right) \mathcal{N}\left(\mathbf{z}_{n-1} \mid \mathbf{J}_{n-1} \mathbf{z}_{n}+\left(\mathbf{I}-\mathbf{J}_{n-1} \mathbf{A}\right) \mu_{n-1},\left(\mathbf{I}-\mathbf{J}_{n-1} A\right) \mathbf{V}_{n-1}\right)
\end{aligned}
$$

である。上記式展開は(13.88）と

$$
\begin{aligned} \mathbf{Y}&=\left(\mathbf{V}_{n-1}^{-1}+A^{\mathrm{T}
} \Gamma^{-1} A\right)^{-1} \\ &=\mathbf{V}_{n-1}-\mathbf{V}_{n-1} A^{\mathrm{T}
}\left(\Gamma+A \mathbf{V}_{n-1} A^{\mathrm{T}
}\right)^{-1} A \mathbf{V}_{n-1}\quad(C.7) \\
&=\mathbf{V}_{n-1}-\mathbf{V}_{n-1} A^{\mathrm{T}
} \mathbf{P}_{n-1}^{-1} A \mathbf{V}_{n-1}\quad(13.88) \\
&=\mathbf{V}_{n-1}-J_{n-1} A \mathbf{V}_{n-1}\quad(13.102) \\
&=\left(\mathbf{I}-J_{n-1} A\right) \mathbf{V}_{n-1}
\end{aligned}
$$

$$
\begin{aligned}
\mathbf{Y}A^{\mathrm{T}} \Gamma^{-1} &=\left(\mathbf{V}_{n-1}^{-1}+A^{\mathrm{T}} \Gamma^{-1} A\right)^{-1} A^{\mathrm{T}} \Gamma^{-1} \\ &=\mathbf{V}_{n-1} A^{\mathrm{T}}\left(A \mathbf{V}_{n-1} A^{\mathrm{T}}+\Gamma\right)^{-1}\quad(C.5) \\
&=\mathbf{V}_{n-1} A^{\mathrm{T}} \mathbf{P}_{n-1}^{-1}\quad(13.88) \\
&=J_{n-1}\quad(13.102)
\end{aligned}
$$

を使用した。

さらにここで$(2.115)-(2.117)$を使用すると

$$
\begin{aligned}
&\ \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \boldsymbol{\mu}_{n-1}, \mathbf{P}_{n-1}\right) \mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{C} \mathbf{z}_{n}, \mathbf{\Sigma}\right) \\
=&\ \mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{C A \mu _ { n - 1 }}, \mathbf{\Sigma}+\mathbf{C P _ { n - 1 }} \mathbf{C}^{\mathrm T}\right) \times \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{M}\left(\mathbf{C}^{\mathrm T} \mathbf{\Sigma}^{-1} \mathbf{x}_{n}+\mathbf{P}_{n-1}^{-1} \mathbf{A} \boldsymbol{\mu}_{n-1}\right), \mathbf{M}\right)
\end{aligned}
$$

ただし、

$$
\begin{aligned}
\mathbf{M}&=\left(\mathbf{P}_{n-1}^{-1}+\mathbf{C}^{\mathrm{T}} \mathbf{\Sigma}^{-1} \mathbf{C}\right)^{-1} \\
&=c_{n} \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{K}_{n} \mathbf{x}_{n}+\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{P}_{n-1} \mathbf{P}_{n-1}^{-1} \mathbf{A} \mu_{n-1},\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{P}_{n-1}\right)\quad(13.91) \\
&=c_{n} \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \mu_{n-1}+\mathbf{K}_{n}\left(\mathbf{x}_{n}-\mathbf{C A} \mu_{n-1}\right),\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{P}_{n-1}\right) \\
&=c_{n} \mathcal{N}\left(\mathbf{z}_{n} \mid \boldsymbol{\mu}_{n}, \mathbf{V}_{n}\right)\quad(13.89)、（13.90） \\
&=c_{n} \hat{\alpha}\left(\mathbf{z}_{n}\right)
\end{aligned}
$$

上記1行目の式は

$$
\begin{aligned}
\mathbf{M} &=\left(\mathbf{P}_{n-1}^{-1}+\mathbf{C}^{\mathrm{T}} \mathbf{\Sigma}^{-1} \mathbf{C}\right)^{-1} \\ &=\mathbf{P}_{n-1}-\mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}\left(\mathbf{\Sigma}+\mathbf{C} \mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}\right)^{-1} \mathbf{C} \mathbf{P}_{n-1} \quad(C.7) \\
&=\mathbf{P}_{n-1}-\mathbf{K}_{n} \mathbf{C} \mathbf{P}_{n-1}\quad(13.92) \\
&=\left(\mathbf{I}-\mathbf{K}_{n} \mathbf{C}\right) \mathbf{P}_{n-1} \\
\mathbf{M} \mathbf{C}^{\mathrm{T}} \mathbf{\Sigma}^{-1}&=\left(\mathbf{P}_{n-1}^{-1}+\mathbf{C}^{\mathrm{T}} \mathbf{\Sigma}^{-1} \mathbf{C}\right)^{-1} \mathbf{C}^{T} \mathbf{\Sigma}^{-1} \\
&=\mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}\left(\mathbf{C} \mathbf{P}_{n-1} \mathbf{C}^{\mathrm{T}}+\mathbf{\Sigma}\right)^{-1}\quad(C.5) \\
&=\mathbf{K}_{n}\quad(13.92)
\end{aligned}
$$

これらを$(13.103)$に入れると

$$
\begin{aligned}
\xi\left(\mathbf{z}_{n-1}, \mathbf{z}_{n}\right)&=\frac{\mathcal{N}\left(\mathbf{z}_{n-1} \mid \mathbf{J}_{n-1} \mathbf{z}_{n}+\left(\mathbf{\mathbf{I}}-\mathbf{J}_{n-1} \mathbf{A}\right) \boldsymbol{\mu}_{n-1},\left(\mathbf{I}-\mathbf{J}_{n-1} \mathbf{A}\right) \mathbf{V}_{n-1}\right) c_{n} \hat{\alpha}\left(\mathbf{z}_{n}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \widehat{\boldsymbol{\mu}}_{n}, \widehat{\mathbf{V}}_{n}\right)}{c_{n} \hat{\alpha}\left(\mathbf{z}_{n}\right)} \\
&=\mathcal{N}\left(\mathbf{z}_{n-1} \mid \mathbf{J}_{n-1} \mathbf{z}_{n}+\left(\mathbf{\mathbf{I}}-\mathbf{J}_{n-1} \mathbf{A}\right) \boldsymbol{\mu}_{n-1},\left(\mathbf{\mathbf{I}}-\mathbf{J}_{n-1} \mathbf{A}\right) \mathbf{V}_{n-1}\right) \mathcal{N}\left(\mathbf{z}_{n} \mid \widehat{\boldsymbol{\mu}}_{n}, \widehat{\mathbf{V}}_{n}\right)\quad(13.103)^{\prime}
\end{aligned}
$$

を得る。

$(13.103)^{\prime}$の右辺は線形ガウスモデルの周辺分布と条件分布の積になっているので2.3.3節より$\mathbf{z}_{n-1}$と$\mathbf{z}_{n}$の同時分布はガウス分布で$(2.108)$より平均は

$$
\begin{aligned}
\mathbf{E}\left[\left(\begin{array}{c}
\mathbf{z}_{n} \\
\mathbf{z}_{n-1}
\end{array}\right)\right] &=\left(\begin{array}{c}
\widehat{\boldsymbol{\mu}}_{n} \\
\mathbf{J}_{n-1} \widehat{\boldsymbol{\mu}}_{n}+\left(\mathbf{I}-\mathbf{J}_{n-1} \mathbf{A}\right) \boldsymbol{\mu}_{n-1}
\end{array}\right) \\
&=\left(\begin{array}{c}
\widehat{\boldsymbol{\mu}}_{n} \\
\boldsymbol{\mu}_{n-1}+\mathbf{J}_{n-1}\left(\widehat{\boldsymbol{\mu}}_{n}-\mathbf{A} \boldsymbol{\mu}_{n-1}\right)
\end{array}\right) \\
&=\left(\begin{array}{c}
\widehat{\boldsymbol{\mu}}_{n} \\
\widehat{\boldsymbol{\mu}}_{n-1}
\end{array}\right)\quad(13.100)
\end{aligned}
$$

となる。$(2.105)$より$\mathbf{z}_{n-1}$と$\mathbf{z}_{n}$の同時分布の共分散分布は

$$
\operatorname{cov}\left[\left(\begin{array}{l}
\mathbf{z}_{n} \\
\mathbf{z}_{n-1}
\end{array}\right)\right]=\left(\begin{array}{cc}
\widehat{\mathbf{V}}_{n} & \widehat{\mathbf{V}}_{n} \mathbf{J}_{n-1}^{\mathrm T} \\
\mathbf{J}_{n-1} \widehat{\mathbf{V}}_{n} & \left(\mathbf{I}-\mathbf{J}_{n-1} \mathbf{A}\right) \mathbf{V}_{n-1}+\mathbf{J}_{n-1} \widehat{\mathbf{V}}_{n} \mathbf{J}_{n-1}^{\mathrm T}
\end{array}\right)
$$

となる。$(2.78)$より、$\mathbf{z}_{n-1}$と$\mathbf{z}_{n}$の共分散は2行1列の要素になるので

$$
\operatorname{cov}\left[\mathbf{z}_{n-1}, \mathbf{z}_{n}\right]=\mathbf{J}_{n-1} \widehat{\mathbf{V}}_{n}\tag{13.104}
$$

を得る。

## 演習 13.32

線形動的システムにおける$\boldsymbol{\mu}_{0}$と$\mathbf{P}_{0}$に対するMステップの方程式の結果

$$
\boldsymbol{\mu}_{0}^{\text{new}}=\mathbb{E}\left[\mathbf{z}_{1}\right] \tag{13.110}
$$

$$
\mathbf{P}_{0}^{\text{new}}=\mathbb{E}\left[\mathbf{z}_{1} \mathbf{z}_{1}^{\mathrm{T}}\right]-\mathbb{E}\left[\mathbf{z}_{1}\right] \mathbb{E}\left[\mathbf{z}_{1}^{\mathrm{T}}\right] \tag{13.111}
$$
を確かめよ.

----

状態空間モデルの同時分布は

$$
p\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{N}, \mathbf{z}_{1}, \ldots, \mathbf{z}_{N}\right)=p\left(\mathbf{z}_{1}\right)\left[\prod_{n=2}^{N} p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right)\right] \prod_{n=1}^{N} p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) \tag{13.6}
$$

線形動的システム（LDS）を導入すると、$(13.75)(13.76)(13.77)$より

$$
\begin{aligned}
p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}\right) &=\mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A} \mathbf{z}_{n-1}, \mathbf{\Gamma}\right) \\
p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}\right) &=\mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{C} \mathbf{z}_{n}, \mathbf{\Sigma}\right) \\
p\left(\mathbf{z}_{1}\right)&=\mathcal{N}\left(\mathbf{z}_{1} \mid \boldsymbol{\mu}_{0}, \mathbf{P}_{0}\right)
\end{aligned}
$$

となる。P.361より完全データの対数尤度関数は、$(13.6)$の対数をとって

$$
\begin{aligned}
\ln p(\mathbf{X}, \mathbf{Z} \mid \boldsymbol{\theta})=& \ln p\left(\mathbf{z}_{1} \mid \boldsymbol{\mu}_{0}, \mathbf{P}_{0}\right)+\sum_{n=2}^{N} \ln p\left(\mathbf{z}_{n} \mid \mathbf{z}_{n-1}, \mathbf{A}, \mathbf{\Gamma}\right) \\
&+\sum_{n=1}^{N} \ln p\left(\mathbf{x}_{n} \mid \mathbf{z}_{n}, \mathbf{C}, \mathbf{\Sigma}\right)
\end{aligned} \tag{13.108}
$$

次に事後分布について

$$
Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text {old}}\right)=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}[\ln p(\mathbf{X}, \mathbf{Z} \mid \boldsymbol{\theta})] \tag{13.109}
$$

これに代入すると

$$
\begin{aligned}
Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text {old}}\right)&=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\ln \mathcal{N}\left(\mathbf{z}_{1} \mid \boldsymbol{\mu}_{0}, \mathbf{P}_{0}\right)+\sum_{n=2}^{N} \ln \mathcal{N}\left(\mathbf{z}_{n} \mid \mathbf{A}{\mathbf{z}_{n-1}}, \mathbf{\Gamma}\right)+\sum_{n=1}^{N} \ln \mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{Cz}_{n}, \mathbf{\Sigma}\right)\right] \\
&=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[-\frac{1}{2} \ln \left|\mathbf{P}_{0}\right|-\frac{1}{2}\left(\mathbf{z}_{1}-\boldsymbol{\mu}_{0}\right)^{\mathrm T} \mathbf{P}_{0}^{-1}\left(\mathbf{z}_{1}-\boldsymbol{\mu}_{0}\right)\right]+\text { const. }
\end{aligned}
$$

ここで$\boldsymbol{\mu}_{0}$あるいは$\mathbf{P}_{0}$に依存しないすべての項はconst.項に吸収させている。
これを$\boldsymbol{\mu}_{0}$について最大化すると

$$
\begin{aligned}
\frac{\partial Q}{\partial \boldsymbol{\mu}_{0}}&=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[-\frac{1}{2} \cdot-2 \mathbf{P}_{0}^{-1}\left(\mathbf{z}_{1}-\boldsymbol{\mu}_{0}\right)\right]\\
&=\mathbf{P}_{0}^{-1}\left(\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[ \mathbf{z}_{1} \right]-\boldsymbol{\mu}_{0}\right)=0\\
\boldsymbol{\mu}_{0}^{\text {new}}&=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[ \mathbf{z}_{1} \right]
\end{aligned}
$$

$\mathbf{P}_{0}$について最大化すると

$$
\frac{\partial Q}{\partial \mathbf{P}_{0}}=-\frac{1}{2}\left[\mathbf{P}_{0}^{-\mathrm{T}}+\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[-\mathbf{P}_{0}^{-\mathrm{T}}\left(\mathbf{z}_{1}-\boldsymbol{\mu}_{0}\right)\left(\mathbf{z}_{1}-\boldsymbol{\mu}_{0}\right)^{\mathrm{T}} \mathbf{P}_{0}^{-\mathrm{T}}\right]\right] =0
$$

$$
\begin{aligned}
\left(\mathbf{P}^{\textrm{new}}_{0}\right)^{-\mathrm{T}} &=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\left(\mathbf{P}^{\textrm{new}}_{0}\right)^{-\mathrm{T}}\left(\mathbf{z}_{1}-\boldsymbol{\mu}_{0}\right)\left(\mathbf{z}_{1}-\boldsymbol{\mu}_{0}\right)^{\mathrm{T}} \left(\mathbf{P}^{\textrm{new}}_{0}\right)^{-\mathrm{T}}\right] \\
\mathbf{P}^{\textrm{new}}_{0} &=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\left(\mathbf{z}_{1}-\boldsymbol{\mu}_{0}\right)\left(\mathbf{z}_{1}-\boldsymbol{\mu}_{0}\right)^{\mathrm{T}}\right] \\
&=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{1} \mathbf{z}_{1}^{\mathrm{T}}\right]-2 \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{1}\right] \boldsymbol{\mu}_{0}^{\mathrm{T}}+\boldsymbol{\mu}_{0} \boldsymbol{\mu}_{0}^{\mathrm{T}} \\
&=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{1} \mathbf{z}_{1}^{\mathrm{T}}\right]-2 \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{1}\right] \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{1}\right]^{\mathrm{T}}+\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{1}\right] \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{1}\right]^{\mathrm{T}}\\
&=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{1} \mathbf{z}_{1}^{\mathrm{T}}\right]-\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{1}\right] \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{1}\right]^{\mathrm{T}}
\end{aligned}
$$

## 演習 13.33

線形動的システムにおける$\mathbf{A}$と$\mathbf{\Gamma}$に対するMステップの方程式の結果

$$
\mathbf{A}^{\text{new}}=\left(\sum_{n=2}^{N} \mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n-1}^{\mathrm{T}}\right]\right)\left(\sum_{n=2}^{N} \mathbb{E}\left[\mathbf{z}_{n-1} \mathbf{z}_{n-1}^{\mathrm{T}}\right]\right)^{-1} \tag{13.113}
$$

$$
\begin{aligned}
\mathbf{\Gamma}^{\text {new}}=&\frac{1}{N-1} \sum_{n=2}^{N}\left\{\mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n}^{\mathrm{T}}\right]-\mathbf{A}^{\text{new}} \mathbb{E}\left[\mathbf{z}_{n-1} \mathbf{z}_{n}^{\mathrm{T}}\right]\right. \\
& \left. -\ \mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n-1}^{\mathrm{T}}\right]\left(\mathbf{A}^{\text{new}}\right)^{\mathrm{T}}+\mathbf{A}^{\text{new}} \mathbb{E}\left[\mathbf{z}_{n-1} \mathbf{z}_{n-1}^{\mathrm{T}}\right]\left(\mathbf{A}^{\text{new}}\right)^{\mathrm{T}}\right\}
\end{aligned} \tag{13.114}
$$

を確かめよ.

----

演習13.32の$Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text{old}}\right)$のうち、$\mathcal{N}\left(\mathbf{z}_{n} \mid  \mathbf{Az}_{n-1}, \mathbf{\Gamma}\right)$に関係する項のみを抜き出して

$$
\begin{aligned}
Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text{old}}\right) &=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\sum_{n=2}^{N} \ln \mathcal{N}\left(\mathbf{z}_{n} \mid  \mathbf{Az}_{n-1}, \mathbf{\Gamma}\right)\right]+\text{ const.} \\
&=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\sum_{n=2}^{N}\left\{-\frac{1}{2} \ln |\mathbf{\Gamma}|-\frac{1}{2}\left(\mathbf{z}_{n}-\mathbf{Az}_{n-1}\right)^{\mathrm T} \mathbf{\Gamma}^{-1}\left(\mathbf{z}_{n}-\mathbf{Az}_{n-1}\right)\right\}\right]+\text{ const.}
\end{aligned}
$$

$\mathbf{A}$について

$$
\begin{aligned}
\frac{\partial Q}{\partial \mathbf{A}} &=-\frac{1}{2} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\sum_{n=2}^{N} \frac{\partial}{\partial \mathbf{A}}\left[\left(\mathbf{z}_{n}-\mathbf{Az}_{n-1}\right)^{\mathrm T} \mathbf{\Gamma}^{-1}\left(\mathbf{z}_{n}-\mathbf{Az}_{n-1}\right)\right]\right] \\
&=-\frac{1}{2} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\sum_{n=2}^{N}\left(-2 \mathbf{\Gamma}^{-1}\left(\mathbf{z}_{n}-\mathbf{Az}_{n-1}\right) \mathbf{z}_{n-1}^{\mathrm T}\right)\right] \\
&=\sum_{n=2}^{N} \mathbf{\Gamma}^{-1} \mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n-1}^{\mathrm T}\right]-\sum_{n=2}^{N} \mathbf{\Gamma}^{-1} \mathbf{A} \mathbb{E}\left[\mathbf{z}_{n-1} \mathbf{z}_{n-1}^{\mathrm T}\right]
\end{aligned}
$$

最大化するために$\frac{\partial Q}{\partial \mathbf{A}} =0$として

$$
\sum_{n=2}^{N} \mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n-1}^{\mathrm T}\right] = \sum_{n=2}^{N} \mathbf{A}^{\text{new}} \mathbb{E}\left[\mathbf{z}_{n-1} \mathbf{z}_{n-1}^{\mathrm T}\right]
$$

$$
\mathbf{A}^{\text{new}}=\left(\sum_{n=2}^{N} \mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n-1}^{\mathrm{T}}\right]\right)\left(\sum_{n=2}^{N} \mathbb{E}\left[\mathbf{z}_{n-1} \mathbf{z}_{n-1}^{\mathrm{T}}\right]\right)^{-1} \tag{13.113}
$$

同様に$\mathbf{\Gamma}$について

$$
\frac{\partial Q}{\partial \mathbf{\Gamma}}=-\frac{1}{2} \sum_{n=2}^{N}\left[\mathbf{\Gamma}^{-\mathrm T}+\mathbb{E}\left[-\mathbf{\Gamma}^{-\mathrm T}\left(\mathbf{z}_{n}-\mathbf{A} \mathbf{z}_{n-1}\right)\left(\mathbf{z}_{n}-\mathbf{A} \mathbf{z}_{n-1}\right)^{\mathrm T} \mathbf{\Gamma}^{-\mathrm T}\right]\right]=0
$$

最大化するために$\frac{\partial Q}{\partial \mathbf{\Gamma}}=0$として

$$
\begin{aligned} \sum_{n=2}^{N}\left(\mathbf{\Gamma}^{\text{new}}\right)^{-\mathrm{T}} &=\sum_{n=2}^{N} \mathbb{E}\left[\left(\mathbf{\Gamma}^{\text{new}}\right)^{-\mathrm{T}}\left(\mathbf{z}_{n}-\mathbf{A}^{\text{new}} \mathbf{z}_{n-1}\right)\left(\mathbf{z}_{n}-\mathbf{A}^{\text{new}} \mathbf{z}_{n-1}\right)^{\mathrm T}\left(\mathbf{\Gamma}^{\text{new}}\right)^{-\mathrm{T}}\right] \\ \sum_{n=2}^{N} \mathbf{\Gamma}^{\text{new}} &=\sum_{n=2}^{N} \mathbb{E}\left[\left(\mathbf{z}_{n}-\mathbf{A}^{\text{new}} \mathbf{z}_{n-1}\right)\left(\mathbf{z}_{n}-\mathbf{A}^{\text{new}} \mathbf{z}_{n-1}\right)^{\mathrm T}\right] \\
(N-1) \mathbf{\Gamma}^{\text{new}}&=\sum_{n=2}^{N}\left\{\mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n}^{\mathrm T}\right]-\mathbf{A}^{\text{new}} \mathbb{E}\left[\mathbf{z}_{n-1} \mathbf{z}_{n}^{\mathrm T}\right]-\mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n-1}^{\mathrm T}\right]\left(\mathbf{A}^{\text{new}}\right)^{\mathrm T}+\mathbf{A}^{\text{new}} \mathbb{E}\left[\mathbf{z}_{n-1} \mathbf{z}_{n-1}^{\mathrm T}\right] \mathbf{A}^{\text{new}}\right\}
\end{aligned}
$$

$$
\begin{aligned}
\mathbf{\Gamma}^{\text {new}}=&\frac{1}{N-1} \sum_{n=2}^{N}\left\{\mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n}^{\mathrm{T}}\right]-\mathbf{A}^{\text{new}} \mathbb{E}\left[\mathbf{z}_{n-1} \mathbf{z}_{n}^{\mathrm{T}}\right]\right. \\
& \left. -\ \mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n-1}^{\mathrm{T}}\right]\left(\mathbf{A}^{\text{new}}\right)^{\mathrm{T}}+\mathbf{A}^{\text{new}} \mathbb{E}\left[\mathbf{z}_{n-1} \mathbf{z}_{n-1}^{\mathrm{T}}\right]\left(\mathbf{A}^{\text{new}}\right)^{\mathrm{T}}\right\}
\end{aligned} \tag{13.114}
$$

## 演習 13.34

線形動的システムにおける$\mathbf{C}$と$\mathbf{\Sigma}$に対するMステップの方程式の結果

$$
\mathbf{C}^{\text{new}} = \left(\sum_{n=1}^{N} \mathbf{x}_{n} \mathbb{E}\left[\mathbf{z}_{n}^{\mathrm{T}}\right]\right)\left(\sum_{n=1}^{N} \mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n}^{\mathrm{T}}\right]\right)^{-1} \tag{13.115}
$$

$$
\begin{aligned}
\mathbf{\Sigma}^{\text{new}} = & \frac{1}{N} \sum_{n=1}^{N}\left\{\mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm{T}}-\mathbf{C}^{\text{new}} \mathbb{E}\left[\mathbf{z}_{n}\right] \mathbf{x}_{n}^{\mathrm{T}}\right.\\ &\left.-\mathbf{x}_{n} \mathbb{E}\left[\mathbf{z}_{n}^{\mathrm{T}}\right]\left(\mathbf{C}^{\text{new}}\right)^{\mathrm{T}}+\mathbf{C}^{\text{new}} \mathbb{E}\left[\mathbf{z}_{n} \mathbf{z}_{n}^{\mathrm{T}}\right]\left(\mathbf{C}^{\text{new}}\right)^{\mathrm{T}}\right\}
\end{aligned} \tag{13.116}
$$

を確かめよ.

----

演習13.32の$Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text{old}}\right)$と同様、$\mathbf{C}$と$\mathbf{\Sigma}$についての項を抜き出す。

$$
\begin{aligned}
Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\text{old}}\right) &=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\sum_{n=1}^{N} \ln N\left(\mathbf{x}_{n} \mid \mathbf{Cz}_{n}, \mathbf{\Sigma}\right)\right]+\text { const.} \\
&=\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\sum_{n=1}^{N}\left(-\frac{1}{2} \ln |\mathbf{\Sigma}|-\frac{1}{2}\left(\mathbf{x}_{n}-\mathbf{Cz}_{n}\right)^{\mathrm{T}} \mathbf{\Sigma}^{-1}\left(\mathbf{x}_{n}-\mathbf{Cz}_{n}\right)\right)\right]+\text { const.}
\end{aligned}
$$

$\mathbf{C}$について、これは演習13.33の$\mathbf{A}^{\textrm{new}}$についての変形とほぼ同様に

$$
\frac{\partial Q}{\partial \mathbf{C}}=\sum_{n=1}^{N} \mathbf{\Sigma}^{-1} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{x}_{n} \mathbf{z}_{n}^{\mathrm{T}}\right]-\sum_{n=1}^{N} \mathbf{\Sigma}^{-1} \mathbf{C} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{n} \mathbf{z}_{n}^{\mathrm{T}}\right]
$$

$\frac{\partial Q}{\partial \mathbf{C}}=0$として

$$
\mathbf{C}^{\textrm{new}} \sum_{n=1}^{N} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{x}_{n} \mathbf{z}_{n}^{\mathrm{T}}\right]=\sum_{n=1}^{N} \mathbf{x}_{n} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{n}^{\mathrm{T}}\right]
$$

$$
\mathbf{C}^{\text{new}} = \left(\sum_{n=1}^{N} \mathbf{x}_{n} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{n}^{\mathrm{T}}\right]\right)\left(\sum_{n=1}^{N} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{n} \mathbf{z}_{n}^{\mathrm{T}}\right]\right)^{-1} \tag{13.115}
$$

同様に$\mathbf{\Sigma}$について

$$
\frac{\partial Q}{\partial \mathbf{\Sigma}}=-\frac{1}{2} \sum_{n=1}^{N}\left[\mathbf{\Sigma}^{-\mathrm{T}}+\mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[-\mathbf{\Sigma}^{-\mathrm{T}}\left(\mathbf{x}_{n}-\mathbf{Cz}_{n}\right)\left(\mathbf{x}_{n}-\mathbf{Cz}_{n}\right)^{\mathrm{T}} \mathbf{\Sigma}^{-\mathrm{T}}\right]\right]
$$

$\frac{\partial Q}{\partial \mathbf{\Sigma}}=0$として

$$
\sum_{n=1}^{N}\left( \mathbf{\Sigma}^{\textrm{new}} \right)^{-\mathrm{T}}=\sum_{n=1}^{N} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\left(\mathbf{\Sigma}^{\textrm{new}}\right)^{-\mathrm{T}}\left(\mathbf{x}_{n}-\mathbf{C}^{\textrm{new}}\mathbf{z}_{n}\right)\left(\mathbf{x}_{n}-\mathbf{C}^{\textrm{new}}\mathbf{z}_{n}\right)^{\mathrm{T}}\left(\mathbf{\Sigma}^{\textrm{new}}\right)^{-\mathrm{T}}\right]
$$

$$
\begin{aligned}
\mathbf{\Sigma}^{\text{new}} = & \frac{1}{N} \sum_{n=1}^{N}\left\{\mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm{T}}-\mathbf{C}^{\text{new}} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{n}\right] \mathbf{x}_{n}^{\mathrm{T}}\right.\\ &\left.-\mathbf{x}_{n} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{n}^{\mathrm{T}}\right]\left(\mathbf{C}^{\text{new}}\right)^{\mathrm{T}}+\mathbf{C}^{\text{new}} \mathbb{E}_{\mathbf{Z} \mid \boldsymbol{\theta}^{\text{old}}}\left[\mathbf{z}_{n} \mathbf{z}_{n}^{\mathrm{T}}\right]\left(\mathbf{C}^{\text{new}}\right)^{\mathrm{T}}\right\}
\end{aligned} \tag{13.116}
$$