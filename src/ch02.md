# PRML第2章演習問題解答

<head>
<style>
  div.panel-primary {
	border: 1px solid #000;
    margin: 10px 5px;
    padding: 16px 10px 0px;
  }
</style>
</head>

## 演習 2.1
<div class="panel-primary">

ベルヌーイ分布

$$
\textrm{Bern}(x|\mu)=\mu^x(1-\mu)^{1-x} \tag{2.2}
$$

が次の性質を満たすことを確かめよ.

$$
\sum_{x=0}^{1} p(x | \mu) =1 \tag{2.257}
$$

$$
\mathbb{E}[x] = \mu \tag{2.258}
$$
$$
\operatorname{var}[x] = \mu(1-\mu) \tag{2.259}
$$

ベルヌーイ分布に従う二値確率変数$x$のエントロピー$\mathrm{H}[x]$が

$$
\mathrm{H}[x]=-\mu \ln \mu-(1-\mu) \ln (1-\mu) \tag{2.260}
$$
で与えられることを示せ．

</div>

$\textrm{Bern}(x|\mu)=\mu^x(1-\mu)^{1-x}$であるから、

$$
\sum_{x=0}^{1} p(x | \mu)=\mu^{0}(1-\mu)^{1}+\mu^{1}(1-\mu)^{0}=1
$$

$$
\mathbb{E}[x]=\sum_{x=0}^{1}x\mu^x(1-\mu)^{1-x} =\mu
$$

$$
\operatorname{var}[x] = \mathbb{E}[x^2]-(\mathbb{E}[x])^2=\mu-\mu^2=\mu(1-\mu)
$$

また、エントロピー$\textrm{H}[x]$については

$$
\begin{aligned} H[x] &=-\sum_{x=0}^{1} \operatorname{Bern}(x | \mu) \cdot \ln \operatorname{Bern}(x | \mu) \\
&=-\sum_{x=0}^{1}\left(\mu^{x}(1-\mu)^{1-x} \ln \mu^{x}(1-\mu)^{1-x}\right) \\
&=-((1-\mu) \cdot \ln (1-\mu)+\mu \ln \mu) \\ &=-\mu \ln \mu-(1-\mu) \ln (1-\mu) \end{aligned}
$$

## 演習 2.2
<div class="panel-primary">

ベルヌーイ分布の

$$
\textrm{Bern}(x|\mu)=\mu^x(1-\mu)^{1-x} \tag{2.2}
$$

の表現では, $x$の2つの値$0$と$1$に関して対称ではない. 場合によっては，対称な$x \in\{-1,1\}$を用いた等価な表現の方が便利である. このとき分布は

$$
p(x | \mu)=\left(\frac{1-\mu}{2}\right)^{(1-x) / 2}\left(\frac{1+\mu}{2}\right)^{(1+x) / 2} \tag{2.261}
$$

と書くことができる. ただし, $\mu \in[-1,1]$である. この分布$(2.261)$が正規化されていることを示し, その平均, 分散, およびエントロピーを計算せよ.

</div>

$x \in\{-1,1\}$の二値のときに正規化されていることをまず示す。
$$
\begin{aligned} \sum_{x=-1}^{1} p(x | \mu) d x &=p(x=-1 | \mu)+p(x=1 | \mu) \\ &=\left(\frac{1-\mu}{2}\right)+\left(\frac{1+\mu}{2}\right)=1 \end{aligned}
$$
続いて、$\mathbb[x], \operatorname{var}[x], \textrm{H}[x]$について、
$$
\begin{aligned}
\mathbb{E}[x] &=\sum x p(x | \mu)=(-1) \frac{1-\mu}{2}+\frac{1+\mu}{2}=\mu \\
\operatorname{var}[x] &=\mathbb{E}\left[x^{2}\right]-\{\mathbb{E}[x]\}^{2}=\left(\frac{1-\mu}{2}\right)+\left(\frac{1+\mu}{2}\right)-\mu^{2}=1-\mu^{2} \\
\textrm{H}[x] &=-\sum p(x | \mu) \ln p(x | \mu) \\
&=-\left(\frac{1-\mu}{2} \ln \frac{1-\mu}{2}+\frac{1+\mu}{2} \ln \frac{1+\mu}{2}\right) \end{aligned}
$$

## 演習 2.3
<div class="panel-primary">

この演習問題では, 二項分布

$$
\operatorname{Bin}(m \mid N, \mu)=\left(\begin{array}{l}N \\ m\end{array}\right) \mu^{m}(1-\mu)^{N-m} \tag{2.9}
$$

が正規化されていることを証明する. まず, 全部で$N$個ある対象から$m$個の同じものを選ぶ組み合わせの数の定義(2.10）を用いて,

$$
\left(\begin{array}{l}N \\ m\end{array}\right)+\left(\begin{array}{c}N \\ m-1\end{array}\right)=\left(\begin{array}{c}N+1 \\ m\end{array}\right) \tag{2.262}
$$

を示せ. この結果を用い, 帰納法で次の結果を証明せよ.

$$
(1+x)^{N}=\sum_{m=0}^{N}\left(\begin{array}{l}N \\ m\end{array}\right) x^{m} \tag{2.263}
$$

これは, <b>二項定理 (binomialtheorem)</b>として知られ，すべての実数値$x$について成り立つ．最後に二項分布が次のように正規化されていることを，$(1-\mu)^N$を和の外に出してから，二項定理を使うことで示せ．

$$
\sum_{m=0}^{N}\left(\begin{array}{l}N \\ m\end{array}\right) \mu^{m}(1-\mu)^{N-m}=1 \tag{2.264}
$$

</div>

$(2.262)$を示す。

$$
\begin{aligned}\left(\begin{array}{c}N \\ m\end{array}\right)+\left(\begin{array}{c}N \\
m-1\end{array}\right) &=\frac{N !}{m !(N-m) !}+\frac{N !}{(m-1) !(N-m+1)!} \\
&=\frac{N !}{(m-1) !(N-m) !}\left(\frac{1}{m}+\frac{1}{N-m+1}\right) \\
&=\frac{N !}{(m-1) !(N-m) !}\left(\frac{N+1}{m(N-m+1)}\right) \\
&=\frac{(N+1) !}{m !(N+1-m) !}=\left(\begin{array}{c}N+1 \\
m\end{array}\right) \end{aligned}
$$

二項定理$(2.263)$を帰納法で示す。
$N=1$のとき、

$$
(左辺)=(1+x)=\left(\begin{array}{c}1 \\ 0\end{array}\right) x^{0}+\left(\begin{array}{c}1 \\ 1\end{array}\right) x^{1}=\sum_{n=0}^{1}\left(\begin{array}{c}1 \\ m\end{array}\right) x^{m}
$$

であり成立する。次に、$N=k$において式$(2.263)$が成立すると仮定したとき、$N=k+1$のときは

$$
\begin{aligned}(1+x)^{k+1} &=(1+x) \sum_{m=0}^{k}\left(\begin{array}{c}k \\ m\end{array}\right) x^{m}=\sum_{m=0}^{k}\left(\begin{array}{c}k \\ m\end{array}\right) x^{m}+x \sum_{m=0}^{k}\left(\begin{array}{c}k \\ m\end{array}\right) x^{m} \\ &=1+\sum_{m=1}^{k}\left\{\left(\begin{array}{c}k \\ m\end{array}\right)+\left(\begin{array}{c}k \\ m-1\end{array}\right)\right\} x^{m}+x^{k+1} \\ &=1+\sum_{m=1}^{k}\left(\begin{array}{c}k+1 \\ m\end{array}\right) x^{m}+x^{k+1} \\ &=\sum_{m=0}^{k+1}\left(\begin{array}{c}k+1 \\ m\end{array}\right) x^{m} \end{aligned}
$$

よって、$N=k+1$のときでも成立するので、帰納法より式$(2.263)$は示された。

最後に正規化の式$(2.264)$について、二項定理から

$$
\left\{(1-\mu)+\mu\right\}^N=\sum_{m=0}^{N}\left(\begin{array}{c}N \\ m \end{array} \right) \mu^m (1-\mu)^{N-m}
$$
が成立する。ここで、$(左辺)=1^N=1$なので、式(2.264)は成立する。

## 演習 2.4
<div class="panel-primary">

二項分布の平均が

$$
\mathbb{E}[m] \equiv \sum_{m=0}^{N} m \operatorname{Bin}(m \mid N, \mu)=N \mu \tag{2.11}
$$

であることを示せ．これには，正規化条件$(2.264)$の両辺を$\mu$で微分し，変形して$n$の平均を求めよ．同様に，$(2.264)$の両辺を$\mu$について2階微分し，二項分布の平均$(2.11)$も用いて，二項分布の分散の結果

$$
\operatorname{var}[m] \equiv \sum_{m=0}^{N}(m-\mathbb{E}[m])^{2} \operatorname{Bin}(m \mid N, \mu)=N \mu(1-\mu) \tag{2.12}
$$

を証明せよ．

</div>

$(2.264)$の両辺を$\mu$で微分すると

$$
\begin{array}{l}
\displaystyle \sum_{m=0}^{N}\left(\begin{array}{l}N \\ m\end{array}\right)\left(m \mu^{m-1}(1-\mu)^{N-m}-(N-m) \mu^{m}(1-\mu)^{N-m-1}\right)=0 \\
\displaystyle \sum_{m=0}^{N}\left(\begin{array}{l}N \\ m\end{array}\right) \mu^{m-1}(1-\mu)^{N-m-1}(m(1-\mu)-(N-m)\mu)=0 \\
\displaystyle \sum_{m=0}^{N}\left(\begin{array}{l}N \\ m\end{array}\right) \mu^{m-1}(1-\mu)^{N-m-1}(m-N \mu)=0 \\
\displaystyle \sum_{m=0}^{N}\left(\begin{array}{l}N \\ m\end{array}\right) m \mu^{m-1}(1-\mu)^{N-m-1}=N\mu \displaystyle \sum_{m=0}^{N}\left(\begin{array}{l}N \\ m\end{array}\right) \mu^{m-1}(1-\mu)^{N-m-1}
\end{array}
$$

両辺に$\mu(1-\mu)$をかけると

$$
\underbrace{\sum_{m=0}^{N}\left(\begin{array}{l}N \\ m\end{array}\right) m \mu^{m}(1-\mu)^{N-m}}_{\mathbb E[m]} = N\mu \underbrace{\sum_{m=0}^{N}\left(\begin{array}{l}N \\ m\end{array}\right) \mu^{m}(1-\mu)^{N-m}}_{1}
$$

よって$\mathbb E[m]=N\mu$が示された。

分散について,

$$
\begin{aligned} \operatorname{var}[m] &=\mathbb{E}\left[m^{2}\right]-(\mathbb{E}[m])^{2} \\ &=\mathbb{E}[m(m-1)]+\mathbb{E}[m]-(\mathbb{E}[m])^{2} \end{aligned}
$$

であるから、$\mathbb{E}[m(m-1)]$の値を求める。

$$
\begin{aligned} E[m(m-1)] &=\sum_{m=0}^{N} m(m-1)\left(\begin{array}{l}N \\ m\end{array}\right) \mu^{m}(1-\mu)^{N-m} \\
&=\sum_{m=2}^{N} m(m-1)\left(\begin{array}{l}N \\ m\end{array}\right) \mu^{m}(1-\mu)^{N-m} \\ &=\sum_{m=2}^{N} m(m-1) \frac{N(N-1)(N-2) !}{(N-m) ! m(m-1)(m-2) !} \mu^{m}(1-\mu)^{N-m} \\
&=N(N-1) \sum_{m=2}^{N}\left(\begin{array}{l}N-2 \\ m-2\end{array}\right) \mu^{m}(1-\mu)^{N-m} \\
&=N(N-1) \mu^{2} \underbrace{\sum_{\ell=0}^{N-2}\left(\begin{array}{c}N-2 \\ \ell \end{array}\right) \mu^{\ell}(1-\mu)^{N-2-\ell}}_1 \\
&=N(N-1) \mu^{2} \end{aligned}
$$

よって

$$
\begin{aligned} \operatorname{var}[m] &=N(N-1) \mu^{2}+N \mu-(N \mu)^{2} \\ &=N \mu(1-\mu) \end{aligned}
$$

これは$(2.12)$と一致する。

## 演習 2.5
<div class="panel-primary">

この演習問題では,

$$
\operatorname{Beta}(\mu \mid a, b)=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \mu^{a-1}(1-\mu)^{b-1} \tag{2.13}
$$

のベータ分布が,

$$
\int_{0}^{1} \operatorname{Beta}(\mu \mid a, b) \mathrm{d} \mu=1 \tag{2.14}
$$

が成立するように正しく正規化されていることを証明する. これは

$$
\int_{0}^{1} \mu^{a-1}(1-\mu)^{b-1} \mathrm{d} \mu=\frac{\Gamma(a) \Gamma(b)}{\Gamma(a+b)} \tag{2.265}
$$

を示すことと等価である．ガンマ関数の定義

$$
\Gamma(x) \equiv \int_{0}^{\infty} u^{x-1} e^{-u} \mathrm{d} u \tag{1.141}
$$

より，

$$
\Gamma(a) \Gamma(b)=\int_{0}^{\infty} \exp (-x) x^{a-1} \mathrm{d} x \int_{0}^{\infty} \exp (-y) y^{b-1} \mathrm{d} y \tag{2.266}
$$

を得る。この式を用いて，次のようにして$(2.265)$を証明せよ．まず$y$についての積分を, $x$についての積分の被積分関数の中に移す．次に$x$を固定して$t=y+x$と置換し，$x$と$t$の積分の順序を交換する．最後に，$t$を固定して$x=t\mu$と置換する．

</div>

式$(2.265)$を証明する。

$$
\begin{aligned} \Gamma(a) \Gamma(b) &=\int_{0}^{\infty} \exp (-x) x^{a-1} dx \int_{0}^{\infty} \exp (-y) y^{b-1} dy \\
&=\int_{0}^{\infty} \exp (-x) x^{a-1}\left\{ \int_{0}^{\infty} \exp (-y) y^{b-1} dy\right\} dx \\
&=\int_{0}^{\infty} \int_{0}^{\infty} \exp (-x-y) x^{a-1} y^{b-1} dydx \end{aligned}
$$

$x$を固定してから$t=y+x$とおくと, $0 \le y \le \infty$なので, $x\le t \le \infty$となる。

$$
\Gamma(a) \Gamma(b)=\int_{0}^{\infty} \int_{x}^{\infty} \exp (-t) x^{a-1}(t-x)^{b-1} dt dx
$$

次に上式の$t$に関する積分と$x$に関する積分を入れ替える.

積分範囲について注意すると、$x$は$0\le x\le \infty$, $t$は$x\le t \le \infty$であり, 順番を入れ替えると$0\le t \le \infty$の積分範囲で, $x$は$0\le x \le t$の範囲となる。よって,

$$
\Gamma(a) \Gamma(b)=\int_{0}^{\infty} \int_{0}^{t} \exp (-t) x^{a-1}(t-x)^{b-1} dx dt
$$

さらに$x=t\mu$と置換すると, 積分範囲は$0\le \mu \le 1, dx=td\mu$である.

$$
\Gamma(a) \Gamma(b)=\int_{0}^{\infty} \int_{0}^{1} \mu^{a-1} t^{a-1} \exp (-t) \cdot t^{b-1}(1-\mu)^{b-1} \cdot t d\mu dt
$$

$\mu$と$t$の積分に分離すると

$$
\Gamma(a) \Gamma(b)=\int_{0}^{\infty} t^{a+b-1} \exp (-t) dt \cdot \int_{0}^{1} \mu^{a-1}(1-\mu)^{b-1} d\mu
$$

ここで$\int_{0}^{\infty} \exp (-t) t^{a+b-1} d t=\Gamma(a+b)$なので,

$$
\int_{0}^{1} \mu^{a-1}(1-\mu)^{b-1} \mathrm{d} \mu=\frac{\Gamma(a) \Gamma(b)}{\Gamma(a+b)}
$$

よって, 式$(2.265)$は示された。

## 演習 2.6
<div class="panel-primary">

$(2.265)$の結果を用いて，ベータ分布

$$
\operatorname{Beta}(\mu \mid a, b)=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \mu^{a-1}(1-\mu)^{b-1} \tag{2.13}
$$

の平均，分散，およびモードがそれぞれ

$$
\mathbb{E}[\mu] =\frac{a}{a+b} \tag{2.267}
$$
$$
\operatorname{var}[\mu] =\frac{a b}{(a+b)^{2}(a+b+1)} \tag{2.268}
$$
$$
\operatorname{mode}[\mu] =\frac{a-1}{a+b-2} \tag{2.269}
$$

になることを示せ.

</div>

式(2.265)$\int_{0}^{1} \mu^{a-1}(1-\mu)^{b-1} d \mu=\frac{\Gamma(a) \Gamma(b)}{\Gamma(a+b)}$を用いる。

$$
\begin{aligned} \mathbb{E}[\mu] &=\int_{0}^{1} \mu \cdot \operatorname{Beta}(\mu | a, b) d \mu \\ &=\int_{0}^{1} \mu \frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \mu^{a-1}(1-\mu)^{b-1} d \mu \\ &=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \int_{0}^{1} \mu^{a}(1-\mu)^{b-1} d \mu=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \cdot \frac{\Gamma(a+1) \Gamma(b)}{\Gamma(a+b+1)} \end{aligned}
$$

ここでガンマ関数の性質$\Gamma(x+1)=x\Gamma(x)$（演習1.17）を利用すると, 平均$\mathbb{E}[\mu]$は

$$
\mathbb{E}[\mu]=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \cdot \frac{a \Gamma(a) \Gamma(b)}{(a+b) \Gamma(a+b)}=\frac{a}{a+b}
$$

次に, 分散$\operatorname{var}[\mu]$の算出のために$\mathbb{E}[\mu^2]$を計算する

$$
\begin{aligned} \mathbb{E}\left[\mu^{2}\right] &=\int_{0}^{1} \mu^{2} \cdot \operatorname{Beta}(\mu | a, b) d \mu \\ &=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \int_{0}^{1} \mu^{a+1}(1-\mu)^{b-1} d \mu \\ &=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \cdot \frac{\Gamma(a+2) \Gamma(b)}{\Gamma(a+b+2)} \\
&= \frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \cdot \frac{a(a+1)\Gamma(a) \Gamma(b)}{(a+b+1)(a+b)\Gamma(a+b)} = \frac{a(a+1)}{(a+b+1)(a+b)} \end{aligned}
$$

よって, 求める分散は

$$
\begin{aligned} \operatorname{var}[\mu] &=\mathbb{E}\left[\mu^{2}\right]-\{\mathbb{E}[\mu]\}^{2} \\ &=\frac{a(a+1)}{(a+b+1)(a+b)}-\frac{a^{2}}{(a+b)^{2}} \\ &=\frac{\left(a^{2}+a\right)(a+b)-a^{2}(a+b+1)}{(a+b)^{2}(a+b+1)} \\ &=\frac{a b}{(a+b)^{2}(a+b+1)} \end{aligned}
$$

$\operatorname{mode}[\mu]$は$\mu$の最頻値, 上に凸で$\operatorname{Beta}(\mu|a,b)$の傾きが0になる点。

$$
\begin{aligned} \frac{\partial \operatorname{Beta}}{\partial \mu} &=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \frac{\partial}{\partial \mu}\left[\mu^{a-1}(1-\mu)^{b-1}\right] \\ &=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)}\left\{(a-1) \mu^{a-2}(1-\mu)^{b-1}-(b-1) \mu^{a-1}(1-\mu)^{b-2}\right\} \\ &=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \mu^{a-2}(1-\mu)^{b-2}\{(a-1)(1-\mu)-(b-1) \mu\}
\end{aligned}
$$
ここで$\mu>0, 1-\mu>0$であるから
$$
(a-1)(1-\mu)-(b-1) \mu=0
$$
を考えれば良い
これを解いて
$$
\space \mu=\frac{a-1}{a+b-2}
$$
(厳密には$a>1, b>1$でないと成立しない)

## 演習 2.7
<div class="panel-primary">

$\mu$の事前分布がベータ分布

$$
\operatorname{Beta}(\mu \mid a, b)=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \mu^{a-1}(1-\mu)^{b-1} \tag{2.13}
$$

である二項分布

$$
\operatorname{Bin}(m \mid N, \mu)=\left(\begin{array}{l}N \\ m\end{array}\right) \mu^{m}(1-\mu)^{N-m} \tag{2.9}
$$

に従う確率変数$x$を考える．ここで,$x=1$の事象が$m$回, $x=0$が$l$回生じたとする．このとき，$\mu$の事後平均が，事前平均と$\mu$の最尤推定量の間の値になることを示せ．これには，事前平均の$\lambda$倍と，最尤推定量の$(1-\lambda)$倍の和で事後平均が書けることを示せばよい．ただし，$0 \leq \lambda \leq 1$である．よって，事後分布が，事前分布と最尤推定解との間のものになることが分かる．

</div>

$0 \le \lambda \le 1$として、事後平均が事前平均の$\lambda$倍と最尤推定量の$(1-\lambda)$倍の和であることを示せばよい。
$(2.15)$より、ベータ分布の平均は$\displaystyle \frac{a}{a+b}$で、これが事前分布の平均である。$x=1$を$m$回、$x=0$を$l$回観測すると、事後分布は$(2.18)$で与えられ、平均値は$(2.19)$, $(2.20)$から$\displaystyle \frac{m+a}{m+a+l+b}$となる。

一方、最尤推定量は$(2.7)$, $(2.8)$の通り、$\displaystyle \mu_{\textrm{ML}}=\frac{m}{N}=\frac{m}{m+l}$であるので、題意としては

$$
\lambda \frac{a}{a+b}+(1-\lambda) \frac{m}{m+l}=\frac{m+a}{m+a+l+b}
$$

となるような$\lambda$が$0 \le \lambda \le 1$に存在することを示す。

$$
\frac{\lambda a(m+l)-\lambda m(a+b)}{(a+b)(m+l)}=\frac{m+a}{m+a+l+b}-\frac{m}{m+l}
$$
$$
\lambda \frac{a l-b m}{(a+b)(m+l)}=\frac{(m+a)(m+l)-m(m+a+l+b)}{(m+a+l+b)(m+l)}
$$
$$
\begin{aligned} \lambda &=\frac{a+b}{a l-b m} \cdot \frac{m^{2}+m l+a m+a l-m^{2}-m a-m l-m b}{m+a+l+b} \\ &=\frac{a+b}{m+a+l+b} \end{aligned}
$$
$m,l \ge 0$, $a, b \gt 0$ なので、$m+a+l+b \ge a+b \gt 0$

よって$0 \le \lambda \le 1$となる。

## 演習 2.8
<div class="panel-primary">

同時確率が$p(x,y)$であるような２つの変数$x$と$y$を考える. これについて，次の2つの結果を証明せよ．

$$
\mathbb{E}[x] =\mathbb{E}_{y}\left[\mathbb{E}_{x}[x | y]\right] \tag{2.270}
$$

$$
\operatorname{var}[x] =\mathbb{E}_{y}\left[\operatorname{var}_{x}[x | y]\right]+\operatorname{var}_{y}\left[\mathbb{E}_{x}[x | y]\right] \tag{2.271}
$$

ただし，$\mathbb{E}_{x}[x | y]$は，条件付き分布$p(x|y)$の下での$x$の期待値である. 条件付き分散についても同様である.

</div>

※ 添字の$x, y$と関数としての$x, y$を分けて考えておく必要がある。PRML P.19の式$(1.36)$にあるように、$\mathbb{E}_x[f(x,y)]$の添字$_x$は関数$f(x,y)$の$x$の分布に関する平均を表している。式$(1.37)$〜$(1.39)$の関数$f$を$f(x)=x$として考える。

はじめに

$$
\mathbb{E}_{x}[f| y ]=\int f p(x | y) d x=\int f \frac{p(x, y)}{p(y)} dx
$$

であるから、

$$
\begin{aligned} \mathbb{E}_{y}\left[\mathbb{E}_{x}[f | y]\right] &=\int \left[ \int f \frac{p(x,y)}{p(y)}dx \right] p(y) dy \\
&=\int\left[\int f p(x, y) d x\right] d y \\
&=\int f \int p(x, y) d y d x \\
&=\int f p(x) d x \\
&=\mathbb{E}_{x}[f] = \mathbb{E}_{x}[x]
\end{aligned}
$$

ここで、重積分の交換と式(1.31)の**確率の加法定理**である$\displaystyle p(x)=\int p(x,y)dy$を使った。

次に式$(2.271)$の右辺について

$$
\begin{aligned}
& \mathbb{E}_{y}\left[\operatorname{var}_{x}[x | y]\right]+\operatorname{var}_{y}\left[\mathbb{E}_{x}[x | y]\right] \\
=& \mathbb{E}_{y}\left[\mathbb{E}_{x}\left[x^{2} | y\right]-\mathbb{E}_{x}[x | y]^{2}\right]+\mathbb{E}_{y}\left[\mathbb{E}_{x}[x | y]^{2}\right]-\left\{\mathbb{E}_{y}\left[\mathbb{E}_{x}[x | y]\right]\right\}^{2} \\
=& \mathbb{E}_{y}\left[\mathbb{E}_{x}\left[x^{2} | y\right]\right]-\mathbb{E}_{y}\left[\mathbb{E}_{x}[x | y]^{2}\right]+\mathbb{E}_{y}\left[\mathbb{E}_{x}[x | y]^{2}\right]-\left\{\mathbb{E}_{y}\left[\mathbb{E}_{x}[x | y]\right\}\right\}^{2} \\
=& \mathbb{E}_{y}\left[\mathbb{E}_{x}\left[x^{2} | y\right]\right]-\left\{\mathbb{E}_{y}\left[\mathbb{E}_{x}[x | y]\right]\right\}^{2} \end{aligned}
$$

ここで式$(2.270)$の結果を用いる。今度は$f(x)=x^2$とすると

$$
\begin{aligned}
 \mathbb{E}_{y}\left[\mathbb{E}_{x}\left[x^{2} | y\right]\right]-\left\{\mathbb{E}_{y}\left[\mathbb{E}_{x}[x | y]\right]\right\}^{2} &= \mathbb{E}_{x}\left[x^{2}\right]-\left\{\mathbb{E}_{x}[x]\right\}^{2} \\
&= \operatorname{var}_{x}[x]
\end{aligned}
$$

これは式$(2.271)$の左辺なので、示された。

## 演習 2.9
<div class="panel-primary">

この演習問題では，ディリクレ分布が正規化されていることを，帰納法によって証明する．
ディリクレ分布で$M=2$とした特殊な場合であるベータ分布が正規化されていることは，演習問題2.5ですでに示した．
次に，ディリクレ分布が$M-1$変数の場合に正規化されているとの仮定の下，$M$変数でも正規化されていることを証明する.
これにはまず$M$変数のディリクレ分布から, $\sum_{k=1}^{M} \mu_{k}=1$の
制約を使って$\mu_M$を除去して，ディリクレ分布を

$$
p_{M}\left(\mu_{1}, \ldots, \mu_{M-1}\right)=C_{M} \prod_{k=1}^{M-1} \mu_{k}^{\alpha_{k}-1}\left(1-\sum_{j=1}^{M-1} \mu_{j}\right)^{\alpha_{M}-1} \tag{2.272}
$$

と書く．すると，あとは$C_M$を表す式を求めればよい．これには，この式を，範囲に注意しつつ$\mu_{M-1}$について積分し，さらに，この積分の範囲が0から1となるように変数を置換する.
$C_{M-1}$での結果が正しいと仮定して(2.265)を用いて，$C_M$の式を導出せよ．

</div>

※ 誘導にしたがって解くものの、指示の意味がピンと来ないかもしれない。まずは制約$\displaystyle{\sum_{k=1}^{M} \mu_{k}=1}$を使ってまずは制約$\displaystyle{\sum_{k=1}^{M} \mu_{k}=1}$を使って$\mu_M$を除去し、$\mu_{M-1}$以下からなる式に変形していく。次に、$\mu_{M-1}$について積分を行うことで、$M-2$変数の周辺分布の形$p_{M-1}(\mu_1, \mu_2, \ldots, \mu_{M-2})$を計算することができる。これと、$M-1$変数のディリクレ分布の結果が正しいと仮定したときに得られる結果と比較することで、$C_M$についての式が得られる。

$M−1$変数の場合に正規化されているとの仮定の下で、$M$変数の場合に正規化されていることを証明する。$M$変数のディリクレ分布から、$\sum_{k=1}^M μ_k = 1$の制約を用いて$\mu_M$を除去すると、以下の$M−1$変数の確率分布が得られる.

$$
p_M(\mu_1,...,\mu_{M-1}) = C_M \prod_{k=1}^{M-1} \mu_k^{\alpha_k-1} \left( 1 - \sum_{j=1}^{M-1} \mu_j \right )^{\alpha_M-1}
$$

ここで、$\displaystyle C_{M}=\frac{\Gamma\left(\alpha_{1}+\cdots+\alpha_{M}\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{M}\right)}$, 制約として$\displaystyle 0 \leq \mu_{i} \leq 1(i=1, \ldots, M-1) , \sum_{k=1}^{M-1} \mu_{k} \leq 1$が存在する。

確率分布$p_M$を変数$\mu_{M-1}$で積分すると、$M-2$変数の周辺分布が得られる（確率の加法定理）。$\mu_{M-1}$の積分範囲は、上記の制約により、$0$から$1-\sum_{j=1}^{M-2}\mu_j$までとなる。

$$
\begin{aligned}
& p_{M-1}\left(\mu_{1}, \ldots, \mu_{M-2}\right) \\=& \int_{0}^{1-\sum_{j=1}^{M-2} \mu_{j}} p_{M}\left(\mu_{1}, \ldots, \mu_{M-1}\right) d \mu_{M-1} \\=& C_{M}\left[\prod_{k=1}^{M-2} \mu_{k}^{\alpha_{k}-1}\right] \int_{0}^{1-\sum_{j=1}^{M-2} \mu_{j}} \mu_{M-1}^{\alpha_{M-1}-1}\left(1-\sum_{j=1}^{M-1} \mu_{j}\right)^{\alpha_{M}-1} d \mu_{M-1}
\end{aligned}
$$

ここで積分範囲を$[0,1]$にするために次の変数変換を行う

$$
\begin{aligned}
\mu_{M-1} &= t\left(1-\sum_{j=1}^{M-2} \mu_{j}\right) \\ 1-\sum_{j=1}^{M-1} \mu_{j} &=1-\sum_{j=1}^{M-2} \mu_{j}-\mu_{M-1} \\ &=\left(1-\sum_{j=1}^{M-2} \mu_{j}\right)-t\left(1-\sum_{j=1}^{M-2} \mu_{j}\right) \\ &=(1-t)\left(1-\sum_{j=1}^{M-2} \mu_{j}\right)
\end{aligned}
$$

これによって

$$
\begin{aligned}
\quad p_{M-1}\left(\mu_{1}, \ldots, \mu_{M-2}\right) &= C_{M}\left[\prod_{k=1}^{M-2} \mu_{k}^{\alpha_{z}-1}\right] \int_{0}^{1}\left\{t\left(1-\sum_{j=1}^{M-2} \mu_{j}\right)\right\}^{\alpha_{w-1}-1}\left\{(1-t)\left(1-\sum_{j=1}^{M-2} \mu_{j}\right)\right\}^{\alpha_{n-1}}\left(1-\sum_{j=1}^{M-2} \mu_{j}\right) d t \\
&= C_{M}\left[\prod_{k=1}^{M-2} \mu_{k}^{\alpha_{k}-1}\right]\left(1-\sum_{j=1}^{M-2} \mu_{j}\right)^{\alpha_{y-1}+\alpha_{n}-1} \int_{0}^{1} t^{\alpha_{n-1}-1}(1-t)^{\alpha_{n-1}-1} d t \\
&= C_{M}\left[\prod_{k=1}^{n-2} \mu_{k}^{\alpha_{k}-1}\right]\left(1-\sum_{j=1}^{M-2} \mu_{j}\right)^{\alpha_{n-1}+\alpha_{n}-1} \frac{\Gamma\left(\alpha_{M-1}\right) \Gamma\left(\alpha_{M}\right)}{\Gamma\left(\alpha_{M-1}+\alpha_{M}\right)}
\end{aligned}
$$

こうして得られた周辺分布$p_{M-1}(μ_1,\ldots,μ_{M-2})$は、$\alpha'=(\alpha_1,\ldots,\alpha_{M-2},\alpha_{M-1}+\alpha_M)^T$をパラメータとする$M−1$変数のディリクレ分布から変数を一つ除去した確率分布の形をしている。

一方、同じパラメータ$\alpha'=(\alpha_1,\ldots,\alpha_{M-2},\alpha_{M-1}+\alpha_M)^T$を持つ$M−1$変数のディリクレ分布から、$\sum_{k=1}^{M-1} μ_k = 1$の制約を用いて変数を一つ除去すると、以下の確率分布が得られる。

$$
p_{M-1}\left(\mu_{1}, \ldots, \mu_{M-2}\right)=C_{M-1} \prod_{k=1}^{M-2} \mu_{k}^{\alpha_{k}-1}\left(1-\sum_{j=1}^{M-2} \mu_{j}\right)^{\alpha_{M-1}+\alpha_{M}-1}
$$

ここで$\displaystyle{C_{M-1}=\frac{\Gamma\left(\alpha_{1}+\cdots+\alpha_{M-2}+\left(\alpha_{M-1}+\alpha_{M}\right)\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{M-2}\right) \Gamma\left(\alpha_{M-1}+\alpha_{M}\right)}}$。
帰納法の仮定より、この確率分布は正規化されている。

上記の$p_{M−1}$の定数部分は

$$
\begin{aligned}
& C_{M} \frac{\Gamma\left(\alpha_{M-1}\right) \Gamma\left(\alpha_{M}\right)}{\Gamma\left(\alpha_{M-1}+\alpha_{M}\right)} \\=& \frac{\Gamma\left(\alpha_{1}+\cdots+\alpha_{M}\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{M}\right)} \frac{\Gamma\left(\alpha_{M-1}\right) \Gamma\left(\alpha_{M}\right)}{\Gamma\left(\alpha_{M-1}+\alpha_{M}\right)} \\=& \frac{\Gamma\left(\alpha_{1}+\cdots+\alpha_{M-2}+\left(\alpha_{M-1}+\alpha_{M}\right)\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{M-2}\right) \Gamma\left(\alpha_{M-1}+\alpha_{M}\right)} \\=& C_{M-1}
\end{aligned}
$$

よって、$M$変数のディリクレ分布も正規化されていることが示された。

## 演習 2.10
<div class="panel-primary">

ガンマ関数の性質$\Gamma(x+1)=x\Gamma(x)$を用いて，

$$
\operatorname{Dir}(\boldsymbol{\mu} | \boldsymbol{\alpha})=\frac{\Gamma\left(\alpha_{1}+\cdots+\alpha_{K}\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{K}\right)} \prod_{k=1}^{K} \mu_{k}^{\alpha_{k}-1} \tag{2.38}
$$

のディリクレ分布の平均，分散，および共分散の結果を導出せよ.

\begin{aligned}
\mathbb{E}[\mu_j] &= \frac{\alpha_j}{\alpha_0} \tag{2.273} \\
\operatorname{var}[\mu_j] &= \frac{\alpha_j(\alpha_0 - \alpha_j)}{\alpha_0^2(\alpha_0 + 1)} \tag{2.274} \\
\operatorname{cov}[\mu_j][\mu_l] &= -\frac{\alpha_j\alpha_l}{\alpha_0^2(\alpha_0 + 1)} \hspace{1em} (j \neq l) \tag{2.275}
\end{aligned}

ただし、$\alpha_0$は

$$
\alpha_0 = \sum_{k=1}^K\alpha_k \tag{2.39}
$$

で定義されている。

</div>

ディリクレ分布は正規化されているので、

$$
\int{\prod_{k=1}^{K}} \mu_{k}^{\alpha_{k}-1} d\boldsymbol{\mu}=\frac{\Gamma\left(\alpha_{1}\right) \Gamma\left(\alpha_{2}\right) \cdots \Gamma\left(\alpha_{K}\right)}{\Gamma\left(\alpha_{1}+\cdots+\alpha_{K}\right)}
$$

平均$\mathbb{E}[\mu_j]$について、

$$
\begin{aligned}
\mathbb{E}\left[\mu_{j}\right] &=\int \mu_{i} \operatorname{Dir}(\boldsymbol{\mu} | \boldsymbol{\alpha}) d \boldsymbol{\mu} \\
&=\frac{\Gamma\left(\alpha_{1}+\cdots +\alpha_{K}\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{K}\right)} \int \mu_{j} \prod_{k=1}^{K} \mu_{k}^{\alpha_{k}-1} d \boldsymbol{\mu} \\
&=\frac{\Gamma\left(\alpha_{1}+\cdots +\alpha_{K}\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{K}\right)} \int \mu_{1}^{\alpha_{1}-1} \mu_{2}^{\alpha_{2}-1} \cdots \mu_{j}^{(\alpha_j +1)-1} \cdot \mu_{K}^{\alpha_{K}-1} d \boldsymbol{\mu}
\end{aligned}
$$

ここで、ディリクレ分布のパラメータ$\boldsymbol{\alpha}$のうち、$\alpha_j \to \alpha_j + 1$となったものだとみなせば、$\displaystyle{\int{\prod_{k=1}^{K}} \mu_{k}^{\alpha_{k}-1} d\boldsymbol{\mu}=\frac{\Gamma\left(\alpha_{1}\right) \Gamma\left(\alpha_{2}\right) \cdots \Gamma\left(\alpha_{K}\right)}{\Gamma\left(\alpha_{1}+\cdots+\alpha_{K}\right)}}$を利用して

$$
\int \mu_{1}^{\alpha_{1}-1} \mu_{2}^{\alpha_{2}-1} \cdots \mu_{j}^{\left(\alpha_{j}+1\right)-1} \cdots \mu_{K}^{\alpha_{K}-1} d \boldsymbol{\mu}=\frac{\Gamma\left(\alpha_{1}\right) \Gamma\left(\alpha_{2}\right) \cdots \Gamma\left(\alpha_{j}+1\right) \cdots \Gamma\left(\alpha_{K}\right)}{\Gamma\left(\alpha_{1}+\cdots+\alpha_{K}+1\right)}
$$

となるので、

$$
\begin{aligned}
\mathbb{E}\left[\mu_{j}\right] &=\frac{\Gamma\left(\alpha_{1}+\cdots +\alpha_{K}\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{K}\right)} \cdot \frac{\Gamma\left(\alpha_{1}\right) \Gamma\left(\alpha_{2}\right) \cdots \Gamma\left(\alpha_{j}+1\right) \cdots \Gamma\left(\alpha_{K}\right)}{\Gamma\left(\alpha_{1}+\cdots+\alpha_{K}+1\right)} \\
&=\frac{\Gamma\left(\alpha_{1}+\cdots +\alpha_{K}\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{K}\right)} \cdot \frac{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{K}\right)}{\Gamma\left(\alpha_{1}+\cdots+ \alpha_{K}\right)} \cdot \frac{\alpha_{j}}{\sum_{k=1}^{K} \alpha_{k}}=\frac{\alpha_{j}}{\alpha_{0}}
\end{aligned}
$$

同様に、

$$
\begin{aligned}
\mathbb{E}\left[\mu_{j}^{2}\right] &=\int \mu_{j}^{2} \operatorname{Dir}(\boldsymbol{\mu} | \boldsymbol{\alpha}) d \boldsymbol{\mu} \\ &=\frac{\Gamma\left(\alpha_{1}+\cdots \alpha_{K}\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{K}\right)} \cdot \frac{\Gamma\left(\alpha_{1}\right) \Gamma\left(\alpha_{2}\right) \cdots \cdot \Gamma\left(\alpha_{j}+2\right) \cdots \Gamma\left(\alpha_{K}\right)}{\Gamma\left(\alpha_{1}+\cdots+\alpha_{K}+2\right)} \\
&=\frac{\alpha_{j}\left(\alpha_{j}+1\right)}{\alpha_{0}\left(\alpha_{0}+1\right)} \end{aligned}
$$

と求まるので、分散$\operatorname{var}[\mu_j]$は

$$
\begin{aligned}
\operatorname{var}\left[\mu_{j}\right] &=\mathbb{E}\left[\mu_{j}^{2}\right]-\left\{\mathbb{E}\left[\mu_{j}\right]\right\}^{2} \\
&=\frac{\alpha_{j}\left(\alpha_{j}+1\right)}{\alpha_{0}\left(\alpha_{0}+1\right)}-\frac{\alpha_{j}^{2}}{\alpha_{0}^{2}} \\
&=\frac{\alpha_{0} \alpha_{j}\left(\alpha_{j}+1\right)-\alpha_{j}^{2}\left(\alpha_{0}+1\right)}{\alpha_{0}^{2}\left(\alpha_{0}+1\right)} \\ &=\frac{\alpha_{j}\left(\alpha_{0}-\alpha_{j}\right)}{\alpha_{0}^{2}\left(\alpha_{0}+1\right)} \end{aligned}
$$

共分散$\operatorname{cov}[\mu_j, \mu_l]$について、$j\neq l$のとき、

$$
\begin{aligned}
\operatorname{cov}\left[\mu_{j}, \mu_{l}\right] &=\mathbb{E}\left[\mu_{j} \mu_{l}\right]-\mathbb{E}\left[\mu_{j}\right] \mathbb{E}\left[\mu_{l}\right] \\
&=\frac{\alpha_{j} \alpha_{l}}{\alpha_{0}\left(\alpha_{0}+1\right)}-\frac{\alpha_{j}}{\alpha_{0}} \cdot \frac{\alpha_{l}}{\alpha_{0}} \\
&=\frac{\alpha_{0} \alpha_{j} \alpha_{l}-\alpha_{j} \alpha_{l}\left(\alpha_{0}+1\right)}{\alpha_{0}^{2}\left(\alpha_{0}+1\right)} \\
&= - \frac{\alpha_{j} \alpha_{l}}{\alpha_{0}^{2}\left(\alpha_{0}+1\right)}
\end{aligned}
$$

## 演習 2.11
<div class="panel-primary">

ディリクレ分布の下での$\ln \mu_j$の期待値を，$\alpha_j$についての導関数として表すと，

$$
\begin{aligned}
\mathbb{E}[\ln \mu_j]=\psi(\alpha_j)-\psi(\alpha_0) \tag{2.276}
\end{aligned}
$$

になることを示せ．ただし$\alpha_0$は$(2.39)$で定義され,$\psi(\cdot)$はディガンマ関数 (digamma function)

$$
\begin{aligned}
\psi(a) \equiv \frac{d}{d a} \ln \Gamma(a) \tag{2.277}
\end{aligned}
$$

である．

</div>

ディリクレ分布は$(2.38)$式から

$$
\operatorname{Dir}(\mathbf{\mu} \mid \mathbf{\alpha})=K(\mathbf{\alpha}) \prod_{k=1}^{M} \mu_{k}^{\alpha_{k}-1}
$$

である。ただし、簡単のために$\displaystyle K(\mathbf{\alpha})=\frac{\Gamma\left(\alpha_{0}\right)}{\Gamma\left(\alpha_{1}\right) \cdots \Gamma\left(\alpha_{M}\right)}$と置いた。ただし、$\alpha_0 = \sum_{k=1}^{M}\alpha_k$である（ちなみにPRML本文内の記述と違い、和の上限の文字が$K$から$M$に変更になっている）。

この設問で求める値はディリクレ分布の下での期待値なので、定義から$\displaystyle \mathbb{E}[\ln \mu_j] = \int \ln \mu_j \operatorname{Dir}(\mathbf{\mu} \mid \mathbf{\alpha}) d {\mu}$
である。

この設問の準備として以下の計算を行っておく。

$$
\frac{\partial}{\partial \alpha_j}\prod_{k=1}^{M}\mu_k^{\alpha_k-1}=\frac{\partial}{\partial \alpha_j}\prod_{k=1}^{M} \exp((\alpha_k-1)\ln \mu_k)
$$

これは$\exp\left((\alpha_j-1)\ln \mu_j\right)$のみ$\alpha_j$で微分すれば良いので

$$
\frac{\partial}{\partial \alpha_j}\left\{ \exp \left( (\alpha_j - 1) \ln \mu_j \right)\right\} = \ln \mu_j \exp\left( (\alpha_j - 1) \ln \mu_j \right)
$$
から、
$$
\frac{\partial}{\partial \alpha_j}\prod_{k=1}^{M}\mu_k^{\alpha_k-1}=\ln \mu_j \prod_{k=1}^M \exp((\alpha_k-1)\ln \mu_k)=\ln \mu_j \prod_{k=1}^{M}\mu_k^{\alpha_k-1}
$$
となる。

よって、

$$
\begin{aligned}
\mathbb{E}\left[\ln \mu_{j}\right] &=K(\mathbf{\alpha}) \int_{0}^{1} \cdots \int_{0}^{1} \ln \mu_{j} \prod_{k=1}^{M} \mu_{k}^{\alpha_{k}-1} \mathrm{d} \mu_{1} \ldots \mathrm{d} \mu_{M} \\
&=K(\mathbf{\alpha}) \frac{\partial}{\partial \alpha_{j}} \int_{0}^{1} \ldots \int_{0}^{1} \prod_{k=1}^{M} \mu_{k}^{\alpha_{k}-1} \mathrm{d} \mu_{1} \ldots \mathrm{d} \mu_{M} \\
&=K(\mathbf{\alpha}) \frac{\partial}{\partial \alpha_{j}} \frac{1}{K(\mathbf{\alpha})}
\end{aligned}
$$

最後はディリクレ分布が正規化されていること $\displaystyle  \int \operatorname{Dir}(\mathbf{\mu} \mid \mathbf{\alpha}) d \mathbf{\mu} = 1$から$\displaystyle \int_{0}^{1} \ldots \int_{0}^{1} \prod_{k=1}^{M} \mu_{k}^{\alpha_{k}-1} \mathrm{d} \mu_{1} \ldots \mathrm{d} \mu_{M} = \frac{1}{K(\alpha)}$となることを用いた。

この式についてさらに$\displaystyle K(\alpha) = \frac{\Gamma(\alpha_0)}{\prod_{i=1}^M \Gamma(\alpha_k)}$を使って展開すると

$$
\begin{aligned} \mathbb{E}\left[\ln \mu_{j}\right]
&=\frac{\Gamma\left(\alpha_{0}\right)}{\prod_{i=1}^{M} \Gamma\left(\alpha_{k}\right)} \frac{\partial}{\partial \alpha_{j}} \frac{\prod_{i=1}^{M} \Gamma\left(\alpha_{k}\right)}{\Gamma\left(\alpha_{0}\right)} \\
&=\frac{\Gamma\left(\alpha_{0}\right)}{\Gamma\left(\alpha_{j}\right)} \frac{\partial}{\partial \alpha_{j}} \frac{\Gamma\left(\alpha_{j}\right)}{\Gamma\left(\alpha_{0}\right)}\hspace{2em}\left(\because 約分 \right) \\
&=\frac{\Gamma\left(\alpha_{0}\right)}{\Gamma\left(\alpha_{j}\right)}
\left[
    \frac{1}{\left\{\Gamma\left(\alpha_{0}\right)\right\}^2}
        \left\{ \left( \frac{\partial}{\partial \alpha_{j}} \Gamma\left(\alpha_{j}\right) \right) \Gamma\left(\alpha_{0}\right)-\Gamma\left(\alpha_{j}\right)\left(\frac{\partial}{\partial \alpha_{j}} \Gamma\left(\alpha_{0}\right)\right)\right\}
\right] \\
&=\frac{1}{\Gamma\left(\alpha_{j}\right)}
    \left(\frac{\partial}{\partial \alpha_{j}} \Gamma\left(\alpha_{j}\right)\right) -\frac{1}{\Gamma\left(\alpha_{0}\right)}\left(\frac{\partial}{\partial \alpha_{j}} \Gamma\left(\alpha_{0}\right)\right)\\
&=\frac{\partial}{\partial \alpha_{j}} \ln \Gamma\left(\alpha_{j}\right)-\frac{1}{\Gamma\left(\alpha_{0}\right)}\left(\frac{\partial}{\partial \alpha_{0}} \frac{\partial \alpha_{0}}{\partial \alpha_{j}} \Gamma\left(\alpha_{0}\right)\right) \\
&=\frac{\partial}{\partial \alpha_{j}} \ln \Gamma\left(\alpha_{j}\right)-\frac{\partial}{\partial \alpha_{0}} \ln \Gamma\left(\alpha_{0}\right) \hspace{2em}
\left( \because \alpha_0 = \sum_{k=1}^M \alpha_k より, \frac{\partial \alpha_{0}}{\partial \alpha_{j}} = 1\right)
\end{aligned}
$$

最後にディガンマ関数の定義$\displaystyle \psi(a) \equiv \frac{d}{d a} \ln \Gamma(a)$を使うと

$$
\mathbb{E}\left[\ln \mu_{j}\right] = \psi(\alpha_j) - \psi(\alpha_0)
$$

が導かれる。

※ $\alpha_j, \alpha_0$は1変数なので偏微分記号$\partial$、全微分記号$d$どちらで微分しても結果は同じである。

## 演習 2.12
<div class="panel-primary">

連続変数$x$の一様分布は

$$
\mathrm{U}(x | a, b)=\frac{1}{b-a}, \quad a \leq x \leq b \tag{2.278}
$$

で定義される．この分布が正規化されていることを確かめ，この分布の平均と分散の式を求めよ．

</div>

まず$\displaystyle \int_a^b \frac{1}{b-a}dx = 1$を証明する。

$$
\int_a^b \frac{1}{b-a}dx = \frac{1}{b-a}\int_a^b1dx = \frac{1}{b-a}(b-a)=1
$$

よって分布が正規化されていることが示された。

分布の平均$\mathbb{E}[x]$は

$$
\mathbb{E}[x] = \int_a^b x \frac{1}{b-a}dx
=\frac{1}{b-a}\left[ \frac{x^2}{2} \right]_{a}^{b}
=\frac{b+a}{2}
$$

分布の分散は

$$
\begin{aligned}
\operatorname{var}[x]
&= \mathbb{E}[x^2]-(\mathbb{E}[x])^2 \\
&= \frac{1}{b-a}\left[ \frac{x^3}{3} \right]_{a}^{b}-\left( \frac{b+a}{2} \right)^2 \\
&= \frac{b^2+ab+a^2}{3}-\frac{b^2+2ab+a^2}{4} \\
&= \frac{(b-a)^2}{12}
\end{aligned}
$$

である。

## 演習 2.13
<div class="panel-primary">

2つのガウス分布$p(\mathbf{x})=\mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma})$と$q(\mathbf{x})=\mathcal{N}(\mathbf{x} | \boldsymbol{m}, \mathbf{L})$の間のカルバック-ライブラーダイバージェンス

$$
\begin{aligned}
\mathrm{KL}(p \| q) &=-\int p(\mathbf{x}) \ln q(\mathbf{x}) \mathrm{d} \mathbf{x}-\left(-\int p(\mathbf{x}) \ln p(\mathbf{x}) \mathrm{d} \mathbf{x}\right) \\
&=-\int p(\mathbf{x}) \ln \left\{\frac{q(\mathbf{x})}{p(\mathbf{x})}\right\} \mathrm{d} \mathbf{x} \tag{1.113}
\end{aligned}
$$

を求めよ．

</div>

※ 演習問題2.15とほぼ同じ操作を2回やるので、先に2.15をやってきたほうが良い。また、一般にガウス分布の指数部分では二次形式とトレースの関係を利用すると計算が楽になり見通しもよくなることが多い。「二次形式があればトレースを利用するかもしれない」くらいの心持ちを持っていると良いかもしれない。

問題文から
$$
\mathrm{KL}(p \| q) =-\int p(\mathbf{x}) \ln q(\mathbf{x}) d\mathbf{x}+\int p(\mathbf{x}) \ln p(\mathbf{x}) d\mathbf{x}
$$
に分解できる。

この第2項は演習問題2.15や付録(B.41)で求められるように（2.15の方を参照）、

$$
\int p(\mathbf{x}) \ln p(\mathbf{x}) d\mathbf{x} = -\frac{1}{2} \ln |\mathbf{\Sigma}| - \frac{D}{2}\left\{ 1 + \ln (2 \pi) \right\} \tag{1}
$$

である。そこで、第1項を求める。

$$
\begin{aligned}
    & -\int p(\mathbf{x}) \ln q(\mathbf{x}) d\mathbf{x} \\
    &=\int \mathcal{N}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Sigma}) \cdot \frac{1}{2}\left\{D \ln (2 \pi)+\ln |\mathbf{L}|+(\mathbf{x}-\mathbf{m})^{\mathrm{T}} \mathbf{L}^{-1}(\mathbf{x}-\mathbf{m})\right\} d \mathbf{x} \\
    &=\frac{1}{2}\left\{(D \ln (2 \pi)+\ln |\mathbf{L}|) \int \mathcal{N}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Sigma}) d \mathbf{x}\right\}+\frac{1}{2} \int \mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Sigma}\right) \operatorname{Tr}\left[(\mathbf{x}-\mathbf{m})^{\mathrm{T}} \mathbf{L}^{-1} (\mathbf{x}-\mathbf{m})\right] d\mathbf{x} \\
    &\hspace{2em} (\because 二次形式はスカラーなので \mathbf{x^{\mathrm{T}}\mathbf{\Sigma}\mathbf{x}} = \operatorname{Tr}[\mathbf{x^{\mathrm{T}}\mathbf{\Sigma}\mathbf{x}}] \\
    &=\frac{1}{2}\{D \ln (2 \pi)+\ln |\mathbf{L}|\}+\frac{1}{2} \int \mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Sigma}\right) \operatorname{Tr}\left[(\mathbf{x}-\mathbf{m})(\mathbf{x}-\mathbf{m})^{\mathrm{T}} \mathbf{L}^{-1}\right] d \mathbf{x} \\
    &\hspace{2em} (\because トレースの循環性\operatorname{Tr}[\mathbf{x^{\mathrm{T}}\mathbf{\Sigma}\mathbf{x}}] = \operatorname{Tr}[\mathbf{xx^{\mathrm{T}}\mathbf{\Sigma}}] )\\
    &=\frac{1}{2}\{D \ln (2 \pi)+\ln |\mathbf{L}|\}
    +\frac{1}{2}\left\{\left(\operatorname{Tr}\left[\int \mathcal{N}(\mathbf{x} \mid \boldsymbol{\mu}, \Sigma) \mathbf{xx}^{\mathrm{T}} \mathbf{L}^{-1}d \mathbf{x} \right]
    -\operatorname{Tr}\left[\int \mathcal{N}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Sigma}) \mathbf{x}\mathbf{m}^{\mathrm{T}} \mathbf{L}^{-1}d \mathbf{x} \right]-\operatorname{Tr}\left[\int \mathcal{N}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Sigma}) \mathbf{m} \mathbf{x}^{\mathrm{T}} \mathbf{L}^{-1} d \mathbf{x} \right]
    +\operatorname{Tr}\left[\int \mathcal{N}\left(\mathbf{x}|\boldsymbol{\mu}, \mathbf{\Sigma}\right) \mathbf{mm}^{\mathrm{T}} \mathbf{L}^{-1} d \mathbf{x}\right] \right) \right\} \\
    &=\frac{1}{2}\{D \ln (2 \pi)+\ln |\mathbf{L}|\}
    +\frac{1}{2}\left\{\operatorname{Tr}\left[\left(\boldsymbol{\mu\mu}^{\mathrm{T}}+\mathbf{\Sigma}\right) \mathbf{L}^{-1}\right]
    -\operatorname{Tr} \left[\boldsymbol{\mu} \mathbf{m}^{\mathrm{T}}\mathbf{L}^{-1}\right]
    -\operatorname{Tr}\left[\mathbf{m} \boldsymbol{\mu}^{\mathrm{T}} \mathbf{L}^{-1}\right]
    +\operatorname{Tr}\left[\mathbf{mm}^{\mathrm{T}} \mathbf{L}^{-1}\right] \right\}\\
    &=\frac{1}{2}\{D \ln (2 \pi)+\ln |\mathbf{L}|\}+\frac{1}{2}\left\{\operatorname{Tr}\left[\left(\boldsymbol{\mu\mu}^{\mathrm{T}}+\mathbf{\Sigma}\right)\mathbf{L}^{-1}\right]
    -\mathbf{m}^{\mathrm{T}}\mathbf{L}^{-1}\boldsymbol{\mu}
    -\boldsymbol{\mu}^{\mathrm{T}}\mathbf{L}^{-1}\mathbf{m}
    +\mathbf{m}^{\mathrm{T}}\mathbf{L}^{-1}\mathbf{m}
    \right\}\hspace{2em} (\because \operatorname{Tr}[\mathbf{x^{\mathrm{T}}\mathbf{\Sigma}\mathbf{x}}] = \mathbf{xx}^{\mathrm{T}}\mathbf{\Sigma} )
\end{aligned}
$$

これと$(1)$の結果から、

$$
\begin{aligned}
\mathrm{KL}(p \| q)
&=-\int p(\mathbf{x}) \ln q(\mathbf{x}) d\mathbf{x}+\int p(\mathbf{x}) \ln p(\mathbf{x}) d\mathbf{x} \\
&= \frac{1}{2}\left(\ln \frac{|\mathbf{L}|}{|\Sigma|}+\operatorname{Tr}\left[\left(\boldsymbol{\mu\mu}^{\mathrm{T}}+\mathbf{\Sigma}\right)\mathbf{L}^{-1}\right]
-\mathbf{m}^{\mathrm{T}} \mathbf{L}^{-1} \boldsymbol{\mu}
-\boldsymbol{\mu}^{\mathrm{T}} \mathbf{L}^{-1} \mathbf{m}
+\mathbf{m}^{\mathrm{T}} \mathbf{L}^{-1} \mathbf{m}-D\right)
\end{aligned}
$$

※ちなみに$\operatorname{Tr}(\mathbf{AB}) = \operatorname{Tr}(\mathbf{BA})$が成り立つので$\operatorname{Tr}\left[\left(\boldsymbol{\mu\mu}^{\mathrm{T}}+\mathbf{\Sigma}\right)\mathbf{L}^{-1}\right] = \operatorname{Tr}\left[\mathbf{L}^{-1}\left(\boldsymbol{\mu\mu}^{\mathrm{T}}+\mathbf{\Sigma}\right)\right]$でも良い（公式解答例の記述）。

※精度行列$\mathbf{L}^{-1}$は演習2.17の結果から一般性を失うことなく共分散行列$\mathbf{L}$を対称行列とおいても問題なく、演習2.22の結果から$\mathbf{L}^{-1}$も対称行列となるので$\mathbf{m}^{\mathrm{T}} \mathbf{L}^{-1} \boldsymbol{\mu}=\boldsymbol{\mu}^{\mathrm{T}} \mathbf{L}^{-1} \mathbf{m}$が成立するため、まとめて$2\mathbf{m}^{\mathrm{T}} \mathbf{L}^{-1} \boldsymbol{\mu}$と書いてもよい気がする。

## 演習 2.14
<div class="panel-primary">

この演習問題では，共分散が与えられているときに，エントロピーを最大にする多変量分布はガウス分布であることを示す．まず，分布$p(\mathbf{x})$のエントロピーは

$$
\mathrm{H}[\mathrm{x}]=-\int p(\mathrm{x}) \ln p(\mathrm{x}) \mathrm{d} \mathrm{x} \tag{2.279}
$$

である．そして，分布$p(\mathbf{x})$が正規化されていることと，平均と共分散が固定されているということを示す制約式

$$
\int p(\mathbf{x}) \mathrm{d} \mathbf{x}=1 \tag{2.280}
$$

$$
\int p(\mathbf{x}) \mathbf{x} \mathrm{d} \mathbf{x}=\boldsymbol{\mu} \tag{2.281}
$$

$$
\int p(\mathbf{x})(\mathbf{x}-\boldsymbol{\mu})(\mathbf{x}-\boldsymbol{\mu})^{\mathrm{T}} \mathrm{d} \mathbf{x}=\mathbf{\Sigma} \tag{2.282}
$$

を満たすすべての分布中で，この$\mathrm{H}[\mathbf{x}]$を最大化したい制約$(2.280)$,$(2.281)$，および$(2.282)$を扱うためにラグランジュ乗数を用い，$（2.279)$を変分最大化し，尤度を最大にする分布がガウス分布$(2.43)$であることを示せ．

</div>

ラグランジュ乗数を用いて、$\mathrm{H}[\mathbf{x}]$を最大化する、そのため、ラグランジュ乗数として、定数、$D$次元ベクトルと$D*D$次元の行列を定義して代入すると

$$
\begin{aligned}
\widetilde{H}[p] &= -\int{p(\mathbf{x})\ln{p(\mathbf{x})}}\mathrm{d}\mathbf{x} + \lambda(\int{p(\mathbf{x})}\mathrm{d}\mathbf{x}-1)\\
&+ \mathbf{m}^\top (\int{p(\mathbf{x})\mathbf{x}}\mathrm{d}\mathbf{x}-\boldsymbol{\mu})\\
&+ \mathbf{tr}\{\mathbf{L}\int{p(\mathbf{x})(\mathbf{x} - \boldsymbol{\mu})(\mathbf{x}-\boldsymbol{\mu})^\top}\mathrm{d}\mathbf{x} - \mathbf{\Sigma}\}\\
\end{aligned}
$$

となる．

この式の導関数を求め,さらに導関数を0にした時の$p(\mathbf{x})$を求めよう。

$$
\begin{aligned}
\frac{\mathrm{d}\widetilde{H}[p(\mathbf{x})]}{\mathrm{d}p(\mathbf{x})} &= -1-\ln{p(\mathbf{x})} + \lambda + \mathbf{m}^\top \mathbf{x} + \mathbf{tr}\{\mathbf{L}(\mathbf{x} - \boldsymbol{\mu})(\mathbf{x} - \boldsymbol{\mu})^\top\}\\
\frac{\mathrm{d}\widetilde{H}[p(\mathbf{x})]}{\mathrm{d}p(\mathbf{x})} &= 0\\
\ln{p(\mathbf{x})} &=  -1+ \lambda + \mathbf{m}^\top \mathbf{x} + \mathbf{tr}\{\mathbf{L}(\mathbf{x} - \boldsymbol{\mu})(\mathbf{x} - \boldsymbol{\mu})^\top\}\\
p(\mathbf{x}) &= \mathrm{exp}\{\lambda -1+ \mathbf{m}^\top \mathbf{x} + \mathbf{tr}\{\mathbf{L}(\mathbf{x} - \boldsymbol{\mu})(\mathbf{x} - \boldsymbol{\mu})^\top\}\}\\
&= \mathrm{exp}\{\lambda - 1 + \mathbf{y}^\top \mathbf{L}\mathbf{y} + \boldsymbol{\mu} ^\top \mathbf{m} - \frac{1}{4}\mathbf{m}^\top\mathbf{L}^{-1}\mathbf{m}\}\\
\end{aligned}
$$


となる，ただし$\mathbf{y} = \mathbf{x} - \mu + \frac{1}{2}\mathbf{L}^{-1}\mathbf{m}$.

また$p(\mathbf{x})$は制約$(2.280)$,$(2.281)$，および$(2.282)$を満たし，$p(\mathbf{x})$を$(2.280)$,$(2.281)$に代入すると

$$
\begin{aligned}
\int{\mathrm{exp}\{\lambda - 1 + \mathbf{y}^\top \mathbf{L}\mathbf{y} + \boldsymbol{\mu} ^\top \mathbf{m} - \frac{1}{4}\mathbf{m}^\top\mathbf{L}^{-1}\mathbf{m}\}}\mathrm{d}\mathbf{y} &= 1\\
\int{\mathrm{exp}\{\lambda - 1 + \mathbf{y}^\top \mathbf{L}\mathbf{y} + \boldsymbol{\mu} ^\top \mathbf{m} - \frac{1}{4}\mathbf{m}^\top\mathbf{L}^{-1}\mathbf{m}\}(\mathbf{y} + \boldsymbol{\mu} - \frac{1}{2}\mathbf{L}^{-1}\mathbf{m})}\mathrm{d}\mathbf{y} &= \boldsymbol{\mu}\\
\end{aligned}
$$

$$
\begin{aligned}
(\boldsymbol{\mu} - \frac{1}{2}\mathbf{L}^{-1}\mathbf{m})\int{\mathrm{exp}\{\lambda - 1 + \mathbf{y}^\top \mathbf{L}\mathbf{y} + \boldsymbol{\mu} ^\top \mathbf{m} - \frac{1}{4}\mathbf{m}^\top\mathbf{L}^{-1}\mathbf{m}\}}\mathrm{d}\mathbf{y} \\+ \int{\mathrm{exp}\{\lambda - 1 + \mathbf{y}^\top \mathbf{L}\mathbf{y} + \boldsymbol{\mu} ^\top \mathbf{m} - \frac{1}{4}\mathbf{m}^\top\mathbf{L}^{-1}\mathbf{m}\}\mathbf{y}}\mathrm{d}\mathbf{y} = \boldsymbol{\mu}\\
\boldsymbol{\mu} - \frac{1}{2}\mathbf{L}^{-1}\mathbf{m} = \boldsymbol{\mu}\\
\end{aligned}
$$

となって，$\mathbf{m}=\mathbf{0}$であることが分かって，$p(\mathbf{x}) = \mathrm{exp}\{\lambda - 1 + (\mathbf{x}-\boldsymbol{\mu})^\top \mathbf{L}(\mathbf{x}-\boldsymbol{\mu})\}$となる．

さらに，$(2.282)$に代入すると

$$
\begin{aligned}
\int{\mathrm{exp}\{\lambda - 1 + (\mathbf{x} - \boldsymbol{\mu})\mathbf{L}(\mathbf{x} - \boldsymbol{\mu})^\top\}(\mathbf{x} - \boldsymbol{\mu})(\mathbf{x} - \boldsymbol{\mu})^\top}\mathrm{d}\mathbf{x} &= \mathbf{\Sigma}\\
\end{aligned}
$$

となる．$\mathbf{z} = \mathbf{x} - \boldsymbol{\mu}$で書き換えると

$$
\begin{aligned}
\int{\mathrm{exp}\{\lambda - 1 + \mathbf{z}\mathbf{L}\mathbf{z}^\top\}\mathbf{z}\mathbf{z}^\top}\mathrm{d}\mathbf{x} &= \mathbf{\Sigma}\\
\mathrm{exp}(\lambda - 1)\int{\mathrm{exp}\{\mathbf{z}\mathbf{L}\mathbf{z}^\top\}\mathbf{z}\mathbf{z}^\top}\mathrm{d}\mathbf{x} &= \mathbf{\Sigma}\\
\end{aligned}
$$

となる．$(2.61)$と比較すると，$\mathbf{L} = -\frac{1}{2} \Sigma^{-1}$であることがわかる．

またここで，$\mathrm{exp}(\lambda - 1)$は正規化されていることを保証しているため

$$
\begin{aligned}
\mathrm{exp}(\lambda - 1) &= \frac{1}{(2\pi)^\frac{1}{2}}\frac{1}{|\mathbf{\Sigma}|^\frac{1}{2}}\\
\lambda &= \ln\left\{\frac{1}{(2\pi)^\frac{1}{2}}\frac{1}{|\mathbf{\Sigma}|^\frac{1}{2}}\right\} + 1
\end{aligned}
$$

となる．

## 演習 2.15
<div class="panel-primary">

多変量ガウス分布$\mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma})$のエントロピーが

$$
\mathrm{H}[\mathbf{x}]=\frac{1}{2} \ln |\mathbf{\Sigma}|+\frac{D}{2}(1+\ln (2 \pi)) \tag{2.283}
$$

となることを示せ．ただし，$D$は$\mathbf{x}$の次元数である．

</div>

エントロピーの定義の式$(1.104)$に直接ガウス分布の式$(2.43)$を代入して式を変形していく。ガウス分布が正規化されていること$\displaystyle \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \mathrm{d} \mathbf{x} = 1$を利用する。

$$
\begin{aligned}
\mathrm{H}[\mathbf{x}]
&=-\int p(\mathbf{x}) \ln p(\mathbf{x}) \mathrm{d} \mathbf{x}\\
&=-\int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \ln \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \mathrm{d} \mathbf{x} \\
&= \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \cdot \frac{1}{2} \{ D \ln(2 \pi) + \ln |\mathbf{\Sigma}| + (\mathbf{x} - \boldsymbol{\mu})^T \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) \} \mathrm{d} \mathbf{x} \\
&= \frac{1}{2} \left\{ D \ln(2 \pi) \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \mathrm{d} \mathbf{x} + \ln |\mathbf{\Sigma}| \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \mathrm{d} \mathbf{x} + \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) (\mathbf{x} - \boldsymbol{\mu})^\mathrm{T} \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) \mathrm{d} \mathrm{x} \right\} \\
&= \frac{1}{2} \left\{ D \ln(2 \pi) \cdot 1 + \ln |\mathbf{\Sigma}| \cdot 1 + \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) (\mathbf{x} - \boldsymbol{\mu})^\mathrm{T} \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) \mathrm{d} \mathbf{x} \right\}
\end{aligned}
$$

ここで、第3項$\displaystyle \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) (\mathbf{x} - \boldsymbol{\mu})^\mathrm{T} \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) \mathrm{d} \mathbf{x}$について、**二次形式とトレースの関係の式**$\mathbf{x}^{\mathrm{T}}\mathbf{A}\mathbf{x} = \mathrm{Tr}(\mathbf{Axx}^{\mathrm{T}})$を使って変形する。これは任意の$m \times n$行列$\mathbf{M}$と$n \times m$行列$\mathbf{N}$に対して$\mathrm{Tr}(\mathbf{MN}) = \mathrm{Tr}(\mathbf{NM})$が成立する（統計のための行列代数 上巻 第5章 補助定理5.2.1）ことから容易に示せる（下記）。また、トレースの値はスカラーであり、任意のスカラー$k$と任意の正方行列$\mathbf{A}$, $\mathbf{B}$に対して以下の性質（**トレースの線形性**）が成立することを利用する（※統計のための行列代数 上巻 第5章 5.1）。

$$
\begin{aligned}
\mathrm{Tr}(k\mathbf{A}) &= k\mathrm{Tr}(\mathbf{A}) \\
\mathrm{Tr}(\mathbf{A}+\mathbf{B}) &= \mathrm{Tr}({\mathbf{A}}) + \mathrm{Tr}({\mathbf{B}})
\end{aligned}
$$

また、$\mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma})$はスカラーであるので、$\displaystyle \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \mathrm{Tr}(\mathbf{A}) = \mathrm{Tr}(\mathbf{\mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) A})$と変形できる。

以上から、
$$
\begin{aligned}
    & \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) (\mathbf{x} - \boldsymbol{\mu})^\mathrm{T} \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) \mathrm{d} \mathbf{x} \\
    =& \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \mathrm{Tr
    }\left( \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) (\mathbf{x} - \boldsymbol{\mu})^\mathrm{T} \right)\mathrm{d} \mathbf{x} \\
    =& \int \mathrm{Tr} \left[ \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \left( \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) (\mathbf{x} - \boldsymbol{\mu})^\mathrm{T} \right)\right]\mathrm{d} \mathbf{x} \\
    =& \int \mathrm{Tr} \left[ \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) (\mathbf{x} \mathbf{x}^\mathrm{T} - \mathbf{x} \boldsymbol{\mu}^\mathrm{T} - \boldsymbol{\mu} \mathbf{x}^\mathrm{T} + \boldsymbol{\mu} \boldsymbol{\mu}^\mathrm{T}) \mathbf{\Sigma}^{-1} \right] \mathrm{d} \mathbf{x} \hspace{1em} (\because \mathrm{Tr}(\mathbf{MN}) = \mathrm{Tr}(\mathbf{NM})) \\
    =& \int \mathrm{Tr} \left[ \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) (\mathbf{x} \mathbf{x}^\mathrm{T} - 2\mathbf{x} \boldsymbol{\mu}^\mathrm{T} + \boldsymbol{\mu} \boldsymbol{\mu}^\mathrm{T}) \mathbf{\Sigma}^{-1} \right] \mathrm{d} \mathbf{x} \hspace{1em} (\because \mathrm{Tr}(\mathbf{x}\boldsymbol{\mu}^{\mathrm{T}}) = \mathrm{Tr}(\boldsymbol{\mu}\mathbf{x}^{\mathrm{T}}))\\
    =& \int \mathrm{Tr} [ \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \mathbf{xx}^\mathrm{T} \mathbf{\Sigma}^{-1} ] \mathrm{d} \mathbf{x}
    -2 \int \mathrm{Tr} [ \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma})\mathbf{x} \boldsymbol{\mu}^\mathrm{T} \mathbf{\Sigma}^{-1} ]\mathrm{d} \mathbf{x}
    + \int \mathrm{Tr} [ \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma})\boldsymbol{\mu} \boldsymbol{\mu}^\mathrm{T} \mathbf{\Sigma}^{-1} ] \mathrm{d} \mathbf{x} \\
    =& \mathrm{Tr} \left[ \left\{ \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \mathbf{xx}^\mathrm{T} \mathrm{d} \mathbf{x} -2 \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma})\mathbf{x} \boldsymbol{\mu}^\mathrm{T} \mathrm{d} \mathbf{x} + \int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma})\boldsymbol{\mu} \boldsymbol{\mu}^\mathrm{T} \right\} \mathbf{\Sigma}^{-1}\right] \\
\end{aligned}
$$

ここで、$(2.59)$と$(2.62)$より

$$\int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \mathbf{x} \mathrm{d} \mathbf{x} = \boldsymbol{\mu}$$

$$\int \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \mathbf{\Sigma}) \mathbf{xx}^\mathrm{T} \mathrm{d} \mathbf{x} = \boldsymbol{\mu\mu}^\mathrm{T} + \mathbf{\Sigma}$$

ゆえに

$$
\begin{aligned}
    \mathrm{H}[\mathbf{x}]
    &= \frac{1}{2} \{ D \ln(2 \pi) + \ln |\mathbf{\Sigma}| + \mathrm{Tr}[ \{ (\boldsymbol{\mu} \boldsymbol{\mu}^\mathrm{T} + \mathbf{\Sigma}) - 2 \boldsymbol{\mu} \boldsymbol{\mu}^T + \boldsymbol{\mu} \boldsymbol{\mu}^\mathrm{T} \} \mathbf{\Sigma}^{-1}  ]\} \\
    &= \frac{1}{2} \{ D \ln(2 \pi) + \ln |\mathbf{\Sigma}| + \mathrm{Tr}[  \mathbf{\Sigma} \mathbf{\Sigma}^{-1}] \} \\
    &= \frac{1}{2} \{ D \ln(2 \pi) + \ln |\mathbf{\Sigma}| + \mathrm{Tr}[ \mathbf{I} ] \} \\
    &= \frac{1}{2} \{ D \ln(2 \pi) + \ln |\mathbf{\Sigma}| + D \} \\
    &= \frac{1}{2} \ln |\mathbf{\Sigma}| + \frac{D}{2}\left\{ 1 + \ln (2 \pi) \right\}
\end{aligned}
$$

したがって題意が示された。

※ 二次形式とトレースの関係$\mathbf{x}^{\mathrm{T}}\mathbf{A}\mathbf{x} = \mathrm{Tr}(\mathbf{Axx}^{\mathrm{T}})$の証明は、任意の$m \times n$行列$\mathbf{M}$と$n \times m$行列$\mathbf{N}$に対して$\mathrm{Tr}(\mathbf{MN}) = \mathrm{Tr}(\mathbf{NM})$が成立する（統計のための行列代数 上巻 第5章 補助定理5.2.1）ことを利用すれば以下のようにして簡単に求められる。

まず二次形式の値はスカラー（$1 \times 1$行列）なので$\mathbf{x}^{\mathrm{T}}\mathbf{A}\mathbf{x} = \mathrm{Tr}(\mathbf{x}^{\mathrm{T}}\mathbf{A}\mathbf{x})$となる。ここで、$\mathrm{Tr}(\mathbf{MN}) = \mathrm{Tr}(\mathbf{NM})$の定理において$\mathbf{M} = \mathbf{x}^{\mathrm{T}}$, $\mathbf{N} = \mathbf{Ax}$とすれば$\mathrm{Tr}(\mathbf{x}^{\mathrm{T}}\mathbf{A}\mathbf{x}) = \mathrm{Tr}(\mathbf{A}\mathbf{x}\mathbf{x}^{\mathrm{T}})$となるので、$\mathbf{x}^{\mathrm{T}}\mathbf{A}\mathbf{x} = \mathrm{Tr}(\mathbf{Axx}^{\mathrm{T}})$となることが示された。

## 演習 2.16
<div class="panel-primary">

2つの確率変数$x_1$と$x_2$を考える．これらはそれぞれ平均が$\mu_1$と$\mu_2$で，精度が$\tau_1$と$\tau_2$のガウス分布に従うとする．このとき，変数$x=x_1+x_2$の微分エントロピーの式を導出せよ．これには，まず，次の関係を用いて$x$の分布を求め，指数部分を平方完成する．

$$
p(x)=\int_{-\infty}^{\infty} p\left(x | x_{2}\right) p\left(x_{2}\right) \mathrm{d} x_{2} \tag{2.284}
$$

次に，これが2つのガウス分布のたたみ込みになっており，また，これ自体もガウス分布になっていることに注目する.最後に1変数のガウス分布のエントロピーの結果

$$
\mathrm{H}[x] = \frac{1}{2}\{ 1+\ln(2\pi\sigma^2) \} \tag{1.110}
$$

を利用する．

</div>

$x_1$、$x_2$について、問題文の条件より

$$p(x_1) = \mathcal{N}(x_1 | \mu_1, \gamma_1^{-1})$$

$$p(x_2) = \mathcal{N}(x_2 | \mu_2, \gamma_2^{-1})$$

変数$x = x_1 + x_2$について、$x_2$が観測され固定された数とみなすと、$x$は$x_1$の線形関数とみなせる。

よって$p(x|x_2)$の分布の平均は$x_1$の平均$\mu_1$に$x_2$を足したものとなり、分散は$x_1$の分散$\gamma_1^{-1}$となる。

ゆえに

$$p(x|x_2) = \mathcal{N}(x | \mu_1 + x_2, \gamma_1^{-1})$$

(2.284)より

$$\begin{aligned}p(x) &= \int_{-\infty}^{\infty} \mathcal{N}(x | \mu_1 + x_2, \gamma_1^{-1}) \cdot \mathcal{N}(x_2 | \mu_2, \gamma_2^{-1}) \mathrm{d} x_2 \\&=  \int_{-\infty}^{\infty} \left( \frac{\gamma_1}{2 \pi} \right)^{\frac{1}{2}} \exp \left\{- \frac{\gamma_1}{2} (x - \mu_1 - x_2)^2 \right\} \cdot \left( \frac{\gamma_2}{2 \pi} \right)^{\frac{1}{2}} \exp \left\{- \frac{\gamma_2}{2} (x_2 - \mu_2)^2 \right\} \mathrm{d} x_2 \\&= \int_{-\infty}^{\infty} \left( \frac{\gamma_1}{2 \pi} \right)^{\frac{1}{2}} \left( \frac{\gamma_2}{2 \pi} \right)^{\frac{1}{2}} \exp \left\{- \frac{\gamma_1}{2} (x - \mu_1 - x_2)^2 -   \frac{\gamma_2}{2} (x_2 - \mu_2)^2 \right\} \mathrm{d} x_2 \end{aligned}$$

この式の指数部分を$x_2$について平方完成すると

$$\begin{aligned} - \frac{\gamma_1}{2} (x - \mu_1 - x_2)^2 -   \frac{\gamma_2}{2} (x_2 - \mu_2)^2 &= - \frac{1}{2} (\gamma_1 + \gamma_2) x_2^2 + \{ \gamma_1(x - \mu_1) + \gamma_2 \mu_2 \} x_2 - \frac{\gamma_1}{2}(x - \mu_1)^2 - \frac{\gamma_2}{2} \mu_2^2 \\&= - \frac{1}{2} (\gamma_1 + \gamma_2) \left\{ x_2 - \frac{\gamma_1 (x - \mu_1) + \gamma_2 \mu_2}{\gamma_1 + \gamma_2} \right\}^2 + \frac{\{\gamma_1 (x - \mu_1) + \gamma_2 \mu_2\}^2}{2 (\gamma_1 + \gamma_2)} - \frac{\gamma_1}{2}(x - \mu_1)^2 - \frac{\gamma_2}{2} \mu_2^2  \end{aligned}$$

ここで、

$$m = \frac{\gamma_1 (x - \mu_1) + \gamma_2 \mu_2}{\gamma_1 + \gamma_2}$$

と置くと、指数部分の式は以下のように表せる。

$$- \frac{\gamma_1 + \gamma_2}{2}  \left( x_2 - m \right)^2 + \frac{\{\gamma_1 (x - \mu_1) + \gamma_2 \mu_2\}^2}{2 (\gamma_1 + \gamma_2)} - \frac{\gamma_1}{2}(x - \mu_1)^2 - \frac{\gamma_2}{2} \mu_2^2$$

この式の$x_2$への依存性を見てみると、ガウス分布の標準的な二次形式部分である第一項に、$x_2$に依存しない項を足したものとなっている。

ここで$x_2$を積分消去すると、指数部分の式は第二項以降となる。

$x$の精度は指数部分の式の$x^2$の係数で直接与えられるため、上記式の第二項以降の項において$x^2$の係数を計算すると

$$\begin{aligned} \frac{\{\gamma_1 (x - \mu_1) + \gamma_2 \mu_2\}^2}{2 (\gamma_1 + \gamma_2)} - \frac{\gamma_1}{2}(x - \mu_1)^2 - \frac{\gamma_2}{2} \mu_2^2 &= \frac{\gamma_1^2}{2 (\gamma_1 + \gamma_2)} x^2 - \frac{\gamma_1}{2} x^2 + \text{const} \\&= - \frac{1}{2} \frac{\gamma_1 \gamma_2}{\gamma_1 +  \gamma_2} x^2 + \text{const} \end{aligned}$$

ただし、$\text{const}$は$x^2$に依存しない数を表す。

ガウス分布の式(2.42)との比較から、$x$の精度を$\gamma$とすると

$$\gamma = \frac{\gamma_1 \gamma_2}{\gamma_1 +  \gamma_2}$$
が得られる。

$(1.110)$の式から微分エントロピーは

$$\begin{aligned}\mathrm{H}[\mathbf{x}] &= \frac{1}{2} \left\{ 1 + \ln \left( \frac{2 \pi}{\gamma} \right) \right\} \\&= \frac{1}{2} \left\{ 1 + \ln \left( \frac{2 \pi (\gamma_1 + \gamma_2)}{\gamma_1 \gamma_2} \right) \right\}  \end{aligned}$$

## 演習 2.17
<div class="panel-primary">

$(2.43)$の多変量ガウス分布を考える精度行列（逆共分散行列）$\mathbf{\Sigma^{-1}}$を対称行列と反対称行列（歪対称行列）の和の形で書くと，反対称行列の項がガウス分布の指数部分には現れなくなるため，一般性を失うことなく精度行列は対称であるとしてよいことを示せ．この結果から，対称行列の逆行列も対称（演習2.22）なので，一般性を失うことなく，共分散行列にも対称なものを選んでよいことになる．

</div>

※ 演習1.14とやろうとしていることはほぼ同じです．行列の二次形式・対称行列・反対称行列についての定理をよく知っていれば瞬殺です．「統計のための行列代数」の第14章の補助定理14.1.1, 補助定理14.6.3あたりに出てきます．

補助定理14.6.3

$n\times n$行列の$\mathbf{A}$は，あらゆる$n$次元ベクトル$\mathbf{x}$に対して，$\mathbf{x'Ax}=0$のときかつそのときに限って，歪対称行列（反対称行列）である.

また，任意の正方行列$\mathbf{M}$は対称行列$\mathbf{A}$と反対称行列$\mathbf{S}$の和でただ1通りに表現できることも必要です．先にそれを示します．


ちなみに対称行列$\mathbf{A}$と反対称行列$\mathbf{S}$の一般形は次の通り．
$$
\mathbf{A}=\left(
	\begin{array}{ccccc}a_{11} & a_{12} & a_{13} & \cdots & a_{1 n} \\ a_{12} & a_{22} & a_{23} & \cdots & a_{2 n} \\ a_{13} & a_{23} & a_{33} & \cdots & a_{3 n} \\ \vdots & \vdots & & \ddots & \vdots \\ a_{1 n} & a_{2 n} & a_{3 n} & \cdots & a_{n n}\end{array}
\right)
$$

$$
\mathbf{S}=\left(
	\begin{array}{ccccc}0 & s_{12} & s_{13} & \cdots & s_{1 n} \\ -s_{12} & 0 & s_{23} & \cdots & s_{2 n} \\ -s_{13} & -s_{23} & 0 & \cdots & s_{3 n} \\ \vdots & \vdots & & \ddots & \vdots \\ -s_{1 n} & -s_{2 n} & -s_{3 n} & \cdots & 0\end{array}
\right)
$$

（証明）

任意の正方行列$\mathbf{M}$に対し，$\mathbf{(M+M}^{\mathrm{T}})^{\mathrm{T}}=\mathbf{M}^{\mathrm{T}}+{\mathbf M}$なので，$\mathbf{M}+\mathbf{M}^{\mathrm{T}}$は対称行列である．また，$\mathbf{(M-M}^{\mathrm{T}})^{\mathrm{T}}=-({\mathbf M}-\mathbf{M}^{\mathrm{T}})$なので，$\mathbf{M}-{\mathbf M}^{\mathrm{T}}$は反対称行列である．

よって，$\displaystyle{\mathbf{A}=\frac{\mathbf{M}+\mathbf{M}^{\mathrm{T}}}{2}, \mathbf{S}=\frac{\mathbf{M}-\mathbf{M}^{\mathrm{T}}}{2}}$とすれば，任意の正方行列$\mathbf{M}$は対称行列$\mathbf{A}$と反対称行列$\mathbf{S}$の和で表せることが示される．

また，これが1通りでのみ表せることを示す．そのために$\mathbf{M}=\mathbf{A}_{1}+\mathbf{S}_{1}=\mathbf{A}_{2}+\mathbf{S}_{2}$と仮定する．ここで，$\mathbf{A}_1,\mathbf{A}_2$は対称行列，$\mathbf{S}_1,\mathbf{S}_2$は反対称行列である．
上式を移行すると$\mathbf{S}_{1}-\mathbf{S}_{2}=\mathbf{A}_{2}-\mathbf{A}_{1}$であるが，$\mathbf{S}_{1}-\mathbf{S}_{2}$は反対称行列，$\mathbf{A}_{2}-\mathbf{A}_{1}$は対称行列となる．よって，これを満たすのは

$$
\mathbf{S}_{1}-\mathbf{S}_{2}=\mathbf{A}_{2}-\mathbf{A}_{1} = \mathbf{O}
$$
のときのみであり，$\mathbf{S}_{1}=\mathbf{S}_{2}$, $\mathbf{A}_{1}=\mathbf{A}_{2}$となる．したがって一意性が示された．

これにより，精度行列$\mathbf{\Sigma}^{-1}$も対称行列$\frac{\mathbf{\Sigma}^{-1}+(\mathbf{\Sigma}^{-1})^{\mathrm T}}{2}$, 反対称行列$\frac{\mathbf{\Sigma}^{-1}-(\mathbf{\Sigma}^{-1})^{\mathrm T}}{2}$に分解できる．

ガウス分布の二次形式部分（マハラノビス距離の部分）$\Delta^2 = (\mathbf{x}-\boldsymbol{\mu})^{\mathrm T}\mathbf{\Sigma^{-1}}(\mathbf{x}-\boldsymbol{\mu})$の$\mathbf{\Sigma^{-1}}$の反対称要素は消えることを示す．

$\mathbf{\Sigma^{-1}}=\mathbf{A}+\mathbf{S}$と書く．ここで$\mathbf{A}$は対称行列，$\mathbf{S}$は反対称行列．

ここで，任意の$D$次元ベクトル$\mathbf{y}$と$D\times D$の反対称行列$\mathbf{S}$について，

$$
\mathbf{y}^{\mathrm T}{\mathbf{S}}{\mathbf{y}}=0
$$

が成立することを示す（上述の補助定理14.6.3）．任意の$D\times D$の行列$\mathbf{M}$を使うと

$$
\begin{aligned}
\mathbf{y}^{\mathrm T}{\mathbf{S}}{\mathbf{y}} &=\sum_{j=1}^{D}\left(\sum_{i=1}^{D} y_{i} S_{i j}\right) y_{j} \\
&=\sum_{j=1}^{D} \sum_{i=1}^{D} y_{i} \cdot \frac{M_{ij}-M_{ji}}{2}\cdot y_{j} \\
&=\frac{1}{2} \left\{ \sum_{j=1}^{D} \sum_{i=1}^{D} y_{i} M_{ij} y_{j}-\sum_{j=1}^{D} \sum_{i=1}^{D} y_{j} M_{ji} y_{i}\right\} \\
&=0
\end{aligned}
$$
よって，

$$
\begin{aligned}
\Delta^{2} &=(\mathbf{x}-\boldsymbol{\mu})^{\mathrm{T}}(\mathbf{A}+\mathbf{S})(\mathbf{x}-\boldsymbol{\mu}) \\
&=(\mathbf{x}-\boldsymbol{\mu})^{\mathrm{T}} \mathbf{A}(\mathbf{x}-\boldsymbol{\mu})
\end{aligned}
$$

つまり，反対称要素が消えることが示された．

## 演習 2.18
<div class="panel-primary">

実対称行列$\mathbf{\Sigma}$を考える．この行列について$(2.45)$

$$
\mathbf{\Sigma}\mathbf{u}_i = \lambda_i\mathbf{u}_i
$$

の固有値の方程式が成立する．この式の複素共役から，もとの式を引いた後，固有ベクトル$\mathbf{u}_i$との内積をとることで，固有値$\lambda_i$が実数となることを示せ．同様に，$\mathbf{\Sigma}$の対称性を用いて，2つの固有ベクトル$\mathbf{u}_i$と$\mathbf{u}_j$が，$\lambda_j \neq \lambda_i$であれば，直交することを示せ．最後に，たとえいくつかの固有値が0であっても，一般性を失うことなく，$(2.46)$式 $\mathbf{u}_i^{\mathrm{T}}\mathbf{u}_j = I_{ij}$を満たす，正規直交となるように固有ベクトル集合を選ぶことが可能であることを示せ．

</div>

この問題は以下の3つの問題を証明していくことになる。

① **対称行列の固有値は実数となる。**
② **異なる固有値に対応する固有ベクトル同士は直交する。**
③ **いくつかの固有値が0であっても、正規直交となるように固有ベクトル集合を選ぶことができる。**

<br>

① **対称行列の固有値は実数となる。**

$(2.45)$式

$$
\mathbf{\Sigma}\mathbf{u}_i = \lambda_i\mathbf{u}_i
$$

に左から随伴行列$\mathbf{u}_i^{\dagger}$をかけると（$\lambda_i$はスカラー値であることに注意する）

$$
\mathbf{u}_i^{\dagger}\mathbf{\Sigma}\mathbf{u}_i = \mathbf{u}_i^{\dagger}\lambda_i\mathbf{u}_i
$$

$$
\mathbf{u}_i^{\dagger}\mathbf{\Sigma}\mathbf{u}_i = \lambda_i\mathbf{u}_i^{\dagger}\mathbf{u}_i \tag{1}
$$

また$(2.45)$式の両辺の複素共役をとり、右から$\mathbf{u}_i$をかける。$(\mathbf{\Sigma u_i})^{\dagger}=\mathbf{u}_i^{\dagger}\mathbf{\Sigma}^{\dagger}=\mathbf{u}_i^{\dagger}\mathbf{\Sigma}$、 $\bar{\lambda_i}$を$\lambda_i$の複素共役として

$$
(\mathbf{\Sigma u_i})^{\dagger}\mathbf{u}_i = (\lambda_i\mathbf{u}_i)^{\dagger}\mathbf{u}_i
$$

$$
\mathbf{u}_i^{\dagger}\mathbf{\Sigma}\mathbf{u}_i = \bar{\lambda_i}\mathbf{u}_i^{\dagger}\mathbf{u}_i \tag{2}
$$


よって(1)(2)式の差を取ると

$$
0 = (\lambda_i - \bar{\lambda_i})\mathbf{u_i}^{\dagger}\mathbf{u_i}
$$
となる。$\mathbf{u_i}^{\dagger}\mathbf{u_i}$は$0$ではないため、$\lambda_i = \bar{\lambda_i}$、つまり$\lambda_i$が実数となることが示された。

<br>

② **異なる固有値に対応する固有ベクトル同士は直交する。**

次に$(2.45)$式の左側から$\mathbf{u_j}^{\mathrm{T}}$をかける

$$
\mathbf{u}_j^{\mathrm{T}}\mathbf{\Sigma}\mathbf{u}_i = \mathbf{u}_j^{\mathrm{T}}\lambda_i\mathbf{u}_i
$$

$$
\mathbf{u}_j^{\mathrm{T}}\mathbf{\Sigma}\mathbf{u}_i = \lambda_i\mathbf{u}_j^{\mathrm{T}}\mathbf{u}_i
$$

$$
\begin{aligned}
\lambda_i\mathbf{u}_j^{\mathrm{T}}\mathbf{u}_i &= \mathbf{u}_j^{\mathrm{T}}\mathbf{\Sigma}\mathbf{u}_i \\
&= (\mathbf{\Sigma}\mathbf{u}_j)^{\mathrm{T}}\mathbf{u}_i \\
&= (\lambda_j\mathbf{u}_j)^{\mathrm{T}}\mathbf{u}_i \\
&= \lambda_j\mathbf{u}_j^{\mathrm{T}}\mathbf{u}_i
\end{aligned}
$$
ここで$\lambda_i \neq \lambda_j$であれば上式から$\mathbf{u}_j^{\mathrm{T}}\mathbf{u}_i=0$となるので、$\mathbf{u}_i$,$\mathbf{u}_j$が直交していることが示された。この固有ベクトルは定数倍して$\mathbf{u}_i \to \mathbf{u}_i/||\mathbf{u}_i||$というように正規化すれば$(2.46)$式を満足させることができる。

（※統計のための行列代数下巻 P.238 定理21.4.5と同じ）

ちなみに、同じ固有値$\lambda(\neq0)$に対する2個の固有ベクトル$\mathbf{u}_i, \mathbf{u}_j$が存在したとき、この線型結合$a_i\mathbf{u}_i+a_j\mathbf{u}_j$について

$$
\mathbf{\Sigma}(a_i\mathbf{u}_i+a_j\mathbf{u}_j) = \lambda(a_i\mathbf{u}_i+a_j\mathbf{u}_j)
$$

と書くことができ、$a_i\mathbf{u}_i+a_j\mathbf{u}_j$も同じ固有値に対する固有ベクトルとして表現できる。これが得られる場合、例えばグラム・シュミットの直交化法を使うことで$(2.46)$式である$\mathbf{u}_k^{\mathrm{T}}\mathbf{u}_l = I_{kl}$となるような正規直交された$\mathbf{u}_k$, $\mathbf{u}_l$を$\mathbf{u}_i, \mathbf{u}_j$の組から得ることが可能であることが知られている。以上から、同じ固有値$\lambda_i=\lambda_j(\neq 0)$の場合でも$(2.46)$式を満足させられる固有ベクトルを得ることは可能である。

<br>

③ **いくつかの固有値が0であっても、正規直交となるように固有ベクトル集合を選ぶことができる。**

最後に、もしいくつかの$\lambda_i$が$0$だった場合、正則行列についての定理から$\mathbf{\Sigma}$は正則行列ではなく、逆行列を持たない特異行列となる。このとき、$\mathbf{\Sigma}\mathbf{u}_i=\mathbf{0}$となる零ベクトルではない固有ベクトル$\mathbf{u}_i$が存在することになり、これは$\mathbf{\Sigma}$の零空間（核）をなす。さらに、同じ固有値0となる別の固有ベクトル$\mathbf{u}_j$がある場合でも、上記のグラム・シュミット直交化法によって$(2.46)$式を満足させられる固有ベクトルを得ることが可能である。

## 演習 2.19
<div class="panel-primary">

固有ベクトルの方程式について$$\mathbf{\Sigma}\mathbf{u}_i=\lambda_i\mathbf{u}_i \tag{2.45}$$が成立する実対称行列$\mathbf{\Sigma}$は，固有値を係数とする固有ベクトルで展開した，

$$
\mathbf{\Sigma}=\sum_{i=1}^{D} \lambda_{i} \mathbf{u}_{i} \mathbf{u}_{i}^{\mathrm{T}} \tag{2.48}
$$

の形で表せることを示せ．同様に，逆行列$\mathbf{\Sigma}^{-1}$は

$$
\mathbf{\Sigma}^{-1}=\sum_{i=1}^{D} \frac{1}{\lambda_{i}} \mathbf{u}_{i} \mathbf{u}_{i}^{\mathrm{T}} \tag{2.49}
$$

の形で表現できることを示せ．

</div>

※ $(2.45)$と$(2.48)$を行列形式で表すと変形が簡単になる。このとき、固有値$\lambda_i$を対角行列$\mathbf{\Lambda}$で書くとわかりやすい。

まず$\mathbf{\Lambda}$を$\displaystyle \mathbf{\Lambda} = \left(\begin{array}{cccc}\lambda_{1} & & & 0 \\ & \lambda_{2} & & \\ & & \ddots & \\ 0 & & & \lambda_{D}\end{array}\right)$となるような固有値からなる対角行列であるとする。さらに、$\mathbf{U}$をその列が$D$個の固有ベクトルからなる行列であるとする（つまり$\mathbf{U} = (\mathbf{u}_{1}, \mathbf{u}_{2}, \cdots, \mathbf{u}_{D})$）。$\mathbf{\Lambda}, \mathbf{U}$はともに$D \times D$の行列である。

これにより$(2.45)$は行列形式で$\mathbf{\Sigma}\mathbf{U} = \mathbf{U}\mathbf{\Lambda}$と表せ（付録C.38などを参照）、$(2.48)$は$\mathbf{\Sigma} = \mathbf{U}\mathbf{\Lambda}\mathbf{U}^{\mathrm{T}}$で表せる（……ということはちょっと計算してみないとわかりにくいかもしれない）。

よって、$\mathbf{\Sigma}\mathbf{U} = \mathbf{U}\mathbf{\Lambda}$の左から$\mathbf{U}^{\mathrm{T}}$を掛けると

$$
\begin{aligned}
\mathbf{U}^{\mathrm{T}}\mathbf{\Sigma}\mathbf{U} &= \mathbf{U}^{\mathrm{T}}\mathbf{U}\mathbf{\Lambda} \\
&= \mathbf{\Lambda} \  (\because \mathbf{U}\mathbf{U}^{\mathrm{T}}=\mathbf{U}\mathbf{U}^{\mathrm{T}}=1 )\\
\end{aligned}
$$
となる。一方、この式から$\mathbf{\Sigma} = \mathbf{U}\mathbf{\Lambda}\mathbf{U}^{\mathrm{T}}$と表せることも分かり、$(2.48)$の行列形式が得られることが示された。

また、$\mathbf{U}^{\mathrm{T}} = \mathbf{U}^{-1}$であることを利用すれば
$$
\begin{aligned}
\mathbf{\Sigma}^{-1} &= (\mathbf{U}\mathbf{\Lambda}\mathbf{U}^{\mathrm{T}})^{-1} \\
&= (\mathbf{U}^{\mathrm{T}})^{-1}\mathbf{\Lambda}^{-1}\mathbf{U}^{-1} \\
&= \mathbf{U}\mathbf{\Lambda}^{-1}\mathbf{U}^{\mathrm{T}}
\end{aligned}
$$
となる。ここで$\mathbf{\Lambda}\mathbf{\Lambda}^{-1} = \mathbf{I}$より、$\mathbf{\Lambda}^{-1}$は対角成分が$\frac{1}{\lambda_i}$となる対角成分であることは容易にわかるので、

$$
\mathbf{\Sigma}^{-1} = \sum_{i=1}^{D}\frac{1}{\lambda_i}\mathbf{u}_i\mathbf{u}_i^{\mathrm{T}}
$$

となり、$(2.49)$式が得られることが示された。

※ $\mathbf{\Sigma}\mathbf{u}_i=\lambda_i\mathbf{u}_i$ならば$\mathbf{\Sigma} \mathbf{U}=\mathbf{U\Lambda}$であることは

$$
\begin{aligned}
\mathbf{\Sigma} \mathbf{U} &= \mathbf{\Sigma}\left(\mathbf{u}_{1}, \mathbf{u}_{2}, \cdots, \mathbf{u}_{D}\right)=\left(\mathbf{\Sigma} \mathbf{u}_{1}, \mathbf{\Sigma} \mathbf{u}_{2}, \cdots \mathbf{\Sigma} \mathbf{u}_{D}\right) \\
\mathbf{U} \mathbf{\Lambda} &=\left(\mathbf{u}_{1}, \mathbf{u}_{2}, \cdots, \mathbf{u}_{D}\right) \begin{pmatrix}\lambda_{1} & & & 0 \\ & \lambda_{2} & & \\ & & \ddots & \\ 0 & & & \lambda_{D}\end{pmatrix}=\left(\lambda \mathbf{u}_{1}, \lambda \mathbf{u}_{2}, \cdots, \lambda \mathbf{u}_{D}\right)
\end{aligned}
$$

から確かめられる。

## 演習 2.20
<div class="panel-primary">

正定値行列$\mathbf{\Sigma}$は次の二次形式が，任意の実ベクトル$\mathbf{a}$について正になるということで定義できる．

$$
\mathbf{a}^{\mathrm{T}}\mathbf{\Sigma}\mathbf{a} \tag{2.285}
$$

$\mathbf{\Sigma}$が正定値になる必要十分条件は，$(2.45)$で定義される$\mathbf{\Sigma}$のすべての固有値$\lambda_i$が正となることであることを示せ．

</div>

※ 行列の定値性と固有値の間の有名な関係を示す問題です。[Wikipedia](https://ja.wikipedia.org/wiki/%E8%A1%8C%E5%88%97%E3%81%AE%E5%AE%9A%E5%80%A4%E6%80%A7)にも書かれています。

問題文より、「$\mathbf{\Sigma}$が正定値行列である」ことの定義は、$(2.285)$のように任意の零ベクトルでない実ベクトル$\mathbf{a}$について$\mathbf{a}^{\mathrm{T}}\mathbf{\Sigma}\mathbf{a}>0$が成立することである。

【解法1】 参考：統計のための行列代数下巻 定理21.8.4の証明

$(2.45)$式から$\mathbf{\Sigma}\mathbf{u}_i=\lambda_i\mathbf{u}_i$とする。$\lambda_i$は固有値である。

$(2.45)$式の両辺に左から$\mathbf{u}_i^{\mathrm{T}}$をかけると

$$
\mathbf{u}_i^{\mathrm{T}}\mathbf{\Sigma}\mathbf{u}_i=\lambda_i\mathbf{u}_i^{\mathrm{T}}\mathbf{u}_i
$$
$$
\lambda_i = \frac{\mathbf{u}_i^{\mathrm{T}}\mathbf{\Sigma}\mathbf{u}_i}{\mathbf{u}_i^{\mathrm{T}}\mathbf{u}_i} \tag{1}
$$

ここで、$\mathbf{u}_i^{\mathrm{T}}\mathbf{\Sigma}\mathbf{u}_i,\ \mathbf{u}_i^{\mathrm{T}}\mathbf{u}_i$はともにスカラーである。一方で、$\mathbf{u}_i^{\mathrm{T}}\mathbf{u}_i$は実ベクトルの自身の2乗なので常に$\mathbf{u}_i^{\mathrm{T}}\mathbf{u}_i>0$となる（※特にこの問題設定では$\mathbf{u}_i$は直交行列なので$\mathbf{u}_i^{\mathrm{T}}\mathbf{u}_i=1$となる）。

よって、もし任意の$i$について$\lambda_{i}>0$ならば$(1)$式から$\mathbf{u}_i^{\mathrm{T}}\mathbf{\Sigma}\mathbf{u}_i>0$となる。すなわち、$\mathbf{\Sigma}$が正定値行列となる。反対に、もし$\mathbf{\Sigma}$が正定値行列ならば任意の$i$について$\mathbf{u}_i^{\mathrm{T}}\mathbf{\Sigma}\mathbf{u}_i>0$となるので、すべての固有値$\lambda_i$が正となる。

以上から題意は示された。

【解法2】 PRML公式解答例による方法

$\mathbf{u}_{1}, \mathbf{u}_{2}, \ldots, \mathbf{u}_{D}$は$\mathbb{R}^D$の基底を張るので任意のベクトル$\mathbf{a}$は係数$a_1, \ldots, a_D$を使って

$$
\mathbf{a}=a_{1} \mathbf{u}_{1}+a_{2} \mathbf{u}_{2}+\ldots+a_{D} \mathbf{u}_{D}
$$

と書くことができる。これより、

$$
\begin{aligned}
\mathbf{a}^{\mathrm{T}}\mathbf{\Sigma}\mathbf{a}
&= (a_{1} \mathbf{u}_{1}^{\mathrm{T}}+a_{2} \mathbf{u}_{2}^{\mathrm{T}}+\ldots+a_{D} \mathbf{u}_{D}^{\mathrm{T}})\mathbf{\Sigma}(a_{1} \mathbf{u}_{1}+a_{2} \mathbf{u}_{2}+\ldots+a_{D} \mathbf{u}_{D}) \\
&= \left(a_{1} \mathbf{u}_{1}^{\mathrm{T}}+\ldots+a_{D} \mathbf{u}_{D}^{\mathrm{T}}\right)\left(a_{1} \lambda_{1} \mathbf{u}_{1}+\ldots+a_{D} \lambda_{D} \mathbf{u}_{D}\right)\hspace{2em}(\because (2.45))
\end{aligned}
$$

となる。今、$i=j$ならば$\mathbf{u}_i^{\mathrm{T}}\mathbf{u}_j=1$でそれ以外のとき$\mathbf{u}_i^{\mathrm{T}}\mathbf{u}_j=0$であることを利用すれば、

$$
\mathbf{a}^{\mathrm{T}}\mathbf{\Sigma}\mathbf{a} = a_{1}^{2} \lambda_{1}+\ldots+a_{D}^{2} \lambda_{D}
$$

が得られる。よって、もしすべての固有値が正ならば（$\lambda_i>0$）$\mathbf{a}^{\mathrm{T}}\mathbf{\Sigma}\mathbf{a}>0$となるため、$\mathbf{\Sigma}$が正定値行列であることがわかる。

反対に$\mathbf{\Sigma}$が正定値行列であるならばすべての固有値が正となることを示す。このために対偶「ある1つの固有値が0以下でならば、$\mathbf{\Sigma}$は正定置行列ではない」ことを示す。

もしある$\lambda_i$について$\lambda_i \le 0$となるようなものが存在した場合、$\mathbf{a}  = \mathbf{u}_i$とすれば$\mathbf{a}^{\mathrm{T}}\mathbf{\Sigma}\mathbf{a} = \lambda_i\mathbf{u}_i^{\mathrm{T}}\mathbf{u}_i \le 0$となり、$\mathbf{\Sigma}$は正定置行列ではないことが示される。よって対偶を取ると「$\mathbf{\Sigma}$が正定値行列であるならばすべての固有値が正となる」が示される。

以上から必要十分条件が示された。

## 演習 2.21
<div class="panel-primary">

大きさが$D\times D$の実対称行列の独立なパラメータは、$D(D+1)/2$個であることを示せ．

</div>

大きさが$D\times D$の実対称行列の全成分の個数は当然$D^2$個である。このうち、対角成分の$D$個を除いて残りのパラメータ（非対角成分）は対角成分に対して対称な値になっていなければならないので、そのパラメータの自由度は$\displaystyle \frac{D^2-D}{2}$個である。これに$D$個を足して

$$
\frac{D^2-D}{2}+D = \frac{D(D+1)}{2}
$$

つまり独立なパラメータは$\displaystyle \frac{D(D+1)}{2}$個である。

## 演習 2.22
<div class="panel-primary">

対称行列の逆行列も対称であることを示せ．

</div>

ある任意の対称行列$\mathbf{A}$があり、逆行列が存在する場合それを$\mathbf{A}^{-1}$とすると、

$$
\mathbf{A}\mathbf{A}^{-1} = \mathbf{I}
$$

となる（$\mathbf{I}$は単位行列）。両辺の転置を取り、$\mathbf{A}$は対称行列なので$\mathbf{A} = \mathbf{A}^{\mathrm{T}}$であることに注意すると

$$
(\mathbf{A}\mathbf{A}^{-1})^{\mathrm{T}} = (\mathbf{A}^{-1})^{\mathrm{T}}\mathbf{A}^{\mathrm{T}} = (\mathbf{A}^{-1})^{\mathrm{T}}\mathbf{A} = \mathbf{I}
$$

ここで第3項について、逆行列の定義から

$$
(\mathbf{A}^{-1})^{\mathrm{T}} = \mathbf{A}^{-1}
$$

とならなければならないことがわかる。これは対称行列の逆行列$\mathbf{A}^{-1}$も対称行列となっていることを表している。

## 演習 2.23
<div class="panel-primary">

$$
\mathbf{\Sigma}=\sum_{i=1}^{D} \lambda_{i} \mathbf{u}_{i} \mathbf{u}_{i}^{\mathrm{T}} \tag{2.48}
$$
の固有ベクトル展開を用いて座標系を対角化することで，マハラノビス距離$\Delta$が定数になる超楕円体の内部の体積が，

$$
V_{D}|\mathbf{\Sigma}|^{1 / 2} \Delta^{D} \tag{2.286}
$$

になることを示せ．ただし，$V_{D}$は$D$次元単位球の体積で，マハラノビス距離は $(2.44)$で定義される．


</div>

※ PRML第2章 **2.3 ガウス分布**の議論にある**ガウス分布の幾何的な形状**についての理解を深めるための問題です。

※ そもそも超楕円体って何？って調べてみても意外とGoogleでヒットしないのですが、以下の定義を使います。

<blockquote> 楕円体は，2次曲面の一種です．2次元において，次の方程式：

$$
\frac{x^2}{a^2}+\frac{y^2}{b^2}=1
$$

で表現される図形を楕円と呼びますが，これの$n$次元へ拡張したものと捉えて問題ありません．より厳密な呼び分けとしては，$n=3$のときのみ楕円体と呼び，$n\ge4$のとき**超楕円体**と呼ぶ場合もあるようです．
http://ssr-yuki.hatenablog.com/entry/2020/04/26/230647 </blockquote>

マハラノビス距離の2乗$\displaystyle \Delta^2 = (\mathbf{x}-\mathbf{\mu})^{\mathrm{T}}\mathbf{\Sigma}^{-1}(\mathbf{x}-\mathbf{\mu})$は、P.78の手続きから固有ベクトル展開を用いて座標系を対角化することで$(2.50)$式$\displaystyle \Delta^2 = \sum_{i=1}^{D}\frac{y_i^2}{\lambda_i}$と書くことができる。例として$D=2$であれば

$$
\frac{y_1^2}{\lambda_1}+\frac{y_2^2}{\lambda_2}=\Delta^2
$$

と書ける。これは平面図形の楕円である（P.79の図2.7のイメージ）。ちなみに$D=3$では楕円体（[Wikipediaの楕円体を参照](https://ja.wikipedia.org/wiki/%E6%A5%95%E5%86%86%E4%BD%93)）を表す式になり、$D \ge 4$では超楕円体を表す。

$D$次元の超楕円体の体積$V_e$は以下の式で定義される。

$$
V_e = \int\int\cdots\int dy_1dy_2\cdots dy_D
$$

これは3次元の場合の式$V_3 = \int\int\int dxdydz$の拡張です。この辺についての説明は [楕円の面積と楕円体の体積の求め方](http://takun-physics.net/3284)のページも参考にしてみてください。

今、マハラノビス距離$\Delta$は定数ということになっているので、超楕円体は$a_i^2=y_i^2/\lambda_i$の変数変換を行うことで、半径$\Delta$の超球へと変換させることができる。つまりヤコビアン$\mathbf{J}$を使って表現すると

$$
\begin{aligned}
V_e &= \int\int\cdots\int dy_1dy_2\cdots dy_D \\
&= \int\int\cdots\int |\mathbf{J}|da_1da_2\cdots da_D
\end{aligned}
$$

となる。ここでヤコビアンは$(2.53)-(2.55)$での議論から

$$
\mathbf{J}=\left(\begin{array}{ccc}\frac{\partial y_{1}}{\partial a_{1}} & \cdots & \frac{\partial y_{1}}{\partial a_{D}} \\ \vdots & \ddots & \vdots \\ \frac{\partial y_{D}}{\partial a_{1}} & \cdots & \frac{\partial y_{0}}{\partial a_{2}}\end{array}\right)=\left(\begin{array}{ccc}
\sqrt{\lambda_{1}} &  &  & 0 \\
 & \sqrt{\lambda_{2}} \\
 & & \ddots & \\
0 & & & \sqrt{\lambda_{D}}
 \end{array}\right)
$$

なので、$|\mathbf{J}| = \prod_{i=1}^{D}\lambda_i^{1/2} =|\mathbf{\Sigma}|^{1/2}$となる。

一方、$\displaystyle \int\int\cdots\int da_1da_2\cdots da_D = \int \prod_{i=1}^{D}da_i$部分は、半径$\Delta$の$D$次元超球の体積を表しているので（超球は演習問題1.18でも登場。各変数$a_i$の定義域は$-\Delta \le a_i \le \Delta$である）、問題文の通りに$V_D$を$D$次元単位球の体積とすると、

$$
\int\int\cdots\int da_1da_2\cdots da_D = V_D\Delta^D
$$

となる。

以上から求める超楕円体の内部の体積$V_e$は$(2.286)$式の通りに

$$
V_e = V_D|\mathbf{\Sigma}|^{1/2}\Delta^D
$$

となることが示された。

> マハラノビス距離の直感的な理解としては、例えば https://mathwords.net/mahalanobis などのサイトの説明を読んでください。多次元からなるデータ群の中で例えば**外れ値**を検出したい場合、データの各次元への分散まで考慮した**データ群からの距離**を考える必要があります。これを実現するのが**マハラノビス距離**です。マハラノビス距離が大きい → その点での確率密度が小さい → **異常度が高い**と考えることができます。

## 演習 2.24
<div class="panel-primary">

$$
\left(\begin{array}{cc}\mathbf{A} & \mathbf{B} \\ \mathbf{C} & \mathbf{D}\end{array}\right)^{-1}=\left(\begin{array}{cc}\mathbf{M} & -\mathbf{M B D}^{-1} \\ -\mathbf{D}^{-1} \mathbf{C M} & \mathbf{D}^{-1}+\mathbf{D}^{-1} \mathbf{C M B D}^{-1}\end{array}\right) \tag{2.76}
$$
の両辺に次の行列$\displaystyle \left(\begin{array}{ll}\mathbf{A} & \mathbf{B} \\ \mathbf{C} & \mathbf{D}\end{array}\right) \ (2.287)$を掛け，また，

$$
\mathbf{M}=\left(\mathbf{A}-\mathbf{B} \mathbf{D}^{-1} \mathbf{C}\right)^{-1} \tag{2.77}
$$

の定義を用いることで，$(2.76)$の恒等式を証明せよ．

</div>

指示通り$(2.76)$の右辺に左から$\displaystyle \left(\begin{array}{cc}\mathbf{A} & \mathbf{B} \\ \mathbf{C} & \mathbf{D} \end{array}\right)$をかけたものを$\mathbf{X}$とおく。これが左辺に左から$\displaystyle \left(\begin{array}{cc}\mathbf{A} & \mathbf{B} \\ \mathbf{C} & \mathbf{D} \end{array}\right)$をかけたもの、すなわち単位行列$\mathbf{I}$になっていることを示せば良い。

$$
\begin{aligned} \mathbf{X}
&=\left(\begin{array}{cc}\mathbf{A} & \mathbf{B} \\ \mathbf{C} & \mathbf{D} \end{array}\right)
\left(\begin{array}{cc}\mathbf{M} & -\mathbf{MBD}^{-1} \\ -\mathbf{D}^{-1} \mathbf{CM} & \mathbf{D}^{-1}+\mathbf{D}^{-1} \mathbf{CMBD}^{-1}\end{array}\right) \\
&=\left(\begin{array}{cc}\mathbf{AM}-\mathbf{BD}^{-1}\mathbf{CM} & -\mathbf{AMBD}^{-1}+\mathbf{B}\left(\mathbf{D}^{-1}+\mathbf{D}^{-1} \mathbf{CMBD}^{-1}\right) \\ \mathbf{CM}-\mathbf{DD}^{-1} \mathbf{CM} & -\mathbf{CMBD}^{-1}+\mathbf{D}\left(\mathbf{D}^{-1}+\mathbf{D}^{-1} \mathbf{CMBD}^{-1}\right)\end{array}\right)
\end{aligned}
$$

このそれぞれの部分行列成分について計算していくと

$$
\begin{aligned}
\mathbf{X}_{11}
&=\mathbf{AM}-\mathbf{BD}^{-1} \mathbf{CM} \\
&=\left(\mathbf{A}-\mathbf{BD}^{-1} \mathbf{C}\right) \mathbf{M} \\ &=\left(\mathbf{A}-\mathbf{B D}^{-1} \mathbf{C}\right) \left(\mathbf{A}-\mathbf{BD}^{-1} \mathbf{C}\right)^{-1} \\ &=\mathbf{I}
\end{aligned}
$$

$$
\begin{aligned}
\mathbf{X}_{12}
&=-\mathbf{A M B D}^{-1}+\mathbf{B}\left(\mathbf{D}^{-1}+\mathbf{D}^{-1} \mathbf{C M B D}^{-1}\right) \\
&=-\mathbf{A M B D}^{-1}+\mathbf{B D}^{-1}+\mathbf{B D}^{-1}\mathbf{C M B D}^{-1} \\
&=-\left(\mathbf{A}-\mathbf{B D}^{-1} \mathbf{C}\right) \mathbf{M B D}^{-1}+\mathbf{B D}^{-1} \\
&=-\left(\mathbf{A}-\mathbf{B D}^{-1} \mathbf{C}\right)\left(\mathbf{A}-\mathbf{B D}^{-1} \mathbf{C}\right)^{-1} \mathbf{B D}^{-1}+\mathbf{B D}^{-1} \\
&=-\mathbf{B D}^{-1}+\mathbf{B D}^{-1} \\
&=\mathbf{O}
\end{aligned}
$$

$$
\begin{aligned}
\mathbf{X}_{21}
&=\mathbf{CM}-\mathbf{DD}^{-1}\mathbf{CM} \\
&=\mathbf{O}
\end{aligned}
$$

$$
\begin{aligned}
X_{22}
&=-\mathbf{C M B D}^{-1}+\mathbf{D}\left(\mathbf{D}^{-1}+\mathbf{D}^{-1} \mathbf{C M B D}^{-1}\right) \\
&=-\mathbf{C M B D}^{-1}+\mathbf{I}+\mathbf{C M B D}^{-1} \\ &=\mathbf{I}
\end{aligned}
$$

よって全体として$\mathbf{X} = \mathbf{I}$となっていることが示せたので、$(2.76)$の恒等式は示された。

## 演習 2.25
<div class="panel-primary">

2.3.1節や2.3.2節では，多変量ガウス分布の条件付き分布や周辺分布について考察した．より一般的に，$\mathbf{x}$の要素を$\mathbf{x}_a, \mathbf{x}_b$,および$\mathbf{x}_c$の3つに分けることを考える．この分割により，対応する平均ベクトル$\boldsymbol{\mu}$と共分散行列$\mathbf{\Sigma}$は

$$
\boldsymbol{\mu}=\left(\begin{array}{c}\boldsymbol{\mu}_{a} \\ \boldsymbol{\mu}_{b} \\ \boldsymbol{\mu}_{c}\end{array}\right), \quad \mathbf{\Sigma}=\left(\begin{array}{ccc}\mathbf{\Sigma}_{a a} & \mathbf{\Sigma}_{a b} & \mathbf{\Sigma}_{a c} \\ \mathbf{\Sigma}_{b a} & \mathbf{\Sigma}_{b b} & \mathbf{\Sigma}_{b c} \\ \mathbf{\Sigma}_{c a} & \mathbf{\Sigma}_{c b} & \mathbf{\Sigma}_{c c}\end{array}\right)
$$

のように分割される. 2.3節の結果を用いて$\mathbf{x}_c$を周辺化で消去した条件付き分布$p(\mathbf{x}_a|\mathbf{x}_b)$の式を求めよ．

</div>

$\mathbf{x}_c$を消去したときの同時分布$p(\mathbf{x}_a,\mathbf{x}_b)$は、平均ベクトルと共分散行列が

$$
\boldsymbol{\mu}=\left(\begin{array}{c}\boldsymbol{\mu}_{a} \\ \boldsymbol{\mu}_{b} \end{array}\right), \quad \mathbf{\Sigma}=\left(\begin{array}{ccc}\mathbf{\Sigma}_{a a} & \mathbf{\Sigma}_{a b} \\ \mathbf{\Sigma}_{b a} & \mathbf{\Sigma}_{b b} \end{array}\right)
$$

のガウス分布となる。よって条件付き分布$p(\mathbf{x}_a|\mathbf{x}_b)$もガウス分布であり、その平均は$(2.81)(2.82)$で与えられ、式は$(2.96)$となる。


## 演習 2.26
<div class="panel-primary">

非常に有用な線形代数の結果であるWoodbury行列反転公式(Woodbury matrix inversion formula)は

$$
(\mathbf{A}+\mathbf{B C D})^{-1}=\mathbf{A}^{-1}-\mathbf{A}^{-1} \mathbf{B}\left(\mathbf{C}^{-1}+\mathbf{D} \mathbf{A}^{-1} \mathbf{B}\right)^{-1} \mathbf{D} \mathbf{A}^{-1} \tag{2.289}
$$

である．この両辺に$(\mathbf{A}+\mathbf{B C D})$を掛けて，この公式を証明せよ.

</div>

右辺に$(\mathbf{A}+\mathbf{B C D})$を掛けると

$$
\begin{aligned}
& (\mathbf{A}+\mathbf{B C D}) (\mathbf{A}^{-1}-\mathbf{A}^{-1} \mathbf{B}\left(\mathbf{C}^{-1}+\mathbf{D} \mathbf{A}^{-1} \mathbf{B}\right)^{-1} \mathbf{D} \mathbf{A}^{-1}) \\
&= \mathbf{I} - \mathbf{B}\left(\mathbf{C}^{-1}+\mathbf{D} \mathbf{A}^{-1} \mathbf{B}\right)^{-1} \mathbf{D} \mathbf{A}^{-1} + \mathbf{B C D}\mathbf{A}^{-1} - \mathbf{B C D} \mathbf{A}^{-1} \mathbf{B}\left(\mathbf{C}^{-1}+\mathbf{D} \mathbf{A}^{-1} \mathbf{B}\right)^{-1} \mathbf{D} \mathbf{A}^{-1}\\
&= \mathbf{I} + \mathbf{B C D}\mathbf{A}^{-1} - \mathbf{B}\left(\mathbf{I}+\mathbf{C D} \mathbf{A}^{-1} \mathbf{B}\right) \left(\mathbf{C}^{-1}+\mathbf{D} \mathbf{A}^{-1} \mathbf{B}\right)^{-1} \mathbf{D} \mathbf{A}^{-1} \\
&= \mathbf{I} + \mathbf{B C D}\mathbf{A}^{-1} - \mathbf{B C}\left(\mathbf{C}^{-1}+\mathbf{D} \mathbf{A}^{-1} \mathbf{B}\right) \left(\mathbf{C}^{-1}+\mathbf{D} \mathbf{A}^{-1} \mathbf{B}\right)^{-1} \mathbf{D} \mathbf{A}^{-1} \\
&= \mathbf{I} + \mathbf{B C D}\mathbf{A}^{-1} - \mathbf{B C D}\mathbf{A}^{-1} \\
&= \mathbf{I}
\end{aligned}
$$

となり示された。

## 演習 2.27
<div class="panel-primary">

$\mathbf{x}$と$\mathbf{z}$を２つの独立な確率ベクトル，すなわち，$p(\mathbf{x, z}) = p(\mathbf{x})p(\mathbf{z})$であるとする．これらの和$\mathbf{y}=\mathbf{x}+\mathbf{z}$の平均が，それぞれの変数について個別に求めた平均の和となることを示せ．同様に，$\mathbf{y}$の共分散行列が，$\mathbf{x}$と$\mathbf{z}$それぞれの共分散行列の和であることを示せ．これが，演習問題1.10の結果と一致することを確認せよ．

</div>

$\mathbb{E}[\mathbf{y}] = \mathbb{E}[\mathbf{x}+\mathbf{z}]=\int\int(\mathbf{x}+\mathbf{z})p(\mathbf{x},\mathbf{z})d\mathbf{x}d\mathbf{z}$

$\mathbf{x}$と$\mathbf{z}$は独立であるから
$$
\begin{aligned}
\int\int(\mathbf{x}+\mathbf{z})p(\mathbf{x},\mathbf{z})d\mathbf{x}d\mathbf{z} &= \int\int(\mathbf{x}+\mathbf{z})p(\mathbf{x})p(\mathbf{z})d\mathbf{x}d\mathbf{z}\\
&= \int\int \mathbf{x}p(\mathbf{x})p(\mathbf{z})d\mathbf{x}d\mathbf{z} + \int\int \mathbf{z}p(\mathbf{z})p(\mathbf{x})d\mathbf{x}d\mathbf{z} \\
&=\int \mathbf{x}p(\mathbf{x})d\mathbf{x} + \int \mathbf{z}p(\mathbf{z})d\mathbf{z} \\
&=\mathbb{E}[\mathbf{x}]+\mathbb{E}[\mathbf{z}]
\end{aligned}
$$
以上より$\mathbb{E}[\mathbf{y}]=\mathbb{E}[\mathbf{x}]+\mathbb{E}[\mathbf{z}]$



共分散行列の定義より
$$
\begin{aligned}
cov[y]
&= \mathbb{E}[(y-\mathbb{E}[y])(y-\mathbb{E}[y])^T]\\
&= \mathbb{E}[(x-\mathbb{E}[\mathbf{x}]+z-\mathbb{E}[z])(x-\mathbb{E}[\mathbf{x}]+z-\mathbb{E}[z])^T]\\
\end{aligned}
$$
$\mathbf{x}-\mathbb{E}[\mathbf{x}]=A$、$\mathbf{z}-\mathbb{E}[\mathbf{z}]=B$と置くと
$$
\begin{aligned}
cov[\mathbf{y}]
&= \mathbb{E}[(A+B)(A+B)^T]\\
&= \mathbb{E}[AA^T]+\mathbb{E}[AB^T]+\mathbb{E}[BA^T]+\mathbb{E}[BB^T]
\end{aligned}
$$
独立な変数同士の共分散は0になることから
$$
\operatorname{cov}[\mathbf{y}] = \mathbb{E}[AA^T]+\mathbb{E}[BB^T] = \operatorname{cov}[\mathbf{x}]+\operatorname{cov}[\mathbf{z}]
$$

## 演習 2.28
<div class="panel-primary">

平均と共分散がそれぞれ
$$
\mathbb{E}[\mathbf{z}]=
\left(\begin{array}{c}\boldsymbol{\mu} \\ \mathbf{A} \boldsymbol{\mu}+\mathbf{b}\end{array}\right) \tag{2.108}
$$
と
$$
\operatorname{cov}[\mathbf{z}]=\mathbf{R}^{-1}=\left(\begin{array}{cc}\mathbf{\Lambda}^{-1} & \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathbf{T}} \\ \mathbf{A} \mathbf{\Lambda}^{-1} & \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathbf{T}}\end{array}\right) \tag{2.105}
$$
であるような，次の変数上の同時分布を考える．

$$
\mathbf{z}=\left(\begin{array}{l}\mathbf{x} \\ \mathbf{y}\end{array}\right) \tag{2.190}
$$

$(2.92)\ \mathbb{E}[\mathbf{x}_a] = \boldsymbol{\mu}_a$と$(2.93)\ \operatorname{cov}[\mathbf{x}_a] = \mathbf{\Sigma}_{aa}$の結果を用いて，周辺分布$p(\mathbf{x})$が$\mathcal{N}(\mathbf{x}|\boldsymbol{\mu}, \mathbf{\Lambda}^{-1})\ (2.99)$となることを示せ．

同様に，
$$
\boldsymbol{\mu}_{a \mid b}=\boldsymbol{\mu}_{a}+\mathbf{\Sigma}_{ab} \mathbf{\Sigma}_{bb}^{-1}\left(\mathbf{x}_{b}-\boldsymbol{\mu}_{b}\right) \tag{2.81}
$$
と
$$
\mathbf{\Sigma}_{a \mid b}=\mathbf{\Sigma}_{a a}-\mathbf{\Sigma}_{a b} \mathbf{\Sigma}_{b b}^{-1} \mathbf{\Sigma}_{b a} \tag{2.82}
$$
の結果を用いて，条件付き分布$p(\mathbf{y}|\mathbf{x})$が

$$
p(\mathbf{y|x}) = \mathcal{N}(\mathbf{y}|\mathbf{Ax+b}, \mathbf{L}^{-1}) \tag{2.100}
$$

となることを示せ．

</div>

$(2.92)$と$(2.93)$を$(2.98)$に代入すると，$p(\mathbf{x})=\mathcal{N}(\mathbf{x}|\boldsymbol{\mu}, \mathbf{\Lambda}^{-1})$であることが簡単に示された．

また

$$
\begin{aligned}
\mathbb{E}[\mathbf{z}] &= \left(
					\begin{array}{c}
					\mu\\
					\mathbf{A}\mu+\mathbf{b}\\
					\end{array}
			  \right)\\
cov[\mathbf{z}] &= \left(
						 \begin{array}{cc}
						 \Lambda^{-1} & \Lambda^{-1}\mathbf{A}^\top \\
						 \mathbf{A}\Lambda^{-1} & \mathbf{L}^{-1} + \mathbf{A}\Lambda^{-1}\mathbf{A}^\top\\
						 \end{array}
				   \right)
\end{aligned}
$$

を$(2.81)$と$(2.82)$に代入すると

$$
\begin{aligned}
\mu_{\mathbf{y}|\mathbf{x}} &= \mu_{\mathbf{y}} + \Lambda_{\mathbf{yx}}\Lambda_{\mathbf{xx}}^{-1}(\mathbf{x} - \mu_{\mathbf{x}})\\
&= \mathbf{A}\mu + \mathbf{b} + \mathbf{A}\Lambda^{-1}\Lambda(\mathbf{x}-\mu)\\
&= \mathbf{A}\mu + \mathbf{b} + \mathbf{Ax} - \mathbf{A\mu}\\
&= \mathbf{Ax+b}\\
\Sigma_{\mathbf{y}|\mathbf{x}} &= \Sigma_{\mathbf{yy}} - \Sigma_{\mathbf{yx}}\Sigma_{xx}^{-1}\Sigma_{\mathbf{xy}}\\
&= \mathbf{L}^{-1} + \mathbf{A}\Lambda^{-1}\mathbf{A}^\top - \mathbf{A}\Lambda^{-1}\Lambda\Lambda^{-1}\mathbf{A}^\top \\
&= \mathbf{L}^{-1}\\
\end{aligned}
$$

となって，$p(\mathbf{y|x}) = \mathcal{N}(\mathbf{y}|\mathbf{Ax+b}, \mathbf{L}^{-1})$も示された．

## 演習 2.29
<div class="panel-primary">

分割行列の逆行列の公式

$$
\left(\begin{array}{cc}\mathbf{A} & \mathbf{B} \\ \mathbf{C} & \mathbf{D}\end{array}\right)^{-1}=\left(\begin{array}{cc}\mathbf{M} & -\mathbf{M B D}^{-1} \\ -\mathbf{D}^{-1} \mathbf{C M} & \mathbf{D}^{-1}+\mathbf{D}^{-1} \mathbf{C M B D}^{-1}\end{array}\right) \tag{2.76}
$$


を用いて，精度行列

$$
\mathbf{R}=\left(\begin{array}{cc}\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{L} \mathbf{A} & -\mathbf{A}^{\mathrm{T}} \mathbf{L} \\ -\mathbf{LA} & \mathbf{L}\end{array}\right) \tag{2.104}
$$

の逆行列が，共分散行列

$$
\operatorname{cov}
[\mathbf{z}]=\mathbf{R}^{-1}=\left(\begin{array}{cc}\mathbf{\Lambda}^{-1} & \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \\ \mathbf{A} \mathbf{\Lambda}^{-1} & \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\end{array}\right) \tag{2.105}
$$

となることを示せ．

</div>

$$
\mathbf{M}=\left(\mathbf{A}-\mathbf{B} \mathbf{D}^{-1} \mathbf{C}\right)^{-1}
$$



$(2.76)$より、$\mathbf{R}^{-1}$について

$$\begin{aligned}( \text{左上} ) &= ( \mathbf{\Lambda} + \mathbf{A}^T \mathbf{L} \mathbf{A} - (- \mathbf{A}^T \mathbf{L}) \mathbf{L}^{-1} \mathbf{L} \mathbf{A})^{-1} \\&= ( \mathbf{\Lambda} + \mathbf{A}^T \mathbf{L} \mathbf{A} - \mathbf{A}^T \mathbf{L} \mathbf{A} )^{-1} \\&= \mathbf{\Lambda}^{-1} \end{aligned}$$

$$\begin{aligned}( \text{右上} ) &= - \mathbf{\Lambda}^{-1} (- \mathbf{A}^T \mathbf{L}) \mathbf{L}^{-1} \\&= \mathbf{\Lambda}^{-1} \mathbf{A}^T \end{aligned}$$

$$\begin{aligned}( \text{左下} ) &= - \mathbf{L}^{-1} (- \mathbf{L} \mathbf{A}) \mathbf{\Lambda}^{-1} \\&= \mathbf{A} \mathbf{\Lambda}^{-1} \end{aligned}$$

$$\begin{aligned}( \text{右下} ) &= \mathbf{L}^{-1} + \mathbf{L}^{-1} (- \mathbf{L} \mathbf{A}) \mathbf{\Lambda}^{-1} (- \mathbf{A}^T \mathbf{L}) \mathbf{L}^{-1} \\&= \mathbf{L}^{-1} + \mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^T \end{aligned}$$

これは共分散行列(2.105)と一致する。

## 演習 2.30
<div class="panel-primary">

$$
\mathbb{E}[\mathbf{z}]=\mathbf{R}^{-1}\left(\begin{array}{c}\mathbf{\Lambda} \boldsymbol{\mu}-\mathbf{A}^{\mathrm{T}} \mathbf{L} \mathbf{b} \\ \mathbf{Lb}\end{array}\right) \tag{2.107}
$$

に，

$$
\operatorname{cov}
[\mathbf{z}]=\mathbf{R}^{-1}=\left(\begin{array}{cc}\mathbf{\Lambda}^{-1} & \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \\ \mathbf{A} \mathbf{\Lambda}^{-1} & \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\end{array}\right) \tag{2.105}
$$
の結果を用いて，
$$
\mathbb{E}[\mathbf{z}]=\left(\begin{array}{c}\boldsymbol{\mu} \\
\mathbf{A} \boldsymbol{\mu}+\mathbf{b}\end{array}\right) \tag{2.108}
$$
を確かめよ．

</div>

単純に計算するだけ

$$
\begin{aligned}
\mathbb{E}[\mathbf{z}] &= \mathbf{R}^{-1}\left(\begin{array}{c}\mathbf{\Lambda} \boldsymbol{\mu}-\mathbf{A}^{\mathrm{T}} \mathbf{L} \mathbf{b} \\ \mathbf{Lb}\end{array}\right) \\
&= \left(\begin{array}{cc}\mathbf{\Lambda}^{-1} & \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \\ \mathbf{A} \mathbf{\Lambda}^{-1} & \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\end{array}\right)\left(\begin{array}{c}\mathbf{\Lambda} \boldsymbol{\mu}-\mathbf{A}^{\mathrm{T}} \mathbf{L b} \\ \mathbf{L b}\end{array}\right) \\
&=\left(\begin{array}{c}\mathbf{\Lambda}^{-1}\left(\mathbf{\Lambda} \boldsymbol{\mu}-\mathbf{A}^{\mathrm{T}} \mathbf{L b}\right)+\mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L b} \\
\mathbf{A} \mathbf{\Lambda}^{-1}\left(\mathbf{\Lambda} \boldsymbol{\mu}-\mathbf{A}^{\mathrm{T}} \mathbf{L} \mathbf{b}\right)+\left(\mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right) \mathbf{L b}\end{array}\right) \\
&=\left(\begin{array}{c}\boldsymbol{\mu}-\mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L} \mathbf{b}+\mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L} \mathbf{b}
\\ \mathbf{A} \boldsymbol{\mu}-\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L} \mathbf{b}+\mathbf{b}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L} \mathbf{b}\end{array}\right) \\
&=\left(\begin{array}{c}\boldsymbol{\mu} \\
\mathbf{A} \boldsymbol{\mu}+\mathbf{b}\end{array}\right)
\end{aligned}
$$


## 演習 2.31
<div class="panel-primary">

2つの多次元確率ベクトル$\mathbf{x}$と$\mathbf{z}$を考える．これらは，それぞれガウス分布$p(\mathbf{x}) = \mathcal{N}(\mathbf{x}| \boldsymbol{\mu}_{\mathbf{x}}, \mathbf{\Sigma_x})$と$p(\mathbf{z}) = \mathcal{N}(\mathbf{z}| \boldsymbol{\mu}_{\mathbf{z}}, \mathbf{\Sigma_z})$に従い，これらの和は$\mathbf{y} = \mathbf{x} + \mathbf{z}$であるとする．周辺分布$p(\mathbf{x})$と条件付き分布$p(\mathbf{y|x})$の積からなる線形ガウスモデルを用いて，

$$
\mathbb{E}[\mathbf{y}] =\mathbf{A} \boldsymbol{\mu}+\mathbf{b} \tag{2.109}
$$

$$
\operatorname{cov}[\mathbf{y}] = \mathbf{L}^{-1}+\mathbf{A}\mathbf{\Lambda}^{-1}\mathbf{A}^{\mathrm{T}} \tag{2.110}
$$

から周辺分布$p(\mathbf{y})$についての式を求めよ．

</div>

※ まず条件付き確率分布$p(\mathbf{y|x})$の解釈を考える。これは$\mathbf{x}$が与えられた中での$\mathbf{y}$の確率分布なので、$\mathbf{x}$は定数として考えることができる。さらに周辺分布$p(\mathbf{y})$は$p(\mathbf{y}) = p(\mathbf{y|x})p(\mathbf{x})$から計算することができる。ここの議論はPRMLテキストのP.88 2.3.3 **ガウス変数に対するベイズの定理**でしっかり行っている。また、周辺分布$p(\mathbf{x})$と条件付き分布$p(\mathbf{y|x})$がともにガウス分布であれば周辺分布$p(\mathbf{y})$もガウス分布になるので、平均と分散パラメータを求めてガウス分布の形の式にすれば良い。

条件付き確率分布$p(\mathbf{y|x})$は$\mathbf{x}$が与えられた（つまり定数とした）中での$\mathbf{y} = \mathbf{x}+\mathbf{z}$の確率分布を表しているので、$\mathbf{y}$の平均は$\boldsymbol{\mu}_{\mathbf{z}}$に$\mathbf{x}$を足したもの、$\mathbf{y}$の分散は$\mathbf{\Sigma}_{\mathbf{z}}$となるので、

$$
p(\mathbf{y|x}) = \mathcal{N}(\mathbf{y}| \boldsymbol{\mu}_{\mathbf{z}}+\mathbf{x}, \mathbf{\Sigma_z})
$$

と表すことができる。

以降、pp.88〜90の線形ガウスモデルの議論とまとめ$(2.113)$〜$(2.117)$と、この問題設定の

$$
\begin{aligned}
    p(\mathbf{x}) &= \mathcal{N}(\mathbf{x}|\boldsymbol{\mu}_{\mathbf{x}},\mathbf{\Sigma}_{\mathbf{x}}) \\
    p(\mathbf{y|x}) &= \mathcal{N}(\mathbf{y}|\mathbf{x}+\boldsymbol{\mu}_{\mathbf{z}},\mathbf{\Sigma}_{\mathbf{z}})
\end{aligned}
$$
を比較すると、
$$
\boldsymbol{\mu} \to \boldsymbol{\mu}_{\mathbf{x}}, \mathbf{\Lambda}^{-1} \to \mathbf{\Sigma}_{\mathbf{x}}, \mathbf{A} \to \mathbf{I}, \mathbf{b} \to \boldsymbol{\mu}_{\mathbf{z}}, \mathbf{L}^{-1} \to \mathbf{\Sigma}_{\mathbf{z}}
$$
と置換することで、$(2.115)$式から
$$
p(\mathbf{y}) = \mathcal{N}(\mathbf{y}|\boldsymbol{\mu}_{\mathbf{x}}+\boldsymbol{\mu}_{\mathbf{z}}, \mathbf{\Sigma}_{\mathbf{x}}+\mathbf{\Sigma}_{\mathbf{z}})
$$

となる。これは演習2.27の結果と同じである。

## 演習 2.32
<div class="panel-primary">

これと次の演習問題で，線形ガウスモデル中の二次形式の操作を練習し，また，本文中で導いた結果も検証する．周辺分布

$$
p(\mathbf{x})=\mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}^{-1}\right) \tag{2.99}
$$

と条件付き分布

$$
p(\mathbf{y} \mid \mathbf{x})=\mathcal{N}\left(\mathbf{y} \mid \mathbf{Ax}+\mathbf{b}, \mathbf{L}^{-1}\right) \tag{2.100}
$$

で定義される同時確率$p(\mathbf{x},\mathbf{y})$を考える．同時確率の指数部分の二次形式に，2.3節で述べた平方完成の技法を適用して，変数$\mathbf{x}$を積分消去した周辺分布$p(\mathbf{y})$の平均と共分散の式を求めよ．これには，Woodbury行列反転公式

$$
(\mathbf{A}+\mathbf{BCD})^{-1}=\mathbf{A}^{-1}-\mathbf{A}^{-1} \mathbf{B}\left(\mathbf{C}^{-1}+\mathbf{DA}^{-1} \mathbf{B}\right)^{-1} \mathbf{DA}^{-1} \tag{2.289}
$$

を用いる．これらが，2章の結果を用いて得た結果

$$
\mathbb{E}[\mathbf{y}] =\mathbf{A} \boldsymbol{\mu}+\mathbf{b} \tag{2.109}
$$

$$
\operatorname{cov}[\mathbf{y}] = \mathbf{L}^{-1}+\mathbf{A}\mathbf{\Lambda}^{-1}\mathbf{A}^{\mathrm{T}} \tag{2.110}
$$
と一致することを確かめよ．

</div>

※ 2.3.3 **ガウス変数に対するベイズの定理**における導出の流れに則りつつも、問題文の指示によれば途中から二次形式を使ったやり方で導出するよう求めているため、2.3.2 **周辺ガウス分布**で行ったような二次形式を使ったやり方で求めていきます。結果は当然変わらないですが、こちらの方が2.3.3の行列形式を使ったやり方よりも計算量がものすごく増えます。

演習2.31の内容と同様に、$p(\mathbf{x,y}) = p(\mathbf{y|x})p(\mathbf{x})$から

$$
\begin{aligned}
p(\mathbf{y}) &= \int p(\mathbf{x}, \mathbf{y}) d\mathbf{x} \\
&= \int \mathcal{N}\left(\mathbf{y} \mid \mathbf{Ax}+\mathbf{b}, \mathbf{L}^{-1}\right) \mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}^{-1}\right) d\mathbf{x}
\end{aligned}
$$

となる。正規化係数を無視して指数部分だけを考えると

$$
\exp \left\{-\frac{1}{2}\left(\mathbf{y}-\mathbf{Ax}-\mathbf{b}\right)^{\mathrm{T}}\mathbf{L}(\mathbf{y}-\mathbf{Ax}-\mathbf{b})-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^{\mathrm{T}}\mathbf{\Lambda}(\mathbf{x}-\boldsymbol{\mu})\right\}
$$



となるので、二次形式を展開すると

$$
\begin{aligned}
&-\frac{1}{2}\left\{\mathbf{y}^{\mathrm{T}}\mathbf{L}\mathbf{y}-2\mathbf{y}^{\mathrm{T}}\mathbf{L}(\mathbf{Ax}+\mathbf{b})+(\mathbf{Ax}+\mathbf{b})^{\mathrm{T}}\mathbf{L}(\mathbf{Ax}+\mathbf{b})+\mathbf{x}^{\mathrm{T}}\mathbf{\Lambda}\mathbf{x}-2\boldsymbol{\mu}^{\mathrm{T}} \mathbf{\Lambda} \mathbf{x}+\boldsymbol{\mu}^{\mathrm{T}} \mathbf{\Lambda} \boldsymbol{\mu} \right\} \\
=&-\frac{1}{2}\left\{\mathbf{y}^{\mathrm{T}} \mathbf{L} \mathbf{y}-2 \mathbf{y}^{\mathrm{T}} \mathbf{L} \mathbf{Ax}-2 \mathbf{y}^{\mathrm{T}} \mathbf{L} \mathbf{b}+\mathbf{x}^{\mathrm{T}} \mathbf{A}^{\mathrm{T}} \mathbf{LAx}+2 \mathbf{b}^{\mathrm{T}} \mathbf{LAx}+\mathbf{b}^{\mathrm{T}} \mathbf{Lb}\right. \\
&+\left.\mathbf{x}^{\mathrm{T}} \mathbf{\Lambda} \mathbf{x}-2 \boldsymbol{\mu}^{\mathrm{T}} \mathbf{\Lambda} \mathbf{x}+\boldsymbol{\mu}^{\mathrm{T}} \mathbf{A} \boldsymbol{\mu} \right\}
\end{aligned}
$$

ここで2.3.2の技法に則り、$\mathbf{x}$を積分消去することを目標として$\mathbf{x}$の関わる項をまとめてから積分を容易にするために平方完成の技法を使う。

$\mathbf{x}$の関わる項を上式から抽出すると

$$
\begin{aligned}
&-\frac{1}{2}\left\{\mathbf{x}^{\mathrm{T}}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right) \mathbf{x}-2\left(\left(\mathbf{y}^{\mathrm{T}}-\mathbf{b}^{\mathrm{T}}\right) \mathbf{LA}+\boldsymbol{\mu}^{\mathrm{T}} \mathbf{\Lambda}\right) \mathbf{x}\right\} \\
=&-\frac{1}{2}(\mathbf{x}-\mathbf{m})^{\mathrm{T}}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)(\mathbf{x}-\mathbf{m})+\frac{1}{2} \mathbf{m}^{\mathrm{T}}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right) \mathbf{m}
\end{aligned}
$$

ここで$\mathbf{m}=\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1}(\mathbf{\Lambda}^{\mathrm{T}} \boldsymbol{\mu}+\mathbf{A}^{\mathrm{T}}\mathbf{L}(\mathbf{y}-\mathbf{b}))$とした。

指数内に戻して考えると

$$
\int\exp\left\{
    -\frac{1}{2}(\mathbf{x}-\mathbf{m})^{\mathrm{T}}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)(\mathbf{x}-\mathbf{m})
    \right\}d\mathbf{x}
$$

この積分は正規化されていないガウス分布の標準的な二次形式になっているので、正規化係数の逆数になる。その逆数は$|(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}}\mathbf{L A})^{-1}|$、つまり共分散行列のみに依存することがガウス分布の性質から分かるので$\mathbf{x}$には依存しなくなっている。つまりこれは$\mathbf{x}$が積分によって消去されていることを意味する。

まだ$\frac{1}{2} \mathbf{m}^{\mathrm{T}}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right) \mathbf{m}$部分が残っているので、これを$\mathbf{y}$に依存する項とあわせて再び計算すると（$\mathbf{y}$に依存しない項は$\text{const.}$とした）

$$
\begin{aligned}
&=-\frac{1}{2}\left\{\mathbf{y}^{\mathrm{T}} \mathbf{Ly}-2 \mathbf{y}^{\mathrm{T}} \mathbf{Lb}+\mathbf{m}^{\mathrm{T}}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right) \mathbf{m}\right\}+\text { const. } \\
&=-\frac{1}{2}\left\{\mathbf{y}^{\mathrm{T}} \mathbf{Ly}-2 \mathbf{y}^{\mathrm{T}} \mathbf{Lb}+\mathbf{y}^{\mathrm{T}} \mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{Ly}-2 \mathbf{y}^{\mathrm{T}}\left[\mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1}\left(\mathbf{\Lambda} \mu-\mathbf{A}^{\mathrm{T}} \mathbf{Lb}\right)\right] + \text{const.} \right\} \\
&=-\frac{1}{2} \mathbf{y}^{\mathrm{T}}\left[\mathbf{L}-\mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L}\right] \mathbf{y}+\mathbf{y}^{\mathrm{T}}\left[\left(\mathbf{L}-\mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L}\right)\mathbf{b}+ \mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{T}\mathbf{LA}\right)^{-1}\mathbf{\Lambda} \boldsymbol{\mu}\right]
\end{aligned}
$$

これが周辺分布$p(\mathbf{y})$の指数部分となっているので、二次形式部分の$\mathbf{L}-\mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L}$が$p(\mathbf{y})$の精度行列に相当することがわかる。

Woodburyの反転公式を使うと、共分散行列$\operatorname{cov}[\mathbf{y}]$は

$$
\operatorname{cov}[\mathbf{y}] = (\mathbf{L}-\mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L})^{-1} = \mathbf{L}^{-1}+\mathbf{A}\mathbf{\Lambda}^{-1}\mathbf{A}^{\mathrm{T}}
$$

となる。

最後に平均$\mathbb{E}[\mathbf{y}]$は、$(2.71), (2.75), (2.89)$で議論したように、$\mathbf{y}^{\mathrm{T}}$の係数$\left[\left(\mathbf{L}-\mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L}\right)\mathbf{b}+\mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{T} \mathbf{LA}\right)^{-1}\mathbf{\Lambda} \boldsymbol{\mu}\right]$が$\{\operatorname{cov}[\mathbf{y}]\}^{-1}\mathbb{E}[\mathbf{y}]$に一致することから求められる。

$$
\begin{aligned}
\mathbb{E}[\mathbf{y}] &= \operatorname{cov}[\mathbf{y}]\left[\left(\mathbf{L}-\mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L}\right)\mathbf{b}+\mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{T} \mathbf{LA}\right)^{-1}\mathbf{\Lambda} \boldsymbol{\mu}\right] \\
&=\left(\mathbf{L}^{-1}+\mathbf{A}\mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right)\left(\left(\mathbf{L}-\mathbf{LA}(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA})^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{L}\right) \mathbf{b}+\mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{\Lambda} \boldsymbol{\mu}\right) \\
&=\left(\mathbf{L}^{-1}+\mathbf{A}\mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right)\left(\left(\mathbf{L}^{-1}+\mathbf{A}\mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right)^{-1} \mathbf{b}+\mathbf{LA}\left(\Lambda+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{\Lambda} \boldsymbol{\mu}\right) \\
&=\mathbf{b}+\left(\mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right) \mathbf{LA}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{\Lambda} \boldsymbol{\mu} \\
&=\mathbf{b}+\left(\mathbf{A}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)\left(\mathbf{\Lambda}\left(\mathbf{I}+\mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)\right)^{-1} \mathbf{\Lambda} \boldsymbol{\mu} \\
&=\mathbf{b}+\left\{\mathbf{A}\left(\mathbf{I}+\mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)\left(\mathbf{I}+\mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \mathbf{\Lambda}^{-1} \mathbf{\Lambda} \boldsymbol{\mu}\right\} \\
&=\mathbf{A}\boldsymbol{\mu}+\mathbf{b}
\end{aligned}
$$

よって$(2.109)$の平均が求められた。

## 演習 2.33
<div class="panel-primary">

演習問題2.32と同じ同時分布について考えるが，今度は，平方完成の技法によって，条件付き分布$p(\mathbf{x|y})$の平均と共分散の式を求める．この結果も，

$$
\mathbb{E}[\mathbf{x} \mid \mathbf{y}] =\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1}\left\{\mathbf{A}^{\mathrm{T}} \mathbf{L}(\mathbf{y}-\mathbf{b})+\mathbf{\Lambda} \boldsymbol{\mu}\right\} \tag{2.111}
$$

$$
\operatorname{cov}[\mathbf{x} \mid \mathbf{y}] =\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \tag{2.112}
$$

の式と一致することを確かめよ．

</div>

※条件付き分布$p(\mathbf{x\mid y})$の場合、$\mathbf{y}$は固定である。演習2.32と同様に考えると

$$
\begin{aligned}
p(\mathbf{x}\mid \mathbf{y}) &= \frac{p(\mathbf{x},\mathbf{y})}{p(\mathbf{y})}\\
&= \frac{p(\mathbf{x}, \mathbf{y})}{\int p(\mathbf{x}, \mathbf{y}) d\mathbf{x}}
\end{aligned}
$$

であり、分母は$\mathbf{y}$が固定で$\mathbf{x}$について積分するので定数となる。よって、$\mathbf{y}$が固定された状態（定数とみなせる状態）で$p(\mathbf{x},\mathbf{y})$について平方完成し、指数部分を調べれば共分散$\operatorname{cov}[\mathbf{x} \mid \mathbf{y}]$が求まり、そこから平均$\mathbb{E}[\mathbf{x} \mid \mathbf{y}]$も求まる。

ここについては演習2.32と同じ流れで

$$
\begin{aligned}
p(\mathbf{x}\mid \mathbf{y}) &= \frac{p(\mathbf{x}, \mathbf{y})}{\int p(\mathbf{x}, \mathbf{y}) d\mathbf{x}} \\
&= C_1 \mathcal{N}\left(\mathbf{y} \mid \mathbf{Ax}+\mathbf{b}, \mathbf{L}^{-1}\right) \mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}^{-1}\right) \\
&= C_2 \exp\left\{-\frac{1}{2}\left\{\mathbf{x}^{\mathrm{T}}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right) \mathbf{x}-2\left(\left(\mathbf{y}^{\mathrm{T}}-\mathbf{b}^{\mathrm{T}}\right) \mathbf{LA}+\boldsymbol{\mu}^{\mathrm{T}} \mathbf{\Lambda}\right) \mathbf{x} + C_3 \right\} \right\}\\
&= C_4 \exp \left\{ -\frac{1}{2}(\mathbf{x}-\mathbf{m})^{\mathrm{T}}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)(\mathbf{x}-\mathbf{m})+\frac{1}{2} \mathbf{m}^{\mathrm{T}}\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right) \mathbf{m} \right\}
\end{aligned}
$$

ここで$C_1$, $C_2$, $C_3$, $C_4$はそれぞれ定数で、$\mathbf{m}=\left(\mathbf{\Lambda}+\mathbf{A}^{\top} \mathbf{LA}\right)^{-1}(\mathbf{\Lambda} \boldsymbol{\mu}+\mathbf{A}^{\mathrm{T}}\mathbf{L}(\mathbf{y}-\mathbf{b}))$であるから、結局$p(\mathbf{x}\mid \mathbf{y})$の共分散は

$$
\operatorname{cov}[\mathbf{x} \mid \mathbf{y}] =\left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1} \tag{2.112}
$$

となり、

$$
\mathbb{E}[\mathbf{x} \mid \mathbf{y}] = \mathbf{m} = \left(\mathbf{\Lambda}+\mathbf{A}^{\mathrm{T}} \mathbf{LA}\right)^{-1}\left\{\mathbf{A}^{\mathrm{T}} \mathbf{L}(\mathbf{y}-\mathbf{b})+\mathbf{\Lambda} \boldsymbol{\mu}\right\}
$$

を得る。

## 演習 2.34
<div class="panel-primary">

多変量ガウス分布の共分散行列の最尤推定解を求めるには，共分散行列が対称で正定値である制約の下で$\mathbf{\Sigma}$について対数尤度関数

$$\ln p(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Sigma})=-\frac{N D}{2} \ln (2 \pi)-\frac{N}{2} \ln |\mathbf{\Sigma}|-\frac{1}{2} \sum_{n=1}^{N}\left(\mathbf{x}_{n}-\boldsymbol{\mu}\right)^{\mathrm{T}} \mathbf{\Sigma}^{-1}\left(\mathbf{x}_{n}-\boldsymbol{\mu}\right) \tag{2.118}
$$

を最大化しなくてはならない．ここでは，こうした制約を無視して，ただ最大化することにする．付録Cの$(C.21)$，$(C.26)$，および$(C.28)$の結果を用いて，対数尤度関数$(2.118)$を最大化する共分散行列$\mathbf{\Sigma}$が，サンプル共分散

$$
\mathbf{\Sigma}_{\mathbf{ML}}=\frac{1}{N} \sum_{n=1}^{N}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{\mathbf{ML}}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{\mathbf{ML}}\right)^{\mathrm{T}} \tag{2.122}
$$

となることを示せ．なお，（サンプル共分散が非特異なら）最終結果は対称かつ，正定値である必要がある．

</div>

※ 公式解答集では共分散行列$\mathbf{\Sigma}$が対称行列であること（$\mathbf{\Sigma}^{-1}=({\mathbf{\Sigma}^{-1}})^{\mathrm{T}}$）の制約を無視して〜と書いてあるのに、その対称性を利用した解答例になっているが、それを利用しなくても答えを出すことはできる。

$$
\begin{aligned}
\frac{\partial}{\partial \mathbf{\Sigma}} \ln p(\mathbf{X} | \boldsymbol{\mu}, \mathbf{\Sigma}) &=-\frac{N}{2} \frac{\partial}{\partial \mathbf{\Sigma}} \ln |\mathbf{\Sigma}|-\frac{1}{2} \frac{\partial}{\partial \mathbf{\Sigma}}\left\{\sum_{n=1}^{N}\left(\mathbf{x}_n-\boldsymbol{\mu}\right)^{\mathrm{T}} \Sigma^{-1} \left(\mathbf{x}_n-\boldsymbol{\mu} \right)\right\} \\
&=-\frac{N}{2}\left(\mathbf{\Sigma}^{-1}\right)^{\mathrm{T}}-\frac{1}{2} \frac{\partial}{\partial \mathbf{\Sigma}}\left\{\sum_{n=1}^{N} \operatorname{Tr}\left(\mathbf{\Sigma}^{-1}\left(\mathbf{x}_n-\boldsymbol{\mu}\right)\left(\mathbf{x}_n-\boldsymbol{\mu} \right)^{\mathrm{T}}\right)\right\} \\
&=-\frac{N}{2}\left(\mathbf{\Sigma}^{-1}\right)^{\mathrm{T}} - \frac{1}{2} \frac{\partial}{\partial \mathbf{\Sigma}} \operatorname{Tr}\left( \mathbf{\Sigma}^{-1} \sum_{n=1}^{N}\left(\mathbf{x}_n-\boldsymbol{\mu}\right)\left(\mathbf{x}_n-\boldsymbol{\mu} \right)^{\mathrm{T}}\right)
\end{aligned}
$$

ここで第2項について、$\mathbf{A}=\mathbf{\Sigma}$, $\mathbf{B}=\sum_{n=1}^{N}\left(\mathbf{x}_n-\boldsymbol{\mu}\right)\left(\mathbf{x}_n-\boldsymbol{\mu} \right)^{\mathrm{T}}$とすると、求めるべきは$\displaystyle \frac{\partial}{\partial \mathbf{A}}{\mathrm{Tr}}(\mathbf{A}^{-1}\mathbf{B})$である。

$$
\begin{aligned}
\frac{\partial}{\partial A_{ij}}{\mathrm{Tr}}(\mathbf{A}^{-1}\mathbf{B}) =& \operatorname{Tr}\left(\left(\frac{\partial}{\partial A_{i j}} \mathbf{A}^{-1} \right) \mathbf{B}\right) \\
=&- \operatorname{Tr}\left(\mathbf{A}^{-1}\left(\frac{\partial}{\partial A_{ij}} \mathbf{A}\right) \mathbf{A}^{-1} \mathbf{B}\right)\hspace{1em}(\because 付録(C.21))\\
=&-\operatorname{Tr}\left(\left(\frac{\partial}{\partial A_{ij}} \mathbf{A}\right) \mathbf{A}^{-1} \mathbf{B} \mathbf{A}^{-1}\right)\hspace{1em}(\because \operatorname{Tr}(\mathbf{ABCD}) = \operatorname{Tr}(\mathbf{BCDA}))
\end{aligned}
$$

なので、$\mathbf{C}=\mathbf{A^{-1}BA^{-1}}$とすると

$$
\begin{aligned} \operatorname{Tr}\left(\left(\frac{\partial}{\partial A_{ij}} \mathbf{A}\right) \mathbf{C}\right) &=\sum_{s}\left(\left(\frac{\partial}{\partial A_{ij}} \mathbf{A}\right) \mathbf{C}\right)_{ss} \\
&= \sum_{s}\left(\sum_{t}\left(\frac{\partial}{\partial A_{ij}} \mathbf{A}\right)_{s t} c_{ts}\right) \\
&=\sum_{s, t} \delta_{is} \delta_{jt} c_{ts}=c_{ji}
\end{aligned}
$$

最後は$s=i$かつ$t=j$のときのみクロネッカーのデルタ$\delta_{is}\delta_{jt}$が$1$になり、その他は$0$となることを表している。
ここについては、付録(C.23)に書かれてある定理に則って

$$
\begin{aligned} \operatorname{Tr}\left(\left(\frac{\partial}{\partial A_{ij}} \mathbf{A}\right) \mathbf{C}\right)
&=\frac{\partial}{\partial A_{ij}} \operatorname{Tr}\left(\mathbf{AC} \right) \\
&=c_{ji}
\end{aligned}
$$

としても良い。

（※ 一般に正方行列$\mathbf{F}$の行列の$ij$成分$f_{ij}$について$\operatorname{Tr}(\mathbf{F})=\sum_{i=1}f_{ii}$より、

$$
\frac{\partial}{\partial f_{ij}}\operatorname{Tr}(\mathbf{F}) = \frac{\partial f_{11}}{\partial f_{ij}}+\frac{\partial f_{22}}{\partial f_{ij}}+\cdots= \operatorname{Tr}\left(\frac{\partial}{\partial f_{ij}} \mathbf{F}\right)
$$

が成立する）

これより、$\displaystyle \frac{\partial}{\partial A_{ij}}{\mathrm{Tr}}(\mathbf{A}^{-1}\mathbf{B})=-c_{ji}$となるので、付録(C.24)のように

$$
\begin{aligned}
\frac{\partial}{\partial \mathbf{A}}{\mathrm{Tr}}(\mathbf{A}^{-1}\mathbf{B}) &= -\mathbf{C}^{\mathrm T} \\
&=-(\mathbf{A^{-1}BA^{-1}})^{\mathrm T} \\
&=-(\mathbf{\Sigma^{-1}B\Sigma^{-1}})^{\mathrm T}
\end{aligned}
$$

よって、最大値を求めるために$\frac{\partial}{\partial \mathbf{\Sigma}} \ln p(\mathbf{X} | \boldsymbol{\mu}, \mathbf{\Sigma}) = 0$とすると

$$
\begin{aligned}
-\frac{N}{2}\left(\mathbf{\Sigma}^{-1}\right)^{\mathrm{T}} - \frac{1}{2} \frac{\partial}{\partial \mathbf{\Sigma}} \operatorname{Tr}\left( \mathbf{\Sigma}^{-1} \sum_{n=1}^{N}\left(\mathbf{x}_n-\boldsymbol{\mu}\right)\left(\mathbf{x}_n-\boldsymbol{\mu} \right)^{\mathrm{T}}\right)
=0 \\
\frac{N}{2}\left(\mathbf{\Sigma}^{-1}\right)^{\mathrm{T}} = \frac{1}{2} \left( \mathbf{\Sigma^{-1}} \sum_{n=1}^{N}\left(\mathbf{x}_n-\boldsymbol{\mu}\right)\left(\mathbf{x}_n-\boldsymbol{\mu} \right)^{\mathrm{T}} \mathbf{\Sigma^{-1}}  \right) ^{\mathrm T}
\end{aligned}
$$

互いの転置をとって移項すると、

$$
\mathbf{\Sigma} = \frac{1}{N}\sum_{n=1}^{N}\left(\mathbf{x}_n-\boldsymbol{\mu}\right)\left(\mathbf{x}_n-\boldsymbol{\mu} \right)^{\mathrm{T}}
$$

となり、これは式$(2.122)$となる。また、これによって$\mathbf{\Sigma}$についての対称性を仮定せずに$\mathbf{\Sigma}$が対称行列になることがわかった。

## 演習 2.35
<div class="panel-primary">

$$
\mathbb{E}[\mathbf{x}] = \boldsymbol{\mu} \tag{2.59}
$$

の結果を用いて，

$$
\mathbb{E}[\mathbf{xx}^{\mathrm{T}}] = \boldsymbol{\mu\mu}^{\mathrm{T}}+\mathbf{\Sigma} \tag{2.62}
$$

を証明せよ．そして，$(2.59)$と$(2.62)$の結果から，

$$
\mathbb{E}\left[\mathbf{x}_{n} \mathbf{x}_{m}^{\mathrm{T}}\right]=\boldsymbol{\mu} \boldsymbol{\mu}^{\mathrm{T}}+I_{n m} \mathbf{\Sigma} \tag{2.291}
$$

を示せ．ただし，$\mathbf{x}_{n}$は，平均が$\boldsymbol{\mu}$で共分散が$\mathbf{\Sigma}$のガウス分布からサンプリングされたデータ点，$I_{nm}$は単位行列の$(n,m)$要素を表す．これから，

$$
\mathbb{E}[\mathbf{\Sigma}_{\mathrm{ML}}] = \frac{N-1}{N}\mathbf{\Sigma} \tag{2.124}
$$

の結果を証明せよ.

</div>

$(2.59)$と$(2.62)$から、$m=n$であれば$\mathbb{E}\left[\mathbf{x}_{n} \mathbf{x}_{m}\right]=\boldsymbol{\mu} \boldsymbol{\mu}^{\mathrm{T}}+\mathbf{\Sigma}$となる。
一方で、$m \ne n$だったときには2つのデータセット$\mathbf{x}_n$と$\mathbf{x}_m$は独立なので$\mathbb{E}\left[\mathbf{x}_{n} \mathbf{x}_{m}\right]=\boldsymbol{\mu} \boldsymbol{\mu}^{\mathrm{T}}$となる。
よって、$I_{nm}$を使うと$\mathbb{E}[\mathbf{x}_n\mathbf{x}_m^{\mathrm T}] = \boldsymbol{\mu}\boldsymbol{\mu}^{\mathrm{T}} + I_{nm}\mathbf{\Sigma}$となる。


$(2.124)$式 $\displaystyle \mathbb{E}\left[\mathbf{\Sigma}_{\mathrm{ML}}\right]=\frac{N-1}{N} \mathbf{\Sigma}$を示す。

$(2.122)$式より

$$
\begin{aligned}
\mathbb{E}\left[\mathbf{\Sigma}_{\mathrm{ML}}\right] &=\frac{1}{N} \sum_{n=1}^{N} \mathbb{E}\left[\left(\mathbf{x}_{n}-\frac{1}{N} \sum_{m=1}^{N} \mathbf{x}_{m}\right)\left(\mathbf{x}_{n}^{\mathrm{T}}-\frac{1}{N} \sum_{l=1}^{N} \mathbf{x}_{l}^{\mathrm{T}}\right)\right] \\
&=\frac{1}{N} \sum_{n=1}^{N} \mathbb{E}\left[\mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm{T}}-\frac{2}{N} \mathbf{x}_{n} \sum_{m=1}^{N} \mathbf{x}_{m}^{\mathrm{T}}+\frac{1}{N^{2}} \sum_{m=1}^{N} \sum_{l=1}^{N} \mathbf{x}_{m} \mathbf{x}_{l}^{\mathrm{T}}\right] \\
&=\frac{1}{N}\sum_{n=1}^{N}\left\{ \mathbb{E}[\mathbf{x}_n\mathbf{x}_n^{\mathrm{T}}]-\frac{2}{N}\mathbb{E}\left[ \mathbf{x}_{n} \sum_{m=1}^{N} \mathbf{x}_{m}^{\mathrm{T}} \right] +\frac{1}{N^2}\mathbb{E}\left[ \sum_{m=1}^{N} \sum_{l=1}^{N} \mathbf{x}_{m} \mathbf{x}_{l}^{\mathrm{T}} \right] \right\} \\
&=\frac{1}{N}\sum_{n=1}^{N}\left\{\boldsymbol{\mu} \boldsymbol{\mu}^{\mathrm{T}}+\mathbf{\Sigma}-2\left(\boldsymbol{\mu} \boldsymbol{\mu}^{\mathrm{T}}+\frac{1}{N} \mathbf{\Sigma}\right)+\boldsymbol{\mu} \boldsymbol{\mu}^{\mathrm{T}}+\frac{1}{N} \mathbf{\Sigma}\right\} \\
&=\frac{N-1}{N} \mathbf{\Sigma}
\end{aligned}
$$


## 演習 2.36
<div class="panel-primary">

$$
\begin{aligned}
\boldsymbol{\mu}_{\mathrm{ML}}^{(N)} &=\frac{1}{N} \sum_{n=1}^{N} \mathbf{x}_{n} \\
&=\frac{1}{N} \mathbf{x}_{N}+\frac{1}{N} \sum_{n=1}^{N-1} \mathbf{x}_{n} \\
&=\frac{1}{N} \mathbf{x}_{N}+\frac{N-1}{N} \boldsymbol{\mu}_{\mathrm{ML}}^{(N-1)} \\
&=\boldsymbol{\mu}_{\mathrm{ML}}^{(N-1)}+\frac{1}{N}\left(\mathbf{x}_{N}-\boldsymbol{\mu}_{\mathrm{ML}}^{(N-1)}\right) \tag{2.126}
\end{aligned}
$$

を得たのと同様の手続きで，次の最尤推定の式から，1変数ガウス分布の分散の逐次推定の式を導出せよ．

$$
\sigma_{\mathrm{ML}}^{2}=\frac{1}{N} \sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2} \tag{2.292}
$$

Robbins-Monroの逐次推定の式

$$
\theta^{(N)}=\theta^{(N-1)}-a_{N-1} \frac{\partial}{\partial \theta^{(N-1)}}\left[-\ln p\left(x_{N} \mid \theta^{(N-1)}\right)\right] \tag{2.135}
$$

にガウス分布を代入すると，これと同じ式になることを確かめ，ここから対応する係数$a_N$の式を求めよ．

</div>

※ この問題の主題は$(2.292)$式から$(2.126)$式のような手続きによって1変数ガウス分布の分散を求めるというのが前半で、後半はこの式とRobbins-Monroアルゴリズムによる$(2.135)$式が係数$a_N$を適切に定めることで同型になることを示すことである。

まずは$(2.292)$式から分散の逐次更新式を求める。
$$
\begin{aligned}
\sigma^2_{(N)}  &=\frac{1}{N} \sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2} \\
                &=\frac{1}{N}\left\{\sum_{n=1}^{N-1}\left(x_{n}-\mu\right)^{2}+\left(x_{N}-\mu\right)^{2}\right\} \\
                &=\frac{N-1}{N} \cdot \frac{1}{N-1} \sum_{n=1}^{N-1}\left(x_{n}-\mu \right)^{2}+\frac{1}{N}\left(x_{N}-\mu\right)^{2} \\
                &=\frac{N-1}{N} \sigma^2_{(N-1)}+\frac{1}{N}\left(x_{N}-\mu \right)^{2} \\
                &=\sigma^2_{(N-1)}+\frac{1}{N}\left( (x_N-\mu)^2-\sigma^2_{(N-1)}\right) \hspace{2em} \cdots (1)
\end{aligned}
$$

一方、Robbins-Monroの式ガウス分布の式を代入すると

$$
\begin{aligned}
\sigma_{(N)}^{2}
&=\sigma_{(N-1)}^{2}-a_{N-1} \frac{\partial}{\partial \sigma_{(N-1)}^{2}}\left[-\ln \left\{\frac{1}{\sqrt{2 \pi \sigma_{(N-1)}^{2}}} \exp \left(-\frac{\left(x_{N}-\mu\right)^{2}}{2 \sigma_{(N-1)}^{2}}\right)\right\}\right]\\
&=\sigma_{(N-1)}^{2}-a_{N-1} \frac{\partial}{\partial \sigma_{(N-1)}^{2}}\left[\frac{1}{2} \ln \left(2 \pi \sigma_{(N-1)}^{2}\right)+\frac{\left(x_{N}-\mu\right)^{2}}{2 \sigma_{(N-1)}^{2}}\right] \\
&=\sigma_{(N-1)}^{2}-a_{N-1}\left\{\frac{1}{2} \cdot \frac{1}{\sigma_{(N-1)}^{2}}-\frac{\left(x_{N}-\mu\right)^{2}}{2 \sigma_{(N-1)}^{4}}\right\} \\
&=\sigma_{(N-1)}^{2}+\frac{a_{N-1}}{2 \sigma_{(N-1)}^{4}}\left\{-\sigma^2_{(N-1)}+\left(x_{N}-\mu\right)^{2}\right\} \hspace{2em} \cdots (2)
\end{aligned}
$$

$(1), (2)$式を比較すると$\displaystyle a_{N-1} = \frac{2\sigma^4_{(N-1)}}{N} \hspace{1em} \left( a_{N} = \frac{2\sigma^4_{(N)}}{N+1} \right)$が得られる。

> Robbins-Monroアルゴリズムについて本文の説明P.93はわかりにくいので補足すると、パラメータ$\theta$が与えられた時に、条件付き確率$p(z|\theta)$に従って、変数$z$が観測される状況を考えてください。図2.10でいうと、まずパラメータ$\theta$を決めると、$z$の観測値(青い点)が得られるという感じです。<br>
> この時、$z$の観測値(青い点)の出方は、$z$の条件付き期待値$\mathrm{E}[z|\theta]=f(\theta)$(赤い曲線)に従います。<br>
> 今、$z$と$\theta$の大規模データはないので、私たちはこの条件付き期待値$\mathrm{E}[z|\theta]$(赤い曲線)の形を知りません。もし大規模データがあれば、直接曲線をフィッティングできますが、今は逐次的にのみ$z$が観測されるといった状態です。<br>
> Robbins-Monroアルゴリズムで求めるのは、この$\mathrm{E}[z|\theta]$の値が$0$になるようなパラメータ$\theta$の値です。（というか、期待値が任意の値をとるようなパラメータを見つけるように簡単に拡張できます。(Robbins and Monro, 1951)）<br>
> $(2.128)$のように条件つき分散(青点のちらばり具合)が有限であるなら, $(2.129)$のような簡単な手続きで$\theta$が求まります。<br>
> つまり、ある$\theta$で$z$を観測してみて、$0$より大きければ$\theta$を小さく、小さければ大きくしてあげるだけです。もし$z$の観測の分散が無限に大きいならそれが無理なのもわかると思います。<br>
> 問題はこれを最尤推定にどうあてはめるかですが、とにかく、$0$に持っていきたい関数が条件付き期待値になっていれば良いのです。
> パラメータの最尤推定は、尤度関数をパラメータで微分して$0$とおくことで、尤度関数が最小値をとるようなパラメータを求める方法です。なので、尤度関数をパラメータで微分したもの(0にしたいもの：$(2.133)$左辺)が上で言う$f(\theta)$になりそうです。そして、それが条件付き期待値の形になっていれば良いのですが、$(2.134)$のようにちゃんとなってますよ、ということです。

## 演習 2.37
<div class="panel-primary">

$(2.126)$を得たのと同様の手続きで、最尤推定の式

$$
\mathbf{\Sigma}_{\mathbf{ML}}=\frac{1}{N} \sum_{n=1}^{N}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{\mathbf{ML}}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{\mathbf{ML}}\right)^{\mathrm{T}} \tag{2.122}
$$

から，多変量ガウス分布の共分散の逐次推定の式を導出せよ．Robbins-Monroの逐次推定の式$(2.135)$にガウス分布を代入すると，これと同じ式になることを確かめ，ここから係数$a_N$の式を求めよ．

</div>

※**問題設定が悪く、解けない可能性が高い**。

$(2.122)$式

$$
\Sigma_{\mathrm{ML}} = \frac{1}{N}\sum_{n=1}^{N}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{\mathrm{ML}}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{\mathrm{ML}}\right)^{\mathrm{T}}
$$

から多次元ガウス分布の分散の逐次更新式を求める。

$$
\begin{aligned}
\Sigma_{(N)} &= \frac{1}{N}\sum_{n=1}^{N}\left(\mathbf{x}_{n}-\boldsymbol{\mu}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}\right)^{\mathrm{T}} \\
             &= \frac{N-1}{N}\cdot\frac{1}{N-1}\left\{ \sum_{n=1}^{N-1}\left(\mathbf{x}_{n}-\boldsymbol{\mu}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}\right)^{\mathrm{T}}+\left(\mathbf{x}_{N}-\boldsymbol{\mu}\right)\left(\mathbf{x}_{N}-\boldsymbol{\mu}\right)^{\mathrm{T}} \right\} \\
             &= \frac{N-1}{N}\Sigma_{(N-1)}+\frac{1}{N}(\mathbf{x}_{N}-\boldsymbol{\mu})(\mathbf{x}_{N}-\boldsymbol{\mu})^{\mathrm{T}} \\
             &= \Sigma_{(N-1)}+\frac{1}{N}\left\{ (\mathbf{x}_{N}-\boldsymbol{\mu})(\mathbf{x}_{N}-\boldsymbol{\mu})^{\mathrm{T}} - \Sigma_{(N-1)}\right\} \hspace{2em} \cdots (1)
\end{aligned}
$$

一方、Robbins-Monroの式に多変量ガウス分布を当てはめると、

$$
\Sigma_{(N)} = \Sigma_{(N-1)}-a_{N-1}\frac{\partial}{\partial \Sigma_{(N-1)}}\left[ -\ln \left\{ \frac{1}{(2\pi)^{D/2}}\frac{1}{|\Sigma_{(N-1)}|^{1/2}}\exp\left\{ -\frac{1}{2}(\mathbf{x}_N-\boldsymbol{\mu})^{\mathrm{T}}\Sigma_{(N-1)}(\mathbf{x}_N-\boldsymbol{\mu}) \right\} \right\} \right]\hspace{2em} \cdots (2)
$$

この微分項について考える。

$$
\begin{aligned}
&\frac{\partial}{\partial \Sigma_{(N-1)}}\left[ -\ln \left\{ \frac{1}{(2\pi)^{D/2}}\frac{1}{|\Sigma_{(N-1)}|^{1/2}}\exp\left\{ -\frac{1}{2}(\mathbf{x}_N-\boldsymbol{\mu})^{\mathrm{T}}\Sigma_{(N-1)}(\mathbf{x}_N-\boldsymbol{\mu}) \right\} \right\} \right] \\
=& \frac{1}{2}\Sigma_{(N-1)}^{-1}-\frac{1}{2}\left\{ \Sigma_{(N-1)}^{-1}(\mathbf{x}_{N}-\boldsymbol{\mu})(\mathbf{x}_{N}-\boldsymbol{\mu})^{\mathrm{T}}\Sigma_{(N-1)}^{-1} \right\} \\
=& -\frac{1}{2}\Sigma_{(N-1)}^{-1}\left\{ (\mathbf{x}_{N}-\boldsymbol{\mu})(\mathbf{x}_{N}-\boldsymbol{\mu})^{\mathrm{T}} -\Sigma_{(N-1)} \right\}\Sigma_{(N-1)}^{-1}
\end{aligned}
$$

$(2)$式に当てはめれば

$$
\Sigma_{(N)} = \Sigma_{(N-1)}+\frac{a_{N-1}\Sigma_{(N-1)}^{-1}}{2}\left\{ (\mathbf{x}_{N}-\boldsymbol{\mu})(\mathbf{x}_{N}-\boldsymbol{\mu})^{\mathrm{T}} -\Sigma_{(N-1)} \right\}\Sigma_{(N-1)}^{-1}
$$

ここまではわかったけれど係数$a_{N-1}$がきれいな式にならない……。解答例では、追加で共分散行列がdiagonal（対角行列？）ならば$\displaystyle a_{N-1} = \frac{2}{N}\left( \Sigma_{(N-1)}\right)^2$とすれば良いと書いてあるが、仮にdiagonalでも合わない気がする。Googleで調べてみたけれどよくわからない。

> 参考：https://math.stackexchange.com/questions/1558016/deriving-mle-for-covariance-matrix-using-robbins-monro

## 演習 2.38
<div class="panel-primary">

二次形式を平方完成することで，

$$
\mu_{N} =\frac{\sigma^{2}}{N \sigma_{0}^{2}+\sigma^{2}} \mu_{0}+\frac{N \sigma_{0}^{2}}{N \sigma_{0}^{2}+\sigma^{2}} \mu_{\mathrm{ML}} \tag{2.141}
$$

$$
\frac{1}{\sigma_{N}^{2}} =\frac{1}{\sigma_{0}^{2}}+\frac{N}{\sigma^{2}} \tag{2.142}
$$

の結果を導出せよ．

</div>

$$
p(\mu \mid \mathbf{x}) \propto p(\mathbf{x} \mid \mu) p(\mu) \tag{2.139}
$$

について、

$$
p(\mathbf{x} \mid \mu)=\prod_{n=1}^{N} p\left(x_{n} \mid \mu\right)=\frac{1}{\left(2 \pi \sigma^{2}\right)^{N / 2}} \exp \left\{-\frac{1}{2 \sigma^{2}} \sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2}\right\} \tag{2.137}
$$

と$p(\mu) = \mathcal{N}(\mu | \mu_0, \sigma_0^2) \hspace{1em}(2.138)$式で変形する。

**$\mu$についての式**としての$p(\mathbf{X}|\mu)p(\mu)$の指数部分について考えると

$$
\begin{aligned}
& \exp \left\{ -\frac{1}{2\sigma^2}\sum_{n=1}^{N}(x_n-\mu)^2 \right\}\cdot \exp \left\{ -\frac{1}{2\sigma_0^2}(\mu-\mu_0)^2 \right\} \\
=&\exp \left \{ -\frac{1}{2\sigma^2} \sum_{n=1}^{N}(x_n^2 -2x_n \mu + \mu^2) - \frac{1}{2\sigma_0^2} (\mu^2 - 2\mu\mu_0 + \mu_0^2)\right\} \\
=&\exp \left\{ -\frac{1}{2}\left( \frac{N}{\sigma^2}+\frac{1}{\sigma_0^2}\right)\mu^2  + \left( \frac{1}{\sigma^2}\sum_{n=1}^{N}x_n+\frac{\mu_0}{\sigma_0^2} \right)\mu + \cdots  \right\}
\end{aligned}
$$

となる。ここで、$\cdots$の部分は$\mu$に依存しない項なので考えなくても良い。一方で、$(2.140)$の右辺の指数部分について考えると、

$$
\begin{aligned}
 & \exp \left\{ -\frac{1}{2\sigma_N^2}(\mu - \mu_N)^2 \right\} \\
=& \exp \left\{ -\frac{1}{2}\left( \frac{1}{\sigma_N^2} \right)\mu^2+\frac{\mu_N}{\sigma_N^2}\mu+\cdots \right\}
\end{aligned}
$$

$\displaystyle \sum_{n=1}^{N}x_n = N\mu_{\mathrm{ML}}$に注意して、これら2つの式を比較すると

$$
\begin{aligned}
\frac{1}{\sigma_N^2}&=\frac{1}{\sigma_0^2}+\frac{N}{\sigma^2},\hspace{2em}\left( \sigma_N^2 = \frac{\sigma^2\sigma_0^2}{\sigma^2+N\sigma_0^2} \right) \\
\frac{\mu_N}{\sigma_N^2}&=\frac{\mu_0}{\sigma_0^2}+\frac{N}{\sigma^2}\mu_{\mathrm{ML}}
\end{aligned}
$$

2式めを変形して

$$
\begin{aligned}
\mu_{N}&=\left( \frac{\mu_0}{\sigma_0^2}+\frac{N\mu_{\mathrm{ML}}}{\sigma^2} \right)\sigma_{N}^2 \\
       &=\left( \frac{\mu_0}{\sigma_0^2}+\frac{N\mu_{\mathrm{ML}}}{\sigma^2} \right) \left( \frac{\sigma^2\sigma_0^2}{\sigma^2+N\sigma_0^2} \right) \\
       &=\frac{\sigma^{2}}{N \sigma_{0}^{2}+\sigma^{2}} \mu_{0}+\frac{N \sigma_{0}^{2}}{N \sigma_{0}^{2}+\sigma^{2}} \mu_{\mathrm{ML}}
\end{aligned}
$$

**ベイズ推定では、事前知識を決め打ちではなく分布の形で表す。**

## 演習 2.39
<div class="panel-primary">

ガウス確率変数の平均の事後分布についての結果
$$
\mu_{N} =\frac{\sigma^{2}}{N \sigma_{0}^{2}+\sigma^{2}} \mu_{0}+\frac{N \sigma_{0}^{2}}{N \sigma_{0}^{2}+\sigma^{2}} \mu_{\mathrm{ML}} \tag{2.141}
$$

$$
\frac{1}{\sigma_{N}^{2}} =\frac{1}{\sigma_{0}^{2}}+\frac{N}{\sigma^{2}} \tag{2.142}
$$
を元に，最初の$N-1$個のデータ点の影響を分離し$\mu_{N}$と$\sigma^2_{N}$の逐次更新の式を求めよ．そして，事後分布$p\left(\mu | x_{1}, \ldots, x_{N-1}\right)=\mathcal{N}\left(\mu | \mu_{N-1}, \sigma_{N-1}^{2}\right)$に尤度関数$p(x_N|\mu) = \mathcal{N}(x_N|\mu, \sigma^2)$を掛けた後,平方完成と正規化をすることで，$N$個の観測値を得た後の事後分布と同じ結果を導出せよ．

</div>

問題文の通り、$N-1$個のデータ点との影響を分離する。ただし、分散$\sigma^2$は既知であることに注意する。

$(2.141)$と$(2.142)$式と、演習問題2.38の結果から、$\mu_0 \to \mu_{N-1}$, $\sigma_0 \to \sigma_{N-1}$, $\mu_{\mathrm{ML}}=x_N$, $N=1$の場合に当てはまるので、$\displaystyle \mu_N = \left( \frac{\mu_{N-1}}{\sigma_{N-1}^2}+\frac{x_N}{\sigma^2} \right)\sigma_N^2$の形になるはずである。これを示す。

$$
\begin{aligned}
  \frac{1}{\sigma_N^2}&=\frac{1}{\sigma_0^2}+\frac{N}{\sigma^2}=\frac{1}{\sigma_0^2}+\frac{N-1}{\sigma^2}+\frac{1}{\sigma^2} = \frac{1}{\sigma_{N-1}^2}+\frac{1}{\sigma^2} \\
  \sigma_N^2 &= \frac{\sigma^2+\sigma_{N-1}^2}{\sigma^2\sigma_{N-1}^2}
\end{aligned}
$$

平均$\mu_N$について

$$
\begin{aligned}
  \mu_N &= \frac{\sigma^{2}}{N \sigma_{0}^{2}+\sigma^{2}} \mu_{0}+\frac{N \sigma_{0}^{2}}{N \sigma_{0}^{2}+\sigma^{2}} \mu_{\mathrm{ML}} \\
  &= \frac{\mu_0}{\sigma_0^2}\sigma_N^2+\frac{\sigma_N^2}{\sigma^2}\left( \sum_{n=1}^{N-1}x_n + x_N \right) \\
  &= \left( \frac{\mu_0}{\sigma_0^2}+\frac{1}{\sigma^2}\sum_{n=1}^{N-1}x_n \right)\sigma_N^2 + \frac{x_N}{\sigma^2}\sigma_N^2
\end{aligned}
$$

ここで$\displaystyle \frac{\mu_0}{\sigma_0^2}+\frac{1}{\sigma^2}\sum_{n=1}^{N-1}x_n$について、演習2.38の途中式で出てきたように

$$
\frac{\mu_0}{\sigma_0^2}+\frac{1}{\sigma^2}\sum_{n=1}^{N-1}x_n = \frac{\mu_{N-1}}{\sigma_{N-1}^2}
$$

と書けるので、

$$
\mu_N = \left( \frac{\mu_{N-1}}{\sigma_{N-1}^2} + \frac{x_N}{\sigma^2} \right)\sigma_N^2\, \hspace{2em}\left( \frac{\mu_N}{\sigma_N^2} = \frac{\mu_{N-1}}{\sigma_{N-1}^2}+\frac{x_N}{\sigma^2} \right)
$$

となる。これが逐次更新の式となる。

事後分布に尤度関数をかけて、平方完成と正規化〜の部分は演習問題2.38の解き方と同じであり、得られる結果は上記となる。

## 演習 2.40
<div class="panel-primary">

$D$次元ガウス確率変数$\mathbf{x}$を考える．この分布$\mathcal{N}(\mathbf{x}|\boldsymbol{\mu}, \mathbf{\Sigma})$の共分散$\mathbf{\Sigma}$は既知としたとき，観測値集合$\mathbf{X} = \{ \mathbf{x}_1, \ldots, \mathbf{x}_N \}$から平均$\boldsymbol{\mu}$を推定したいとする．事前分布$p(\boldsymbol{\mu})=\mathcal{N}\left(\boldsymbol{\mu} | \boldsymbol{\mu}_{0}, \mathbf{\Sigma_{0}} \right)$について、これに対応する事後分布$p(\boldsymbol{\mu} | \mathbf{X})$を求めよ．

</div>


事後分布$p(\boldsymbol{\mu} | \mathbf{X})$は事前分布$\prod_{n=1}^{N} p\left(\mathbf{x}_{n} | \boldsymbol{\mu}, \mathbf{\Sigma}\right)$に尤度関数$p(\boldsymbol{\mu})$をかけたものに比例するので、

$$
p(\boldsymbol{\mu} | \mathbf{X}) \propto \prod_{n=1}^{N} p\left(\mathbf{x}_{n} | \boldsymbol{\mu}, \mathbf{\Sigma}\right) p(\boldsymbol{\mu})
$$

先の演習問題と同様に指数部分を考えると

$$
\begin{aligned}
  &-\frac{1}{2}\left(\boldsymbol{\mu}-\boldsymbol{\mu}_{0}\right)^{\mathrm{T}} \mathbf{\Sigma}_{0}^{-1}\left(\boldsymbol{\mu}-\boldsymbol{\mu}_{0}\right)-\frac{1}{2} \sum_{n=1}^{N}\left(\mathbf{x}_{n}-\boldsymbol{\mu}\right)^{\mathrm{T}} \mathbf{\Sigma}^{-1}\left(\mathbf{x}_{n}-\boldsymbol{\mu}\right) \\
  =&-\frac{1}{2} \boldsymbol{\mu}^{\mathrm{T}}\left(\mathbf{\Sigma}_{0}^{-1}+N \mathbf{\Sigma}^{-1}\right) \boldsymbol{\mu}+\boldsymbol{\mu}^{\mathbf{T}}\left(\mathbf{\Sigma}_{0}^{-1} \boldsymbol{\mu}_{0}+\mathbf{\Sigma}^{-1} \sum_{n=1}^{N} \mathbf{x}_{n}\right)+\mathrm{const.}
\end{aligned}
$$
ここで、$\mathrm{const.}$は$\boldsymbol{\mu}$と独立な項であり、正規化時に吸収される。

求める事後分布の形を$\mathcal{N}(\boldsymbol{\mu}|\boldsymbol{\mu}_N,\mathbf{\Sigma}_{N})$とすると、この指数部分は

$$
-\frac{1}{2}(\boldsymbol{\mu}-\boldsymbol{\mu}_N)^{\mathrm{T}}\mathbf{\Sigma}_N^{-1}(\boldsymbol{\mu}-\boldsymbol{\mu}_N)=-\frac{1}{2}\boldsymbol{\mu}^{\mathrm{T}}\mathbf{\Sigma}_N^{-1}\boldsymbol{\mu}+\boldsymbol{\mu}^{\mathrm{T}}\mathbf{\Sigma}_N^{-1}\boldsymbol{\mu}_N+\textrm{const.}
$$

となるので、まず$\boldsymbol{\mu}$の二次形式部分について

$$
\mathbf{\Sigma}_{N}^{-1} =\mathbf{\Sigma}_{0}^{-1}+N \mathbf{\Sigma}^{-1}
$$

となり、$\boldsymbol{\mu}^{\mathrm{T}}$の係数について
$$
\begin{aligned}
  \boldsymbol{\mu}_{N} &=\mathbf{\Sigma}_N\left(\mathbf{\Sigma}_{0}^{-1} \boldsymbol{\mu}_{0}+\mathbf{\Sigma}^{-1} N \boldsymbol{\mu}_{\mathrm{ML}}\right) \\
  &=\left(\mathbf{\Sigma}_{0}^{-1}+N \boldsymbol{\Sigma}^{-1}\right)^{-1}\left(\mathbf{\Sigma}_{0}^{-1} \boldsymbol{\mu}_{0}+\mathbf{\Sigma}^{-1} N \boldsymbol{\mu}_{\mathrm{ML}}\right)
\end{aligned}
$$

となる。ただし、ここで$\displaystyle \sum_{n=1}^{N}\mathbf{x}_n=N\boldsymbol{\mu}_{\mathrm{ML}}$とした。

すなわち、事後分布$p(\boldsymbol{\mu} | \mathbf{X})$は$\mathcal{N}(\boldsymbol{\mu}|\boldsymbol{\mu}_N,\mathbf{\Sigma}_{N}) = \mathcal{N}(\boldsymbol{\mu}\mid \left(\mathbf{\Sigma}_{0}^{-1}+N \boldsymbol{\Sigma}^{-1}\right)^{-1}\left(\mathbf{\Sigma}_{0}^{-1} \boldsymbol{\mu}_{0}+\mathbf{\Sigma}^{-1} N \boldsymbol{\mu}_{\mathrm{ML}}\right), (\mathbf{\Sigma}_{0}^{-1}+N \mathbf{\Sigma}^{-1})^{-1})$の形で書ける。

## 演習 2.41
<div class="panel-primary">

ガンマ関数

$$
\Gamma(a) \equiv \int_{0}^{\infty} u^{a-1} e^{-u} \mathrm{d} u \tag{1.141}
$$

の定義から，ガンマ分布

$$
\operatorname{Gam}(\lambda | a, b)=\frac{1}{\Gamma(a)} b^{a} \lambda^{a-1} \exp (-b \lambda) \tag{2.146}
$$

が正規化されていることを示せ．

</div>

ガンマ分布が正規化されている$\displaystyle \left(\int_0^{\infty}\frac{1}{\Gamma(a)} b^{a} \lambda^{a-1} \exp (-b \lambda) d\lambda = 1\right)$ことを示す。

これには$b\lambda = u$という変数変換を使うと（$d\lambda = b^{-1}du$）、

$$
\begin{aligned}
  &\int_0^{\infty}\frac{1}{\Gamma(a)} b^{a} \lambda^{a-1} \exp (-b \lambda) d\lambda \\
  =&\frac{1}{\Gamma(a)}\int_0^{\infty}b^a\lambda^{a-1}\exp(-u)b^{-1}du \\
  =&\frac{1}{\Gamma(a)}\int_0^{\infty}u^{a-1}e^{-u}du = \frac{\Gamma(a)}{\Gamma(a)} = 1
\end{aligned}
$$

となるので、正規化されていることが示された。

## 演習 2.42
<div class="panel-primary">

ガンマ分布

$$
\operatorname{Gam}(\lambda | a, b)=\frac{1}{\Gamma(a)} b^{a} \lambda^{a-1} \exp (-b \lambda) \tag{2.146}
$$

の平均，分散，およびモードを求めよ．

</div>

まず，平均を求める．

$$
\begin{aligned}
\mathbb E \left[\lambda \right] =& \int_0^{\infty} \frac{1}{\Gamma(a)} b^{a} \lambda^{a-1} \exp (-b \lambda) \lambda \mathrm{d} \lambda \\
=& \frac{1}{\Gamma(a)} \int_0^{\infty} b^{a} \lambda^a \exp (-b \lambda) \mathrm{d} \lambda \\
\end{aligned}
$$

ここで$b\lambda = u$と変数変換すると，$\mathrm{d} \lambda = b^{-1} \mathrm{d} u$であるから

$$
\begin{aligned}
\mathbb E \left[\lambda \right] =& \frac{1}{\Gamma(a)} \int_0^{\infty} u^a \exp (-u) b^{-1} \mathrm{d} u \\
=& \frac{1}{\Gamma(a)} b^{-1} \int_0^{\infty} u^a e^{-u} \mathrm{d} u \\
=& \frac{1}{\Gamma(a)} b^{-1} \Gamma(a+1) \\
=& \frac{1}{\Gamma(a)} b^{-1} a\Gamma(a) \\
=& \frac{a}{b}
\end{aligned}
$$

となる．

次に，分散を求める．

$$
\begin{aligned}
\mathbb E \left[\lambda^2 \right] =& \int_0^{\infty} \frac{1}{\Gamma(a)} b^{a} \lambda^{a-1} \exp (-b \lambda) \lambda^2 \mathrm{d} \lambda \\
=& \frac{1}{\Gamma(a)} \int_0^{\infty} b^{a} \lambda^{a+1} \exp (-b \lambda) \mathrm{d} \lambda \\
\end{aligned}
$$

ここで$b\lambda = u$と変数変換すると，$\mathrm{d} \lambda = b^{-1} \mathrm{d} u$であるから

$$
\begin{aligned}
\mathbb E \left[\lambda^2 \right] =& \frac{1}{\Gamma(a)} \int_0^{\infty} b^{-1} u^{a+1} \exp (-u) b^{-1} \mathrm{d} u \\
=& \frac{1}{\Gamma(a)} b^{-2} \int_0^{\infty} u^{a+1} e^{-u} \mathrm{d} u \\
=& \frac{1}{\Gamma(a)} b^{-2} \Gamma(a+2) \\
=& \frac{1}{\Gamma(a)} b^{-2} (a+1)\Gamma(a+1) \\
=& \frac{1}{\Gamma(a)} b^{-2} a(a+1)\Gamma(a) \\
=& \frac{a(a+1)}{b^2}
\end{aligned}
$$

となる．したがって分散は

$$
\begin{aligned}
\operatorname{var}\left[\lambda \right] =& \mathbb E \left[\lambda^2 \right] - \mathbb E \left[\lambda \right]^2 \\
=& \frac{a(a+1)}{b^2} - \frac{a^2}{b^2} \\
=& \frac{a}{b^2}
\end{aligned}
$$

となる．

次に，モードを求める．モードは分布の停留点を求めれば良いので$(2.146)$を$\lambda$で微分して0とおく．

$$
\begin{aligned}
& \frac{\mathrm{d}}{\mathrm{d}\lambda} \operatorname{Gam}(\lambda | a, b) = 0 \\
\Leftrightarrow ~ & \frac{\mathrm{d}}{\mathrm{d}\lambda} \frac{1}{\Gamma(a)} b^{a} \lambda^{a-1} \exp (-b \lambda) = 0 \\
\Leftrightarrow ~ & \frac{\mathrm{d}}{\mathrm{d}\lambda} \lambda^{a-1} e^{-b \lambda} = 0 \\
\Leftrightarrow ~ & (a-1) \lambda^{a-2} e^{-b \lambda} + \lambda^{a-1} e^{-b \lambda} (-b) = 0 \\
\Leftrightarrow ~ & \lambda^{a-2} e^{-b \lambda} (a-1-b\lambda) = 0 \\
\Leftrightarrow ~ & \lambda = \frac{a-1}{b} \\
\end{aligned}
$$

したがってモードは$\displaystyle \frac{a-1}{b}$となる．

## 演習 2.43
<div class="panel-primary">

次の分布は，1変数ガウス分布を一般化したものである．

$$
p\left(x | \sigma^{2}, q\right)=\frac{q}{2\left(2 \sigma^{2}\right)^{1 / q} \Gamma(1 / q)} \exp \left(-\frac{|x|^{q}}{2 \sigma^{2}}\right) \tag{2.293}
$$

この分布が，次のように正規化されていることを示せ．

$$
\int_{-\infty}^{\infty} p\left(x | \sigma^{2}, q\right) \mathrm{d} x=1 \tag{2.294}
$$
そして,$q=2$で$(2.293)$がガウス分布となることを示せ．目的変数が$t=y(\mathbf{x}, \mathbf{w})+\epsilon$で，ランダムノイズ変数$\epsilon$が分布$(2.293)$に従う回帰モデルを考える．入力ベクトル集合$\mathbf{X} = \{ \mathbf{x}_1, \cdots, \mathbf{x}_N \}$と，目的変数に相当する観測値が$\mathbf{t} = (t_1, \ldots, t_N)^{\mathrm{T}}$であるとき，$\mathbf{w}$と$\sigma^2$についての対数尤度関数が

$$
\ln p\left(\mathbf{t} | \mathbf{X}, \mathbf{w}, \sigma^{2}\right)=-\frac{1}{2 \sigma^{2}} \sum_{n=1}^{N}\left|y\left(\mathbf{x}_{n}, \mathbf{w}\right)-t_{n}\right|^{q}-\frac{N}{q} \ln \left(2 \sigma^{2}\right)+\mathrm{const} \tag{2.295}
$$

になることを示せ．ただし，$\mathrm{const}$は$\mathbf{w}$と$\sigma^2$の両方と独立な項である．なお，これは$\mathbf{w}$の関数として見た場合，1.5.5節で扱った$L_q$誤差関数である．

</div>

まず$(2.293)$について

$$
\begin{aligned}
\int_{-\infty}^{\infty} p(x | \sigma^2, q)dx &= \int_{-\infty}^{\infty} \frac{q}{2\left(2 \sigma^{2}\right)^{1 / q} \Gamma(1 / q)} \exp \left(-\frac{|x|^{q}}{2 \sigma^{2}}\right) d x
\\
&=\frac{q}{2\left(2 \sigma^{2}\right)^{1 / q} \Gamma(1 / q)} \cdot 2 \int_{0}^{\infty} \exp \left(-\frac{|x|^{q}}{2 \sigma^{2}}\right) d x \\
&=\frac{q}{\left(2 \sigma^{2}\right)^{1 / q} \Gamma(1 / q)} \int_{0}^{\infty} \exp \left(-\frac{x^{q}}{2 \sigma^{2}}\right) d x
\end{aligned}
$$

ここで$\displaystyle u = \frac{x^q}{2\sigma^2}$とおくと、$\displaystyle du = \frac{q}{2\sigma^2}x^{q-1}dx$, $x=(2\sigma^2u)^{1/q}$となるので、

$$
\begin{aligned}
\int_{0}^{\infty} \exp \left(-\frac{x^{2}}{2 \sigma^{2}}\right) d x
&=\int_{0}^{\infty} \frac{2 \sigma^{2}}{q x^{q-1}} e^{-u} du \\
&=\frac{2 \sigma^{2}}{q} \int_{0}^{\infty} \frac{1}{\left(2 \sigma^{2} u\right)^{\frac{q-1}{q}}} e^{-u} d u \\
&=\frac{2 \sigma^{2}}{q} \cdot \frac{\left(2 \sigma^{2}\right)^{\frac{1}{q}}}{2 \sigma^{2}} \int_{0}^{\infty} u^{\frac{1}{q}-1} e^{-u} d u \\
&=\frac{\left(2 \sigma^{2}\right)^{\frac{1}{q}}}{q} \Gamma(1 / q)
\end{aligned}
$$

よって

$$
\int_{-\infty}^{\infty} p\left(x \mid \sigma^{2}, q\right) d x=\frac{q}{\left(2 \sigma^{2}\right)^{1 / q} \Gamma(1 / q)} \cdot \frac{\left(2 \sigma^{2}\right)^{\frac{1}{q}}}{q} \Gamma(1 / q)=1
$$

正規化されていることが示された。
また、$q=2$のとき$\Gamma(1/2) = \sqrt{\pi}$を代入すれば

$$
\int_{-\infty}^{\infty} p\left(x \mid \sigma^{2}, 2 \right) dx = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left( -\frac{x^2}{2\sigma^2}\right)
$$

となり、ガウス分布の形になる。

最後に、ランダムノイズが$\epsilon$が$p(x|\sigma^2,q)$に従うとすると、$\epsilon = t-y(\mathbf{x}, \mathbf{w})$が$(2.293)$式の$x$に相当する。
$\mathbf{X} = \{\mathbf{x}_1, \ldots, \mathbf{x}_N\}$を入力として目的変数に相当する観測値が$\mathbf{t} = (t_1, \ldots, t_N)^{\mathrm{T}}$とするとき、1.2.5節での議論から

$$
p(\mathbf{t} | \mathbf{X}, \mathbf{w}, \sigma^2) = \prod_{n=1}^N p(t_n | \mathbf{x}_n, \mathbf{w}, \sigma^2)
$$

となるので、これの対数尤度は

$$
\begin{aligned}
\ln p\left(\mathbf{t} | \mathbf{X}, \mathbf{w}, \sigma^2 \right) &=\ln \left\{\prod_{n=1}^{N} \frac{q}{2\left(2 \sigma^{2}\right)^{1 / q} \Gamma(1 / q)} \exp \left(-\frac{\mid t_n-y\left(\mathbf{x}_n, \mathbf{w} \right) \mid^q}{2 \sigma^{2}}\right)\right \} \\
&=-\frac{1}{2 \sigma^{2}} \sum_{n=1}^{N}\left|y\left(\mathbf{x}_n, \mathbf{w} \right)-t_{n}\right|^{q}-\frac{N}{q} \ln \left(2 \sigma^{2}\right)+\operatorname{const}
\end{aligned}
$$

となる($\textrm{const}$は$\mathbf{w}$と$\sigma^2$の両方に独立な項である)。

> $(2.295)$を、パラメータ $\mathbf w$ についての式と見れば、1.5.5節の$L_q$損失(ミンコフスキー損失)と同値になります。
>
> 1.2.5節にあるように、回帰において、二乗損失($L_2$損失)の総和を最小化するパラメータ $\mathbf w$ を求める（＝最小二乗法）ことと、データのノイズにガウス分布を仮定して最尤推定によりパラメータ $\mathbf w$を求めることとは、$\mathbf w$ を決定する意味では結果的に同じになりました。
>
> これと同様に、回帰問題において、$L_q$損失を最小化することと、ノイズに一般化ガウス分布を仮定して最尤推定することとは、$\mathbf w$を決定する意味においては同じ事になります。

## 演習 2.44
<div class="panel-primary">

1変数ガウス分布$\mathcal{N}\left(x | \mu, \tau^{-1}\right)$について考える．共役事前分布はガウス–ガンマ分布

$$
p(\mu, \lambda)=\mathcal{N}\left(\mu \mid \mu_{0},(\beta \lambda)^{-1}\right) \operatorname{Gam}(\lambda \mid a, b) \tag{2.154}
$$

で，独立同分布な観測値集合が$\mathbf{x}=\left\{x_{1}, \ldots, x_{N}\right\}$であるとする．事後分布も，事前分布と同じガウスーガンマ分布になることを示し，各パラメータに対する事後分布の式を書き下せ．

</div>

事後分布は$p(\mu,\lambda|\mathbf{X})$、尤度関数は$p(\mathbf{X}|\mu, \lambda)$と書ける。
このとき共役事前分布$p(\mu,\lambda)$と合わせて、ベイズの定理から
$$
p(\mu,\lambda|\mathbf{X}) \propto p(\mathbf{X}|\mu, \lambda)p(\mu,\lambda)
$$
と書ける。また、$(2.152)$式のように尤度関数は

$$
\begin{aligned}
p(\mathbf{X} \mid \mu, \lambda)&=\prod_{n=1}^{N}\left(\frac{\lambda}{2 \pi}\right)^{1 / 2} \exp \left\{-\frac{\lambda}{2}\left(x_{n}-\mu\right)^{2}\right\} \\
&\propto\left[\lambda^{1 / 2} \exp \left(-\frac{\lambda \mu^{2}}{2}\right)\right]^{N} \exp \left\{\lambda \mu \sum_{n=1}^{N} x_{n}-\frac{\lambda}{2} \sum_{n=1}^{N} x_{n}^{2}\right\}
\end{aligned}
$$

の形で書ける。これと

$$
p(\mu, \lambda) \propto (\beta\lambda)^{1/2}\exp\left( -\frac{\beta\lambda}{2}(\mu-\mu_0)^2 \right)\lambda^{a-1}\exp(-b\lambda)
$$

を利用して、事後分布$p(\mu,\lambda|\mathbf{X})$の指数部を計算してみてガウス-ガンマ分布のそれと同型になることを示せば良い（正規化定数を求めるのはキツイ）。

$$
\begin{aligned}
    p(\mu,\lambda|\mathbf{X}) &= \lambda^{\frac{N}{2}}(\beta \lambda)^{\frac{1}{2}} \lambda^{a-1} \exp \left\{-\frac{N \lambda \mu^{2}}{2}-\frac{\beta \lambda}{2}\left(\mu-\mu_{0}\right)^{2}-b \lambda+\lambda \mu \sum_{n=1}^{N} x_{n}-\frac{\lambda}{2} \sum_{n=1}^{N} x_{n}^{2}\right\} \\
    &= \beta^{\frac{1}{2}} \lambda^{\frac{N}{2}+\frac{1}{2}+a-1} \exp \left\{\mu^{2} \left( -\frac{N \lambda}{2}-\frac{\beta \lambda}{2}\right)+\mu\left(\beta \lambda \mu_{0}+\lambda \sum_{n=1}^{N} x_{n}\right)-b \lambda-\frac{\lambda}{2} \sum_{n=1}^{N} x_{n}^{2}-\frac{\beta \lambda}{2} \mu_{0}^{2}\right\} \\
    &=\beta^{\frac{1}{2}} \lambda^{\frac{N}{2}+\frac{1}{2}+a-1} \exp \left\{ -\frac{\lambda(N+\beta)}{2} \mu^{2}+\mu \lambda\left(\beta \mu_{0}+\sum_{n=1}^{N} x_{n}\right)-\lambda\left(b+\frac{1}{2} \sum_{n=1}^{N} x_{n}^{2}-\frac{\beta}{2} \mu_{0}^{2}\right)\right\} \\
    &=\beta^{\frac{1}{2}} \lambda^{\frac{N}{2}+\frac{1}{2}+a-1} \exp \left\{-\frac{\lambda(N+\beta)}{2}\left(\mu-\frac{\beta\mu_0+\sum_{n=1}^{N} x_{n}}{N+\beta}\right)^{2}\right\}
    \exp \left\{-\lambda\left(b+\frac{1}{2} \sum_{n=1}^N x_{n}^{2}+\frac{\beta}{2} \mu_{0}^{2}-\frac{\left(\beta\mu_0+\sum_{n=1}^{N} x_{n}\right)^{2}}{2(N+\beta)}\right)\right\} \\
    &\propto (\lambda(N+\beta))^{\frac{1}{2}}\exp \left\{-\frac{\lambda(N+\beta)}{2}\left(\mu-\frac{\beta\mu_0+\sum_{n=1}^{N} x_{n}}{N+\beta}\right)^{2}\right\}\lambda^{a+\frac{N}{2}-1}\exp \left\{-\left(b+\frac{1}{2} \sum_{n=1}^N x_{n}^{2}+\frac{\beta}{2} \mu_{0}^{2}-\frac{\left(\beta\mu_0+\sum_{n=1}^{N} x_{n}\right)^{2}}{2(N+\beta)}\right)\lambda\right\}
\end{aligned}
$$

これは
$$
\begin{aligned}
\mu_{N} &=\frac{\beta \mu_{0}+\sum_{n=1}^{N} x_{n}}{N+\beta} \\
\lambda_{N}^{-1} &= (\lambda(N+\beta))^{-1} \\
a_{N} &=a+\frac{N}{2} \\
b_{N} &=b+\frac{1}{2} \sum_{n=1}^N x_{n}^{2}+\frac{\beta}{2} \mu_{0}^{2}-\frac{\left(\beta\mu_0+\sum_{n=1}^{N} x_{n}\right)^{2}}{2(N+\beta)}
\end{aligned}
$$
としたときの$\mathcal{N}(\mu|\mu_N,\lambda_N^{-1})\operatorname{Gam}(\lambda|a_N, b_N)$の指数部分と同型になる。

したがって、事後分布もガウス-ガンマ分布の形になっていることが示された。

## 演習 2.45
<div class="panel-primary">

$$
\mathcal{W}(\mathbf{\Lambda} \mid \mathbf{W}, \nu)=B|\mathbf{\Lambda}|^{(\nu-D-1) / 2} \exp \left(-\frac{1}{2} \operatorname{Tr}\left(\mathbf{W}^{-1} \mathbf{\Lambda}\right)\right) \tag{2.155}
$$

で定義されたウィシャート分布が確かに，多変量ガウス分布の精度行列の共役事前分布であることを確かめよ．

</div>

事前分布と尤度と掛け合わせて事後分布を求めたとき，目的とする変数についての形式が変わらないような事前分布が共役事前分布である．したがって，尤度を求め，精度$\mathbf \Lambda$についてウィシャート分布の形になっていることを確認すれば良い．

$\mathbf{X} = \{\mathbf{x}_1, \mathbf{x}_2, \cdots,\mathbf{x}_N\}$が与えられたとき，精度$\mathbf \Lambda$のガウス分布$\mathcal{N}(\mathbf{X}|\boldsymbol{\mu},\mathbf{\Lambda}^{-1})$の尤度関数は

$$
\begin{aligned}
& \prod_{n=1}^N \mathcal{N}(\mathbf{x}_n|\boldsymbol{\mu},\mathbf{\Lambda}^{-1}) \\
\propto & |\mathbf{\Lambda}|^{\frac{1}{2}} \exp{\left( -\frac{1}{2} \sum_{n=1}^N (\mathbf{x}_n - \boldsymbol{\mu})^{\mathrm{T}} \mathbf{\Lambda} (\mathbf{x}_n - \boldsymbol{\mu}) \right)} \\
=& |\mathbf{\Lambda}|^{\frac{1}{2}} \exp{\left( -\frac{1}{2} \sum_{n=1}^N \operatorname{Tr} \left[(\mathbf{x}_n - \boldsymbol{\mu})^{\mathrm{T}} \mathbf{\Lambda} (\mathbf{x}_n - \boldsymbol{\mu})  \right]\right)} \\
=& |\mathbf{\Lambda}|^{\frac{1}{2}} \exp{\left( -\frac{1}{2} \sum_{n=1}^N \operatorname{Tr} \left[(\mathbf{x}_n - \boldsymbol{\mu}) (\mathbf{x}_n - \boldsymbol{\mu})^{\mathrm{T}} \mathbf{\Lambda} \right]\right)} \\
=& |\mathbf{\Lambda}|^{\frac{1}{2}} \exp{\left( -\frac{1}{2} \operatorname{Tr} \left[ \sum_{n=1}^N (\mathbf{x}_n - \boldsymbol{\mu}) (\mathbf{x}_n - \boldsymbol{\mu})^{\mathrm{T}} \mathbf{\Lambda} \right]\right)} \\
=& |\mathbf{\Lambda}|^{\frac{1}{2}} \exp{\left( -\frac{1}{2} \operatorname{Tr} \left[\mathrm{S} \mathbf{\Lambda} \right]\right)} \\
\end{aligned}
$$

となり，ウィシャート分布と同じ形であることがわかる．ただし$\displaystyle \sum_{n=1}^N (\mathbf{x}_n - \boldsymbol{\mu}) (\mathbf{x}_n - \boldsymbol{\mu})^{\mathrm{T}} = \mathrm{S}$とおいた．

以上より，ウィシャート分布$(2.156)$は多変量ガウス分布の精度行列の共役事前分布となっていることが確認できた．


## 演習 2.46
<div class="panel-primary">

$$
\begin{aligned}
p(x|\mu,a,b)&=\int_{0}^{\infty} \mathcal{N} (x | \mu, \tau^{-1}) \operatorname{Gam}(\tau | a, b) d \tau \\
&=\int_{0}^{\infty} \frac{b^{a} e^{(-b \tau)} \tau^{a-1}}{\Gamma(a)}\left(\frac{\tau}{2 \pi}\right)^{1 / 2} \exp \left\{-\frac{\tau}{2}(x-\mu)^{2}\right\} \mathrm{d} \tau\\
&=\frac{b^{a}}{\Gamma(a)}\left(\frac{1}{2 \pi}\right)^{\frac{1}{2}} \int_{0}^{\infty} \tau^{a-\frac{1}{2}} \exp \left\{-\tau\left(b+\frac{(x-\mu)^{2}}{2}\right)\right\} d \tau \tag{2.146}
\end{aligned}
$$

の積分を計算し

$$
\operatorname{St}(x \mid \mu, \lambda, \nu)=\frac{\Gamma(\nu / 2+1 / 2)}{\Gamma(\nu / 2)}\left(\frac{\lambda}{\pi \nu}\right)^{1 / 2}\left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{-\nu / 2-1 / 2} \tag{2.159}
$$

になることを確かめよ．

</div>

まず$(2.158)$式に$\displaystyle \operatorname{Gam} ( \lambda |a, b)=\frac{1}{r(a)} b^{a} \lambda^{a-1} \exp (-b \lambda), \quad \Gamma(x)=\int_{0}^{\infty} u^{x-1} e^{-u} dx$を適用する。

$$
\begin{aligned}
&\int_{0}^{\infty} \mathcal{N} (x | \mu, \tau^{-1}) \operatorname{Gam}(\tau | a, b) d \tau \\
=&\int_{0}^{\infty} \frac{\sqrt{\tau}}{\sqrt{2 \pi}} \exp \left\{ -\frac{\tau}{2}(x-\mu)^{2}\right\} \frac{b^{a}}{\Gamma(a)} \tau^{a-1} \exp (-b \tau) d \tau \\
=&\frac{b^{a}}{\Gamma(a)}\left(\frac{1}{2 \pi}\right)^{\frac{1}{2}} \int_{0}^{\infty} \tau^{a-\frac{1}{2}} \exp \left\{-\tau\left(b+\frac{(x-\mu)^{2}}{2}\right)\right\} d \tau
\end{aligned}
$$
ここで、$\displaystyle b+\frac{(x-\mu)^2}{2}=c$とおき、$\tau c = u$とすると、$d\tau = c^{-1}du$

$$
\begin{aligned}
=&\frac{b^{a}}{\Gamma(a)}\left(\frac{1}{2 \pi}\right)^{\frac{1}{2}} \int_{0}^{\infty}\left(\frac{u}{c}\right)^{a-\frac{1}{2}} \exp (-u) \cdot c^{-1} d u \\
=&\frac{b^{a}}{\Gamma(a)}\left(\frac{1}{2 \pi}\right)^{\frac{1}{2}} c^{-a-\frac{1}{2}} \int_{0}^{\infty} u^{a-\frac{1}{2}} e^{-u} d u \\
=&\frac{b^{a}}{\Gamma(a)}\left(\frac{1}{2 \pi}\right)^{\frac{1}{2}}\left[b+\frac{(x-\mu)^{2}}{2}\right]^{-a-\frac{1}{2}} \Gamma\left(a+\frac{1}{2}\right)
\end{aligned}
$$

よって$(2.158)$の式変形が示された。次に$\displaystyle \nu=2a,\quad \lambda=\frac{a}{b}$とおくと, $\displaystyle b^a = \left( \frac{\nu}{2\lambda} \right)^\frac{\nu}{2}= \left( \frac{2\lambda}{\nu} \right)^{- \frac{\nu}{2}}$

$$
\begin{aligned}
&=\frac{\Gamma\left(\frac{\nu}{2}+\frac{1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)}\left(\frac{1}{2 \pi}\right)^{\frac{1}{2}}\left( \frac{2\lambda}{\nu} \right)^{- \frac{\nu}{2}}\left[\frac{\nu}{2 \lambda}+\frac{(x-\mu)^{2}}{2}\right]^{-\frac{\nu}{2}-\frac{1}{2}} \\
&=\frac{\Gamma\left(\frac{\nu}{2}+\frac{1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)} \left(\frac{\lambda}{\pi \nu}\right)^{\frac{1}{2}}  \left(\frac{2 \lambda}{\nu} \cdot \frac{\nu+\lambda(x-\mu)^{2}}{2 \lambda}\right)^{-\frac{\nu}{2}-\frac{1}{2}} \\
&=\frac{\Gamma\left(\frac{\nu}{2}+\frac{1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)}\left(\frac{\lambda}{\pi \nu}\right)^{\frac{1}{2}}\left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{-\frac{\nu}{2}-\frac{1}{2}}
\end{aligned}
$$
となり、$(2.159)$式に変形できることが示された。

## 演習 2.47
<div class="panel-primary">

$\nu \to \infty$の極限で，t分布

$$
\operatorname{St}(x \mid \mu, \lambda, \nu)=\frac{\Gamma(\nu / 2+1 / 2)}{\Gamma(\nu / 2)}\left(\frac{\lambda}{\pi \nu}\right)^{1 / 2}\left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{-\nu / 2-1 / 2} \tag{2.159}
$$

がガウス分布になることを示せ．ヒント: 正規化係数を無視し，$x$への依存性だけに注目する．

</div>

スチューデントのt分布が$\nu \to \infty$の極限で$\displaystyle \mathcal{N}(x|\mu, \lambda^{-1})=\sqrt{\frac{\lambda}{2\pi}} \exp \left\{ -\frac{\lambda(x-\mu)^2}{2} \right\}$になることを示す。

$\displaystyle \left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{-\frac{\nu}{2}-\frac{1}{2}}$の部分を$\exp(\cdot)$で表すように変形させることを意識する。また、$\displaystyle \frac{\Gamma\left(\frac{\nu}{2}+\frac{1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)\left(\frac{\nu}{2}\right)^{1/2}}$が$\nu \to \infty$の極限で1に収束することを示す。このために$\displaystyle \lim_{n\to\infty}\frac{\Gamma(x+n)}{\Gamma(n)n^x} = 1$であることを示す（※公式の解答集や問題文のヒントから、ここはどうせ規格化定数で吸収するので考えなくても良いことになっているけれど、一応示す）。

まずガンマ関数の定義から

$$
\Gamma(x) = \lim_{n\to\infty}\frac{(n-1)!n^x}{\prod_{k=0}^{n-1}(x+k)}
$$

逆数をとって

$$
\frac{1}{\Gamma(x)}=\lim_{n\to\infty}\frac{\prod_{k=0}^{n-1}(x+k)}{(n-1)!n^x}
$$

よって

$$
\begin{aligned}
1 &= \lim_{n\to\infty}\Gamma(x)\frac{\prod_{k=0}^{n-1}(x+k)}{(n-1)!n^x} \\
  &= \lim_{n\to\infty}\frac{\Gamma(x)\Gamma(x+n)}{\Gamma(n)\Gamma(x)n^x} \\
  &= \lim_{n\to\infty}\frac{\Gamma(x+n)}{\Gamma(n)n^x}
\end{aligned}
$$

ここで、$x = 1/2, n=\nu/2$とすれば、$\displaystyle \lim_{n\to\infty}\frac{\Gamma\left(\frac{\nu}{2}+\frac{1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)\left(\frac{\nu}{2}\right)^{1/2}} = 1$となることが示された。

ちなみにガンマ関数の定義をWikipediaにならって

$$
\Gamma(x) = \lim_{n\to\infty}\frac{n!n^x}{\prod_{k=0}^{n}(x+k)}
$$

とした場合、上の式変形を進めていくと

$$
1 = \lim_{n\to\infty}\left( 1+\frac{x}{n+1}\right)\frac{\Gamma(x+n)}{\Gamma(n)n^x}
$$

となる。$n\to\infty$で$\displaystyle 1+\frac{x}{n+1} \to 1$となることを使えば結果は同様となる（ということであってるかな……？）。

続いて$\displaystyle \left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{-\frac{\nu}{2}-\frac{1}{2}}$ について

$$
\left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{-\frac{\nu}{2}-\frac{1}{2}}= \exp \left\{ -\frac{\nu + 1}{2}\ln \left( 1+ \frac{\lambda(x-\mu)^2}{\nu}\right)\right\}
$$

ここでテイラー展開$\ln (1+\epsilon) = \epsilon+O(\epsilon^2)$を用いると

$$
\begin{aligned}
&\exp \left\{ -\frac{\nu + 1}{2}\ln \left( 1+ \frac{\lambda(x-\mu)^2}{\nu}\right)\right\} \\
=&\exp\left\{ -\frac{\nu+1}{\nu}\cdot \left( \frac{\lambda(x-\mu)^2}{2}+O(\nu^{-2})\right)\right\} \\
=&\exp\left\{ -\frac{\nu+1}{\nu}\cdot \frac{\lambda(x-\mu)^2}{2}+O(\nu^{-1})\right\}
\end{aligned}
$$

$\nu \to \infty$の極限で、上式は$\displaystyle \exp\left\{ -\frac{\lambda(x-\mu)^2}{2}\right\}$となる。

したがって以上をまとめると、$\nu \to \infty$の極限で

$$
\begin{aligned}
&\lim_{\nu\to\infty}\frac{\Gamma\left(\frac{\nu}{2}+\frac{1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)}\left(\frac{\lambda}{\pi \nu}\right)^{\frac{1}{2}}\left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{-\frac{\nu}{2}-\frac{1}{2}} \\
=&\lim_{\nu\to\infty}\frac{\Gamma\left(\frac{\nu}{2}+\frac{1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)\left(\frac{\nu}{2}\right)^\frac{1}{2}} \left(\frac{\lambda}{2\pi}\right)^{\frac{1}{2}}\left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{-\frac{\nu}{2}-\frac{1}{2}} \\
=&1\cdot\left(\frac{\lambda}{2\pi}\right)^{\frac{1}{2}}\exp\left\{ -\frac{\lambda(x-\mu)^2}{2}\right\} \\
=&\mathcal{N}(x|\mu,\lambda^{-1})
\end{aligned}
$$

となる。よってガウス分布となることが示された。

**別解**

ネイピア数の定義($\lim_{n\to\infty}(1 + n^{-1})^{n}=e$)に基づいて示す方法

$$
\begin{aligned}
\lim_{\nu\to\infty}\left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{-\frac{\nu+1}{2}}=& \lim_{\nu\to\infty}\left\{\left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{\frac{\nu}{\lambda(x-\mu)^{2}}}\right\}^{\frac{\lambda(x-\mu)^{2}}{\nu}({-\frac{\nu+1}{2}})}\\
=&\displaystyle \exp\left\{ -\frac{\lambda(x-\mu)^2}{2}\right\}
\end{aligned}
$$

{} の中身は $\nu\to\infty$ で exp になり {} の外側の指数部分は $\nu\to\infty$ で $\frac{\lambda(x-\mu)^{2}}{2}$ となることを用いた

## 演習 2.48
<div class="panel-primary">

1変数のスチューデントのt分布

$$
\operatorname{St}(x \mid \mu, \lambda, \nu)=\frac{\Gamma(\nu / 2+1 / 2)}{\Gamma(\nu / 2)}\left(\frac{\lambda}{\pi \nu}\right)^{1 / 2}\left[1+\frac{\lambda(x-\mu)^{2}}{\nu}\right]^{-\nu / 2-1 / 2} \tag{2.159}
$$

の導出で用いたのと同様の手続きで，スチューデントのt分布の多変量形式である

$$
\operatorname{St}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}, \nu)=\frac{\Gamma(D / 2+\nu / 2)}{\Gamma(\nu / 2)} \frac{|\mathbf{\Lambda}|^{1 / 2}}{(\pi \nu)^{D / 2}}\left[1+\frac{\Delta^{2}}{\nu}\right]^{-D / 2-\nu / 2} \tag{2.162}
$$

の結果を，

$$
\operatorname{St}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}, \nu)=\int_{0}^{\infty} \mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu},(\eta \mathbf{\Lambda})^{-1}\right) \operatorname{Gam}(\eta \mid \nu / 2, \nu / 2) \mathrm{d} \eta \tag{2.161}
$$

の変数$\eta$を周辺化することで確かめよ．定義$(2.161)$を用いて，積分変数の順序を交換することで，多変量t分布が正規化されていることを示せ．

</div>

$(2.161)$の積分表現から$(2.162)$を得ることを目的とする。途中で以下の定理を用いる。

> 任意の$n\times n$行列$\mathbf{A}$と任意のスカラー値$k$に対して
> $|k\mathbf{A}| = k^n|\mathbf{A}|$
> が成り立つ（統計のための行列代数P.217, 系13.2.4）

途中でマハラノビス距離$\Delta^2 = (\mathbf{x}-\boldsymbol{\mu})^{\mathrm{T}}\mathbf{\Lambda}(\mathbf{x}-\boldsymbol{\mu})$を用いると

$$
\begin{aligned}
\operatorname{St}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}, v)
&=\int_{0}^{\infty} \mathcal{N}\left(\mathbf{x} \mid \boldsymbol{\mu},(\eta \mathbf{\Lambda})^{-1}\right) \operatorname{Gam}\left(\eta \left| \frac{\nu}{2}, \frac{\nu}{2}\right.\right) d \eta \\
&=\int_{0}^{\infty} \frac{1}{(2 \pi)^{D/2}}|\eta \mathbf{\Lambda}|^{\frac{1}{2}} \exp \left\{-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^{\mathrm{T}}(\eta \mathbf{\Lambda})(\mathbf{x}-\boldsymbol{\mu})\right\} \frac{1}{\Gamma\left(\frac{\nu}{2}\right)}\left(\frac{\nu}{2}\right)^{\frac{\nu}{2}} \eta^{\frac{\nu}{2}-1} \exp \left\{-\frac{\nu}{2} \eta\right\} d\eta \\
&=\frac{|\mathbf{\Lambda}|^{\frac{1}{2}}}{(2 \pi)^{D/2}} \frac{\left(\frac{\nu}{2}\right)^{\nu/2}}{\Gamma\left(\frac{\nu}{2}\right)} \int_{0}^{\infty} \eta^{\frac{D}{2}} \cdot \eta^{\frac{\nu}{2}-1} \exp \left\{-\frac{\nu}{2} \eta-\frac{\eta}{2} \Delta^{2}\right\} d\eta
\end{aligned}
$$
ここで$\displaystyle \tau = \left( \frac{\nu}{2}+\frac{\Delta^2}{2} \right)$とおくと、$\displaystyle d\tau = \left( \frac{\nu}{2}+\frac{\Delta^2}{2}\right)d\eta$で、

$$
\begin{aligned}
(与式)
&=\frac{|\mathbf{\Lambda}|^{\frac{1}{2}}}{(2 \pi)^{D/2}} \frac{\left(\frac{\nu}{2}\right)^{\nu/2}}{\Gamma\left(\frac{\nu}{2}\right)}\left(\frac{\nu}{2}+\frac{\Delta^{2}}{2}\right)^{-\frac{D}{2}-\frac{\nu}{2}} \int_{0}^{\infty} \tau^{\frac{D}{2}+\frac{\nu}{2}-1} e^{-\tau} d \tau \\
&=\frac{|\mathbf{\Lambda}|^{\frac{1}{2}}}{(2 \pi)^{D/2}} \frac{\left(\frac{\nu}{2}\right)^{\nu/2}}{\Gamma\left(\frac{\nu}{2}\right)}\left(\frac{\nu}{2}+\frac{\Delta^{2}}{2}\right)^{-\frac{D}{2}-\frac{\nu}{2}} \Gamma\left(\frac{D}{2}+\frac{\nu}{2}\right) \\
&=\frac{\Gamma\left(\frac{D}{2}+\frac{\nu}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)} \cdot \frac{\left(\frac{\nu}{2}\right)^{\nu/2}}{(2 \pi)^{D/2}} | \mathbf{\Lambda} |^{\frac{1}{2}}\left(\frac{\nu}{2}\right)^{-\frac{D}{2}-\frac{\nu}{2}}\left[1+\frac{\Delta^{2}}{\nu}\right]^{-\frac{D}{2}-\frac{\nu}{2}} \\
&=\frac{\Gamma\left(\frac{D}{2}+\frac{\nu}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)} \frac{|\mathbf{\Lambda}|^{\frac{1}{2}}}{(\nu \pi)^{D/2}}\left[1+\frac{\Delta^{2}}{\nu}\right]^{-\frac{D}{2}-\frac{\nu}{2}}
\end{aligned}
$$

よって$(2.162)$式が得られた。

また、この多変数t分布が正規化されていることを示す。すなわち、

$$
\int_{-\infty}^{\infty}\operatorname{St}(\mathbf{x}|\boldsymbol{\mu},\mathbf{\Lambda},\nu) d\mathbf{x} = 1
$$

であることを示す。（問題文のヒントから）積分が交換可能であることを利用すると、定義から

$$
\begin{aligned}
 & \int_{-\infty}^{\infty} \operatorname{St}(\mathbf{x}|\boldsymbol{\mu},\mathbf{\Lambda},\nu) d\mathbf{x} \\
=& \int_{-\infty}^{\infty} \int_{0}^{\infty} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu},\left(\eta\mathbf{\Lambda}^{-1}\right)\right) \operatorname{Gam}\left(\eta \left| \frac{\nu}{2}, \frac{\nu}{2}\right.\right) d\eta d\mathbf{x} \\
=& \int_{0}^{\infty} \underbrace{\int_{-\infty}^{\infty} \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu},\left(\eta \mathbf{\Lambda}^{-1}\right)\right) d\mathbf{x}}_{1} \operatorname{Gam}\left(n \left| \frac{\nu}{2}, \frac{\nu}{2}\right.\right) d \eta \\
=& \int_{0}^{\infty} \operatorname{Gam}\left(\eta \left| \frac{\nu}{2}, \frac{\nu}{2}\right.\right) d\eta \\
=& 1
\end{aligned}
$$

ガンマ分布が正規化されていることは演習問題2.41で示した。

## 演習 2.49
<div class="panel-primary">

ガウス分布とガンマ分布のたたみ込みである多変量スチューデントt分布の定義$(2.161)$を用いて，$(2.162)$で定義される多変量t分布の平均，共分散，およびモード

$$
\mathbb{E}[\mathbf{x}] = \boldsymbol{\mu} \hspace{2em} (\mu > 1のとき)\tag{2.164}
$$

$$
\operatorname{cov}[\mathbf{x}] = \frac{\nu}{\nu -2} \mathbf{\Lambda}^{-1} \hspace{2em} (\mu > 2のとき)\tag{2.165}
$$

$$
\operatorname{mode}[\mathbf{x}] = \boldsymbol{\mu} \tag{2.166}
$$

を確かめよ．

</div>


$$
\begin{aligned}
 \mathbb{E}[\mathbf{x}] &= \int_{0}^{\infty} \underbrace{\int
 \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu},\left(\eta\mathbf{\Lambda}\right)^{-1}\right) \mathbf{x} d\mathbf{x}}_{\boldsymbol{\mu}(\because{(2.58)式})}\operatorname{Gam}\left(\eta \left| \frac{\nu}{2}, \frac{\nu}{2}\right.\right) d\eta  \\
 &= \int_{0}^{\infty} \boldsymbol{\mu}\operatorname{Gam}\left(\eta \left| \frac{\nu}{2}, \frac{\nu}{2}\right.\right) d\eta \\
 &=\boldsymbol{\mu} (\because 演習2.41)
\end{aligned}
$$


----


$$
\begin{aligned}
 \operatorname{cov}[\mathbf{x}] &= \int\int_{0}^{\infty}
 \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu},\left(\eta\mathbf{\Lambda}\right)^{-1}\right) \operatorname{Gam}\left(\eta \left| \frac{\nu}{2}, \frac{\nu}{2}\right.\right) d\eta (\mathbf{x}-\boldsymbol{\mu})(\mathbf{x}-\boldsymbol{\mu})^\mathrm{T} d\mathbf{x} \\
 &= \int_{0}^{\infty}\underbrace{\int
 \mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu},\left(\eta\mathbf{\Lambda}\right)^{-1}\right) (\mathbf{x}-\boldsymbol{\mu})(\mathbf{x}-\boldsymbol{\mu})^\mathrm{T} d\mathbf{x}}_{\left(\eta\mathbf{\Lambda}\right)^{-1}} \operatorname{Gam}\left(\eta \left| \frac{\nu}{2}, \frac{\nu}{2}\right.\right) d\eta  \\
 &=\int_{0}^{\infty}\left(\eta\mathbf{\Lambda}\right)^{-1} \frac{1}{\Gamma(\frac{\nu}{2})}\left(\frac{\nu}{2}\right)^\frac{\nu}{2}\eta^{\left(\frac{\nu}{2}-1\right)} e^{{-\frac{\nu}{2}}\eta} d\eta \\
 &=\mathbf{\Lambda}^{-1} \frac{\frac{\nu}{2}^\frac{\nu}{2}}{\Gamma(\frac{\nu}{2})} \int_{0}^{\infty}\eta^{\left(\frac{\nu}{2}-2\right)}e^{-\frac{\nu}{2}\eta}d\eta \\\\
 &ここで\frac{\nu}{2}\eta = uとおく。d\eta=\frac{2}{\nu}du \\\\
 &=\mathbf{\Lambda}^{-1} \frac{\frac{\nu}{2}^\frac{\nu}{2}}{\Gamma(\frac{\nu}{2})} \int_{0}^{\infty}\left(\frac{2u}{\nu}\right)^{\left(\frac{\nu}{2}-2\right)}e^{-u}\frac{2}{\nu}du \\
 &=\mathbf{\Lambda}^{-1} \frac{\frac{\nu}{2}^\frac{\nu}{2}}{\Gamma(\frac{\nu}{2})}\left(\frac{2}{\nu}\right)^{\left(\frac{\nu}{2}-1\right)} \underbrace{\int_{0}^{\infty}u^{\left(\frac{\nu}{2}-2\right)}e^{-u}du}_{\Gamma(\frac{\nu}{2}-1)} \\
 &=\mathbf{\Lambda}^{-1} \frac{\Gamma(\frac{\nu}{2}-1)}{\Gamma(\frac{\nu}{2})}\frac{\nu}{2} \\
 &=\mathbf{\Lambda}^{-1} \frac{\Gamma(\frac{\nu}{2}-1)}{\Gamma(\frac{\nu}{2}-1)\left(\frac{\nu}{2}-1\right)}\frac{\nu}{2}\\
 &=\frac{\nu}{\nu-2}\Lambda^{-1}\\
\end{aligned}
$$

----

$mode[x]=\boldsymbol{\mu}$ を示す

$$
\begin{aligned}\\
\operatorname{St}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}, \nu)=\frac{\Gamma(D / 2+\nu / 2)}{\Gamma(\nu / 2)} \frac{|\mathbf{\Lambda}|^{1 / 2}}{(\pi \nu)^{D / 2}}\left[1+\frac{\Delta^{2}}{\nu}\right]^{-D / 2-\nu / 2}\\
\end{aligned}
$$

このようにかけるので

$$
\begin{aligned}
&\frac{\partial}{\partial\mathbf{x}}\operatorname{St}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}, \nu)\propto \frac{\partial}{\partial\mathbf{x}}\left[1+\frac{\Delta^{2}}{\nu}\right]^{-D / 2-\nu / 2}\\
&=\left(-\frac{D}{2}-\frac{\nu}{2}\right)\left[1+\frac{\Delta^2}{\nu}\right]^{-D/2-\nu/2-1}\frac{2}{\nu}\mathbf{\Lambda}(\mathbf{x}-\boldsymbol{\mu})\\
\end{aligned}
$$
これが$\mathbf{0}$となるのは$\mathbf{x}=\boldsymbol{\mu}$のとき



## 演習 2.50
<div class="panel-primary">

$\nu \to \infty$の極限で，多変量スチューデントt分布

$$
\operatorname{St}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}, \nu)=\frac{\Gamma(D / 2+\nu / 2)}{\Gamma(\nu / 2)} \frac{|\mathbf{\Lambda}|^{1 / 2}}{(\pi \nu)^{D / 2}}\left[1+\frac{\Delta^{2}}{\nu}\right]^{-D / 2-\nu / 2} \tag{2.162}
$$

が，平均が$\boldsymbol{\mu}$で精度が$\mathbf{\Lambda}$のガウス分布になることを示せ．

</div>

$\lim_{\nu \to \infty} \operatorname{St}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}, \nu)=\mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu},\mathbf{\Lambda}\right)$を示す。スチューデントのt分布の形は

$$
\operatorname{St}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}, \nu)=\frac{\Gamma(D / 2+\nu / 2)}{\Gamma(\nu / 2)} \frac{|\mathbf{\Lambda}|^{1 / 2}}{(\pi \nu)^{D / 2}}\left[1+\frac{\Delta^{2}}{\nu}\right]^{-D / 2-\nu / 2}
$$

ここで$\displaystyle \lim_{\nu \to \infty}\frac{\Gamma(D/2+\nu/2)}{\Gamma(\nu/2)\left(\nu/2\right)^{D/2}}=1$であるので(演習2.47を参照)、

$$
\begin{aligned}\\
\lim_{\nu\to\infty}\operatorname{St}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}, \nu) &= \lim_{\nu\to\infty}\frac{|\mathbf{\Lambda}|^{1 / 2}}{(2\pi)^{D / 2}}\left[1+\frac{\Delta^{2}}{\nu}\right]^{-D / 2-\nu / 2} \\
&=\frac{|\mathbf{\Lambda}|^{1 / 2}}{(2\pi)^{D / 2}}\lim_{\nu\to\infty}\underbrace{\left[1+\frac{\Delta^{2}}{\nu}\right]^{-D / 2}}_{\to1}\left[1+\frac{\Delta^{2}}{\nu}\right]^{-\nu / 2}
\end{aligned}
$$

ここで$\displaystyle u=-\frac{\nu}{2}$と置換し$\displaystyle \exp(x)=\lim_{n\to\infty}\left[1+\frac{x}{n}\right]^{n}=\lim_{n\to-\infty}\left[1+\frac{x}{n}\right]^{n}$を用いると

$$
\begin{aligned}
\lim_{\nu\to\infty}\operatorname{St}(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Lambda}, \nu) &= \frac{|\mathbf{\Lambda}|^{1 / 2}}{(2\pi)^{D / 2}}\lim_{u\to-\infty}\left[1-\frac{\Delta^{2}}{2u}\right]^{u}\\
&=\frac{|\mathbf{\Lambda}|^{1 / 2}}{(2\pi)^{D / 2}}\exp\left(-\frac{\Delta^{2}}{2}\right)\\
&=\mathcal{N}\left(\mathbf{x} | \boldsymbol{\mu},\mathbf{\Lambda}\right)
\end{aligned}
$$

## 演習 2.51
<div class="panel-primary">

本章の周期変数の議論で用いた，いろいろな三角関数の公式は，次の関係を用いて容易に証明できる．

$$
\exp(iA) = \cos A+i\sin A \tag{2.296}
$$

ただし$i$は$-1$の平方根である．

$$
\cos^2 A+\sin^2 A = 1 \tag{2.177}
$$

の結果を

$$
\exp(iA) \exp(-iA)=1 \tag{2.297}
$$

から証明せよ．同様に

$$
\cos (A-B)=\Re \exp \{i(A-B)\} \tag{2.298}
$$

を用いて

$$
\cos A \cos B+\sin A \sin B=\cos (A-B) \tag{2.178}
$$

を証明せよ．ただし，$\Re$は実部を示す．最後に，$\sin (A-B) = \Im \exp\{i(A-B)\}$から，

$$
\sin (A-B)=\sin A \cos B-\cos A \sin B \tag{2.183}
$$

を証明せよ．ただし，$\Im$は虚部を示す．

</div>
(2.296)を(2.297)に代入すると

$$\begin{aligned}( \text{左辺} ) &= \exp(iA)\exp(-iA) \\&= (\cos A + i \sin iA)(\cos A - i \sin iA) \\&= \cos^2 A + \sin^2 A \end{aligned}$$
よって、(2.177)は示された。


(2.298)より

$$\begin{aligned} \cos (A-B) &= \Re \exp \{ i(A-B) \} \\&= \Re \exp(iA) \exp(-iB) \\&= \Re (\cos A + i \sin iA)(\cos B - i \sin iB) \\&= \cos A \cos B + \sin A \sin B \end{aligned}$$


また

$$\begin{aligned} \sin (A-B) &= \Im \exp \{ i(A-B) \} \\&= \Im \exp(iA) \exp(-iB) \\&= \Im (\cos A + i \sin iA)(\cos B - i \sin iB) \\&= \sin A \cos B - \cos A \sin B \end{aligned}$$


## 演習 2.52
<div class="panel-primary">

フォン・ミーゼス分布

$$
p\left(\theta \mid \theta_{0}, m\right)=\frac{1}{2 \pi I_{0}(m)} \exp \left\{m \cos \left(\theta-\theta_{0}\right)\right\} \tag{2.179}
$$

は，$m$が大きいとき，モード$\theta_0$の周囲で鋭く尖る．$\xi = m^{1/2}(\theta-\theta_0)$と定義し，余弦関数のテイラー展開が

$$
\cos \alpha = 1-\frac{\alpha^2}{2}+O(\alpha^4)　\tag{2.299}
$$
であるとして，$m \to \infty$でフォン・ミーゼス分布がガウス分布になることを示せ．

</div>

$\xi = m^{1/2}(\theta-\theta_0)$より、$\theta-\theta_0 = \xi m^{-1/2}$。

これをフォン・ミーゼス分布(2.179)に代入すると、

$$\begin{aligned} p\left(\theta \mid \theta_{0}, m\right) &\propto \exp \left\{m \cos \left(\theta-\theta_{0}\right)\right\} \\&= \exp \left\{m \cos \left(\xi m^{-1/2}\right)\right\} \\&= \exp \left\{m \left( 1 - \frac{1}{2} \xi^2 m^{-1} + O(\xi^4 m^{-2}) \right) \right\} \\&\propto \exp \left( -\frac{\xi^2}{2} \right) \\&= \exp \left\{ - \frac{m(\theta - \theta_{0})^2}{2} \right\} \end{aligned}$$

これはガウス分布の形になっているので示された。


## 演習 2.53
<div class="panel-primary">

三角関数の公式
$$
\sin (A-B)=\sin A \cos B-\cos A \sin B \tag{2.183}
$$
を用いて，$\theta_0$についての

$$
\sum_{n=1}^{N} \sin \left(\theta_{n}-\theta_{0}\right)=0 \tag{2.182}
$$

の解が

$$
\theta_{0}^{\mathrm{ML}}=\tan ^{-1}\left\{\frac{\sum_{n} \sin \theta_{n}}{\sum_{n} \cos \theta_{n}}\right\} \tag{2.184}
$$

となることを示せ．

</div>

$(2.183)$で示されている加法定理$\sin(A-B) = \sin A \cos B- \cos A \sin B$を用いて$(2.182)$式を解いて

$$
\sum_{n=1}^{N}\sin(\theta_n-\theta_0)=0 \\
$$
$$
\sum_{n=1}^{N}\left( \sin \theta_n \cos \theta_0 -\cos \theta_n \sin\theta_0 \right) =0 \\
$$
$$sin\theta_0\sum_{n=1}^{N}\cos(\theta_n)=cos\theta_0\sum_{n=1}^{N}\sin(\theta_n)$$
$$
\tan \theta_0 = \frac{\sum_{n}\sin\theta_n}{\sum_{n}\cos\theta_n}
$$

なので、最尤推定量$\theta_0^{\mathrm{ML}}$は

$$
\theta_0^{\mathrm{ML}} = \tan^{-1}\left\{ \frac{\sum_{n}\sin\theta_n}{\sum_{n}\cos\theta_n} \right\}
$$

となり、$(2.184)$式を得ることができた。

## 演習 2.54
<div class="panel-primary">

フォン・ミーゼス分布
$$
p\left(\theta \mid \theta_{0}, m\right)=\frac{1}{2 \pi I_{0}(m)} \exp \left\{m \cos \left(\theta-\theta_{0}\right)\right\} \tag{2.179}
$$
の1階と2階の導関数を求め，さらに$m>0$で$I_0(m) > 0$であることを用いて，分布は$\theta = \theta_0$で最大になり，$\theta = \theta_0 + \pi\, (\mathrm{mod}\ 2\pi)$で最小になることを示せ．

</div>

1階の導関数は
$$
\frac{\partial}{\partial \theta} p\left(\theta \mid \theta_{0}, m\right)=\frac{1}{2 \pi I_{0}(m)} \exp \left(m \cos \left(\theta-\theta_{0}\right)\right)\left(-m \sin \left(\theta-\theta_{0}\right)\right)
$$
2階の導関数は
$$
\begin{aligned}
\frac{\partial^{2}}{\partial \theta^{2}} p\left(\theta \mid \theta_{0}, m\right) &=
\frac{1}{2 \pi I_{0}(m)} \exp \left(m \cos\left(\theta-\theta_{0}\right)\left(-m \sin \left(\theta-\theta_{0}\right)\right)\left(-m \sin \left(\theta-\theta_{0}\right)\right)\right. \\ &\left.\left.+\exp \left(m\cos \left(\theta-\theta_{0}\right)\right)( -m\cos \left(\theta-\theta_{0}\right)\right)\right\} \\ &=\frac{1}{2 \pi I_{0}(m)} \exp \left(m\cos \left(\theta-\theta_{0}\right)\right)\left(m^{2} \sin ^{2}\left(\theta-\theta_{0}\right)-m \cos \left(\theta-\theta_{0}\right)\right)
\end{aligned}
$$

上の結果より$\displaystyle \frac{\partial p}{\partial \theta} = 0$となるのは$\displaystyle \frac{1}{2\pi I_0(m)}\exp (m \cos (\theta - \theta_0))>0, m>0$より$\sin(\theta - \theta_0)=0$のとき、つまり$\theta = \theta_0, \theta = \theta_0 + \pi\ (\textrm{mod}\ 2\pi)$のとき。

$\theta = \theta_0$では

$$
\frac{\partial^{2} p}{\partial \theta^{2}}=\frac{1}{2 \pi I_{0}(m)} \exp \left(m \cos \left(\theta-\theta_{0}\right)\right)(-m)<0
$$

なので、$\theta = \theta_0$が$P(\theta \mid \theta_0,m)$の極大点。

$\theta = \theta_0 + \pi$では

$$\frac{\partial^2 p}{\partial \theta^2} = \frac{1}{2\pi I_0(m)}\exp (m \cos (\theta - \theta_0))$$

$m>0$より$\theta = \theta_0 + \pi\ (\mathrm{mod}\ 2\pi)$が$P(\theta \mid \theta_0, m)$の極小点となる。

## 演習 2.55
<div class="panel-primary">

$$
\bar{x}_{1}=\bar{r} \cos \bar{\theta}=\frac{1}{N} \sum_{n=1}^{N} \cos \theta_{n}, \quad \bar{x}_{2}=\bar{r} \sin \bar{\theta}=\frac{1}{N} \sum_{n=1}^{N} \sin \theta_{n} \tag{2.168}
$$
の結果を，

$$
\theta_{0}^{\mathrm{ML}}=\tan ^{-1}\left\{\frac{\sum_{n} \sin \theta_{n}}{\sum_{n} \cos \theta_{n}}\right\} \tag{2.184}
$$

と三角関数の公式

$$
\cos A \cos B+\sin A \sin B=\cos (A-B) \tag{2.178}
$$

と共に用いて，フォン・ミーゼス分布の集中度の最尤推定解$m_{\mathrm{ML}}$が，$A(m_{\mathrm{ML}})=\bar{r}$を満たすことを示せ．ただし，$\bar{r}$は，図2.17のように，2次元ユークリッド平面中の単位ベクトルによって表した観測値の平均の半径である．

</div>
(2.187)より

$$\begin{aligned} A(m_{\mathrm{ML}}) &= \left( \frac{1}{N} \sum_{n=1}^{N} \cos \theta_n \right) \cos \theta_{0}^{\mathrm{ML}} + \left( \frac{1}{N} \sum_{n=1}^{N} \sin \theta_n \right) \sin \theta_{0}^{\mathrm{ML}} \\&= \bar{r} \cos \bar{\theta} \cos \theta_{0}^{\mathrm{ML}} + \bar{r} \sin \bar{\theta} \sin \theta_{0}^{\mathrm{ML}} \\&= \bar{r} \cos \theta_{0}^{\mathrm{ML}} \cos \theta_{0}^{\mathrm{ML}} + \bar{r} \sin \theta_{0}^{\mathrm{ML}} \sin \theta_{0}^{\mathrm{ML}} \\&= \bar{r} \end{aligned}$$

## 演習 2.56
<div class="panel-primary">

ベータ分布

$$
\operatorname{Beta}(\mu \mid a, b)=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \mu^{a-1}(1-\mu)^{b-1} \tag{2.13}
$$

ガンマ分布

$$
\operatorname{Gam}(\lambda \mid a, b)=\frac{1}{\Gamma(a)} b^{a} \lambda^{a-1} \exp (-b \lambda) \tag{2.146}
$$

およびフォン・ミーゼス分布
$$
p\left(\theta \mid \theta_{0}, m\right)=\frac{1}{2 \pi I_{0}(m)} \exp \left\{m \cos \left(\theta-\theta_{0}\right)\right\} \tag{2.179}
$$
を指数型分布族の形

$$
p(\mathbf{x} \mid \boldsymbol{\eta})=h(\mathbf{x}) g(\boldsymbol{\eta}) \exp \left\{\boldsymbol{\eta}^{\mathbf{T}} \mathbf{u}(\mathbf{x})\right\} \tag{2.194}
$$

に変形し，これらの分布の自然パラメータを求めよ．

</div>

※ 与えられた各分布の形を無理やり指数型分布族の一般形に変形していけば求まる。パラメータの変数名は各分布にしたがって適切に置き換える。

まずベータ分布は

$$
\begin{aligned}
    \frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \mu^{a-1}(1-\mu)^{b-1}
    &= \frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)}\exp\left\{ (a-1)\ln \mu +(b-1) \ln(1-\mu) \right\}
    \\
    &= \frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)}\exp\left\{ \left(\begin{array}{c}a-1 \\ b-1\end{array}\right)^{\mathrm{T}} \left(\begin{array}{c}\ln \mu \\ \ln (1-\mu)\end{array}\right) \right\}
\end{aligned}
$$

これより、一般形と照らし合わせると、$\mathbf{x}\to\mu$, $\eta \to a,b$として

$$
h(\mu) = 1,\ g(a,b) = \frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)},\ \boldsymbol{\eta}(a,b) = \left(\begin{array}{c}a-1 \\ b-1\end{array}\right),\ \mathbf{u}(\mu) = \left(\begin{array}{c}\ln \mu \\ \ln (1-\mu)\end{array}\right)
$$

同様にしてガンマ分布は

$$
\begin{aligned}
    \frac{1}{\Gamma(a)} b^{a} \lambda^{a-1} \exp (-b \lambda) &= \frac{1}{\Gamma(a)} b^{a} \exp \{(a-1)\ln\lambda - b\lambda\} \\
    &= \frac{b^a}{\Gamma(a)} \exp \left\{ \begin{pmatrix}a-1 \\ -b \end{pmatrix}^{\mathrm{T}} \begin{pmatrix}\ln \lambda \\ \lambda \end{pmatrix}\right\}
\end{aligned}
$$

これより

$$
h(\lambda) = 1,\ g(a,b) = \frac{b^a}{\Gamma(a)},\ \boldsymbol{\eta}(a,b) = \left(\begin{array}{c}a-1 \\ -b\end{array}\right),\ \mathbf{u}(\lambda) = \left(\begin{array}{c}\ln \lambda \\ \lambda \end{array}\right)
$$

フォン・ミーゼス分布は

$$
\begin{aligned}
    \frac{1}{2 \pi I_{0}(m)} \exp \left\{m \cos \left(\theta-\theta_{0}\right)\right\}
    &= \frac{1}{2 \pi I_{0}(m)} \exp \{ m\cos \theta \cos\theta_0 + m\sin\theta \sin\theta_0 \} \\
    &= \frac{1}{2 \pi I_{0}(m)} \exp \left\{ \left(\begin{array}{c}m\cos\theta_0 \\ m\sin\theta_0 \end{array}\right)^{\mathrm{T}} \left(\begin{array}{c}\cos\theta \\ \sin\theta \end{array}\right) \right\}
\end{aligned}
$$

これより、
$$
h(\theta) = 1,\ g(\theta_0, m) = \frac{1}{2\pi I_0(m)},\ \boldsymbol{\eta}(\theta_0, m) = \left(\begin{array}{c}m\cos\theta_0 \\ m\sin\theta_0 \end{array}\right),\ \mathbf{u}(\theta) = \left(\begin{array}{c}\cos\theta \\ \sin\theta \end{array}\right)
$$

## 演習 2.57
<div class="panel-primary">

多変量ガウス分布は，指数型分布族の形式

$$
p(\mathbf{x} \mid \boldsymbol{\eta})=h(\mathbf{x}) g(\boldsymbol{\eta}) \exp \left\{\boldsymbol{\eta}^{\mathbf{T}} \mathbf{u}(\mathbf{x})\right\} \tag{2.194}
$$

に変形できることを示し，$(2.220)–(2.223)$と同様に，$\boldsymbol{\eta}, \mathbf{u}(\mathbf{x}), h(\mathbf{x})$および$g(\boldsymbol{\eta})$の式を導出せよ．

</div>

多変量ガウス分布の式

$$
\begin{aligned}
N(\mathbf{x} \mid \boldsymbol{\mu}, \mathbf{\Sigma})
&=\frac{1}{(2 \pi)^{D / 2}} \frac{1}{|\mathbf{\Sigma}|^{1 / 2}} \exp \left\{-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu}) \mathbf{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})^{\mathrm{T}}\right\} \\
&=\frac{1}{(2 \pi)^{D / 2}} \frac{1}{|\mathbf{\Sigma}|^{1 / 2}} \exp\left\{-\frac{1}{2} \boldsymbol{\mu}^{\mathrm{T}} \mathbf{\Sigma}^{-1} \boldsymbol{\mu}\right\} \exp \left\{-\frac{1}{2} \mathbf{x}^{\mathrm{T}} \mathbf{\Sigma}^{-1} \mathbf{x}+\mathbf{x}^{\mathrm{T}} \mathbf{\Sigma}^{-1} \boldsymbol{\mu}\right\}
\\
&= \frac{1}{(2 \pi)^{D / 2}} \frac{1}{|\mathbf{\Sigma}|^{1 / 2}} \exp\left\{-\frac{1}{2} \boldsymbol{\mu}^{\mathrm{T}} \mathbf{\Sigma}^{-1} \boldsymbol{\mu}\right\} \exp \left\{-\frac{1}{2}\operatorname{Tr}[\mathbf{xx}^{\mathrm{T}}\mathbf{\Sigma}^{-1}] + \boldsymbol{\mu}^{\mathrm{T}}\mathbf{\Sigma}^{-1}\mathbf{x}\right\}
\end{aligned}
$$
からはじめて、指数型分布族の一般形と比較すると、
$$
h(\mathbf{x}) = (2\pi)^{-D/2}, g(\boldsymbol{\eta}) = |\mathbf{\Sigma}|^{-1 / 2}\exp\left\{-\frac{1}{2} \boldsymbol{\mu}^{\mathrm{T}} \mathbf{\Sigma}^{-1} \boldsymbol{\mu}\right\}
$$
となる。（$g(\boldsymbol{\eta})$が$\boldsymbol{\eta}$の関数になっていないことについては後述。）

指数部分について$\boldsymbol{\eta}(\boldsymbol{\mu}, \mathbf{\Sigma})$と$\mathbf{u}(\mathbf{x})$の形に分離できるようにすることを考える。

まず$\boldsymbol{\mu}^{\mathrm{T}}\mathbf{\Sigma}^{-1}\mathbf{x}$を作るため、

$$
\boldsymbol{\eta}(\mu, \mathbf{\Sigma})^{\mathrm{T}} =
\begin{pmatrix}
\mathbf{A} \\
\mathbf{\Sigma}^{-1}\boldsymbol{\mu}
\end{pmatrix}^{\mathrm{T}},\ \mathbf{u}(\mathbf{x}) =
\begin{pmatrix}
\mathbf{B} \\
\mathbf{x}
\end{pmatrix}
$$
とすれば（**区分行列**（または**分割行列、ブロック行列**とも）$\mathbf{A}, \mathbf{B}$の上下の位置は逆でもよい）、$\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u} = \mathbf{A}^{\mathrm{T}}\mathbf{B}+\boldsymbol{\mu}^{\mathrm{T}}\mathbf{\Sigma}^{-1}\mathbf{x}$となるので、$\exp$の第2項ができる（$\because \mathbf{\Sigma}^{-1} = (\mathbf{\Sigma}^{-1})^{\mathrm{T}}$）。

問題は$\mathbf{A}^{\mathrm{T}}\mathbf{B} = \operatorname{Tr}[\mathbf{xx}^{\mathrm{T}}\mathbf{\Sigma}^{-1}]$となるような区分行列$\mathbf{A}, \mathbf{B}$を求めることである。

ここで$\mathbf{xx}^{\mathrm{T}} = \mathbf{M}$とおくと

$$
\begin{aligned}
\operatorname{Tr}[\mathbf{xx}^{\mathrm{T}}\mathbf{\Sigma}^{-1}] &= \sum_{j=1}^{D}\mathbf{M}_j\mathbf{\Sigma}^{-1}_j \\
&= \begin{pmatrix}\mathbf{m}_{1}^{\mathrm{T}} \mathbf{m}_{2}^{\mathrm{T}}  \ldots \mathbf{m}_{n}^{\mathrm{T}}\end{pmatrix} \begin{pmatrix}\boldsymbol{\sigma}_{1}^{-1} \\ \boldsymbol{\sigma}_{2}^{-1} \\ \vdots \\ \boldsymbol{\sigma}_{n}^{-1}\end{pmatrix} \\
&= \begin{pmatrix}\mathbf{m}_{1} \\ \mathbf{m}_{2} \\ \vdots \\ \mathbf{m}_{n}\end{pmatrix}^{\mathrm{T}}\begin{pmatrix}\boldsymbol{\sigma}_{1}^{-1} \\ \boldsymbol{\sigma}_{2}^{-1} \\ \vdots \\ \boldsymbol{\sigma}_{n}^{-1}\end{pmatrix} \\
&= (\operatorname{vec}(\mathbf{M}))^{\mathrm{T}}(\operatorname{vec}(\mathbf{\mathbf{\Sigma}^{-1}})) \\
&= (\operatorname{vec}(\mathbf{xx}^{\mathrm{T}}))^{\mathrm{T}}(\operatorname{vec}(\mathbf{\mathbf{\Sigma}^{-1}}))
\end{aligned}
$$

ここで$\operatorname{vec}(\mathbf{A})$は任意の$m\times n$行列$\mathbf{A}$について要素$\mathbf{A} = \{ a_{ij} \}$を$mn$次元列ベクトルに再配列したものである（※**vec作用素**と呼ばれる。統計のための行列代数下巻 16.2と定理16.2.2を参照。）

> たとえば， $m = 2$, $n = 3$ の行列$\mathbf{A}$にvec作用素を適用すると，
> $$
> \operatorname{vec}(\mathbf{A}) = \begin{pmatrix} \mathbf{a}_{1} \\ \mathbf{a}_{2} \\ \vdots \\ \mathbf{a}_{n} \end{pmatrix}=\begin{pmatrix}a_{11} \\ a_{21} \\ a_{12} \\ a_{22} \\ a_{13} \\ a_{23}\end{pmatrix}
> $$
> である

これを用いると、求める$\boldsymbol{\eta}(\boldsymbol{\mu}, \mathbf{\Sigma}), \mathbf{u}(\mathbf{x})$は

$$
\boldsymbol{\eta}(\boldsymbol{\mu}, \mathbf{\Sigma}) =
\begin{pmatrix}
\operatorname{vec}(\mathbf{\Sigma}^{-1}) \\
\mathbf{\Sigma}^{-1}\boldsymbol{\mu}
\end{pmatrix},\ \mathbf{u}(\mathbf{x}) =
\begin{pmatrix}
-\frac{1}{2}\operatorname{vec}(\mathbf{xx}^{\mathrm{T}}) \\
\mathbf{x}
\end{pmatrix}
$$

となる。

（$g(\boldsymbol{\eta})$が$\boldsymbol{\eta}$についての式になっていないけれど大丈夫か？という疑問が残るが、vecを作用させる前の$\mathbf{\Sigma}^{-1}$を$\eta_1$,$\mathbf{\Sigma}^{-1}\boldsymbol{\mu}$を$\eta_2$とすれば, $\eta_1, \eta_2$の関数として$g(\boldsymbol{\eta})$を表現することは可能なのでセーフという理屈らしい……）

## 演習 2.58
<div class="panel-primary">

$$
-\nabla \ln g(\boldsymbol{\eta})=\mathbb{E}[\mathbf{u}(\mathbf{x})] \tag{2.226}
$$

は，指数型分布族では$\ln g(\boldsymbol{\eta})$の負の勾配が，$\mathbf{u}(\mathbf{x})$の期待値になることを示している．

$$
g(\boldsymbol{\eta}) \int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}} \mathbf{u}(\mathbf{x})\right\} \mathrm{d} \mathbf{x}=1 \tag{2.195}
$$

の2階微分を取ることで

$$
-\nabla \nabla \ln g(\boldsymbol{\eta})=\mathbb{E}\left[\mathbf{u}(\mathbf{x}) \mathbf{u}(\mathbf{x})^{\mathrm{T}}\right]-\mathbb{E}[\mathbf{u}(\mathbf{x})] \mathbb{E}\left[\mathbf{u}(\mathbf{x})^{\mathrm{T}}\right]=\operatorname{cov}[\mathbf{u}(\mathbf{x})] \tag{2.300}
$$

を示せ．

</div>

※ 先に**スカラーについてのベクトルでの微分**、**ベクトルについてのベクトルでの微分**のやり方を知っておく必要がある。
$g(\boldsymbol{\eta}) \int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})\right\}\mathrm{d}\mathbf{x} = 1$なので$g(\boldsymbol{\eta}) \int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})\right\}\mathbf{u}(\mathbf{x})$はスカラーである。一方で$\mathbf{u}(\mathbf{x})$は列ベクトルである。$\boldsymbol{\eta}$でそれぞれを微分する場合、得られる結果はそれぞれ列ベクトルと行列になることに注意する。
スカラーをベクトルで微分する場合は
$$
\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}=
\begin{pmatrix}
\frac{\partial f}{\partial x_{1}} \\ \vdots \\ \frac{\partial f}{\partial x_{D}}
\end{pmatrix}
$$
これは便宜的に以下のように考えることができる。
$$
\frac{\partial}{\partial \mathbf{x}} f(\mathbf{x})=
\begin{pmatrix}
\frac{\partial}{\partial x_{1}} \\ \vdots \\ \frac{\partial}{\partial x_{D}}
\end{pmatrix} f(\mathbf{x})
$$

これより、

$$
\begin{aligned}
\frac{\partial}{\partial \boldsymbol{\eta}}\underbrace{\exp (\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x}))}_{\textrm{scalar}}
&= \begin{pmatrix}
\frac{\partial}{\partial \eta_{1}} \\ \vdots \\ \frac{\partial}{\partial \eta_{D}}
\end{pmatrix} \exp \left( \sum_{i=1}^{D}\eta_{i}u_i(\mathbf{x}) \right) \\
&= \begin{pmatrix}
\exp \left( \sum_{i=1}^{D}\eta_{i}u_i(\mathbf{x}) \right) u_1(\mathbf{x}) \\ \vdots \\ \exp \left( \sum_{i=1}^{D}\eta_{i}u_i(\mathbf{x}) \right) u_D(\mathbf{x})
\end{pmatrix} \\
&= \exp (\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})) \mathbf{u}(\mathbf{x})
\end{aligned}
$$
となる。また、ベクトルをベクトルで微分する場合は、教科書によって微分する変数側を行ベクトルとするか、微分される関数側を行ベクトルとするか2通りの表現があるが、ここでは変数側を行ベクトルとする。微分される関数を$\mathbf{f}(\mathbf{x})$とすると
$$
\frac{\partial}{\partial \mathbf{x}} \mathbf{f}(\mathbf{x})=
\begin{pmatrix}
\frac{\partial f_1}{\partial x_{1}} & \cdots &\frac{\partial f_1}{\partial x_{D}} \\ \vdots & & \vdots  \\ \frac{\partial f_D}{\partial x_1} & \ldots & \frac{\partial f_D}{\partial x_D}
\end{pmatrix}
$$
これは便宜的に以下のように考えることができる。
$$
\frac{\partial}{\partial \mathbf{x}} \mathbf{f}(\mathbf{x})=
\begin{pmatrix}
\frac{\partial}{\partial x_{1}} \\ \vdots \\ \frac{\partial}{\partial x_{D}}
\end{pmatrix}
\begin{pmatrix}
f_1(\mathbf{x}) & \ldots & f_D(\mathbf{x})
\end{pmatrix}
$$
これより
$$
\begin{aligned}
\frac{\partial}{\partial \boldsymbol{\eta}}\underbrace{\exp (\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x}))\mathbf{u}(\mathbf{x})}_{\textrm{vector}}
&= \begin{pmatrix}
\frac{\partial}{\partial \eta_{1}} \\ \vdots \\ \frac{\partial}{\partial \eta_{D}}
\end{pmatrix}
\begin{pmatrix}
\exp (\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})) u_1(\mathbf{x}) & \ldots & \exp (\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})) u_D(\mathbf{x})
\end{pmatrix} \\
&= \begin{pmatrix}
\exp (\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})) u_1(\mathbf{x}) u_1(\mathbf{x}) & \ldots & \exp (\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})) u_D(\mathbf{x}) u_1(\mathbf{x})
\\ \vdots & \ddots & \vdots \\
\exp (\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})) u_1(\mathbf{x}) u_D(\mathbf{x}) & \ldots & \exp (\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})) u_D(\mathbf{x}) u_D(\mathbf{x})
\end{pmatrix} \\
&= \exp (\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})) \mathbf{u}(\mathbf{x}) \mathbf{u}(\mathbf{x})^{\mathrm{T}}
\end{aligned}
$$
となる。

※ PRML P.110の$(2.194), (2.195)$を用いて$(2.224)-(2.226)$までの式変形をまず検証する。

$(2.195)$の両辺を$\boldsymbol{\eta}$で微分すると

$$
\begin{aligned}
\nabla g(\boldsymbol{\eta}) \int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})\right\} \mathrm{d}\mathbf{x}
&+g(\boldsymbol{\eta}) \int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})\right\}\mathbf{u}(\mathbf{x}) \mathrm{d}\mathbf{x} = 0 \\
\nabla g(\boldsymbol{\eta}) \int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})\right\} \mathrm{d}\mathbf{x} &=
-g(\boldsymbol{\eta}) \int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})\right\}\mathbf{u}(\mathbf{x}) \mathrm{d}\mathbf{x} \\
-\frac{\nabla g(\boldsymbol{\eta})}{g(\boldsymbol{\eta})} &= \frac{\int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})\right\}\mathbf{u}(\mathbf{x}) \mathrm{d}\mathbf{x}}{\int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})\right\}\mathrm{d}\mathbf{x}}
\end{aligned}
$$

ここで再度$(2.195)$式を使うと

$$
-\frac{\nabla g(\boldsymbol{\eta})}{g(\boldsymbol{\eta})} = g(\boldsymbol{\eta})\int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}}\mathbf{u}(\mathbf{x})\right\}\mathbf{u}(\mathbf{x}) \mathrm{d}\mathbf{x} = \mathbb{E}[\mathbf{u}(\mathbf{x})]
$$

これより$(2.226)$式の$-\nabla \ln g(\boldsymbol{\eta}) = \mathbb{E}[\mathbf{u}(\mathbf{x})]$が得られる。

続いて2階微分を行うと

$$
\begin{aligned}
-\nabla \nabla \ln g(\boldsymbol{\eta}) &=\nabla g(\boldsymbol{\eta}) \int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}} \mathbf{u}(\mathbf{x})\right\} \mathbf{u}(\mathbf{x})^{\mathrm{T}} \mathrm{d}\mathbf{x} \\
&+g(\boldsymbol{\eta}) \int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}} \mathbf{u}(\mathbf{x})\right\} \mathbf{u}(\mathbf{x}) \mathbf{u}(\mathbf{x})^{\mathrm{T}} \mathrm{d}\mathbf{x} \\
&=-\mathbb{E}[\mathbf{u}(\mathbf{x})] g(\boldsymbol{\eta}) \int h(\mathbf{x}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}} \mathbf{u}(\mathbf{x})\right\} \mathbf{u}(\mathbf{x})^{\mathrm{T}} \mathrm{d}\mathbf{x} \\
&+\mathbb{E}\left[\mathbf{u}(\mathbf{x}) \mathbf{u}(\mathbf{x})^{\mathrm{T}}\right] \\ &=\mathbb{E}\left[\mathbf{u}(\mathbf{x}) \mathbf{u}(\mathbf{x})^{\mathrm{T}}\right]-\mathbb{E}[\mathbf{u}(\mathbf{x})]\mathbb{E}\left[\mathbf{u}(\mathbf{x})^{\mathrm{T}}\right] \\
&=\operatorname{cov}[\mathbf{u}(\mathbf{x})]
\end{aligned}
$$

となり、共分散が求まる。

## 演習 2.59
<div class="panel-primary">

$f(x)$が正規化されていれば，密度

$$
p(x|\sigma) = \frac{1}{\sigma}f\left( \frac{x}{\sigma} \right) \tag{2.236}
$$

も正規化されていることを，$y=x/\sigma$と変数を変換することで示せ．

</div>

$\displaystyle \int f(x) dx = 1$が成立するときに$\displaystyle \int p(x | \sigma) dx = 1$であることを示せば良い。

$y=x/\sigma$とすると、$dy = \frac{1}{\sigma} dx$なので

$$
\int p(x|\sigma) dx = \int \sigma \cdot \frac{1}{\sigma}f(y) dy = \int f(y) dy = 1 \hspace{1em} \left( \because \int f(x)dx = 1\right)
$$

したがって$p(x|\sigma)$が正規化されていることが示された。

## 演習 2.60
<div class="panel-primary">

空間$\mathbf{x}$がいくつかの固定された領域に分割されているとする．このとき，$i$番目の領域中での密度$p(\mathbf{x})$は一定の値$h_i$であり，領域$i$の体積が$\Delta_i$であるような，ヒストグラム型の密度モデルを考える．$N$個の$\mathbf{x}$の観測値集合があり，領域$i$に入る観測値が、$n_i$個であるとする．このとき，密度の正規化制約条件をラグランジュ乗数法によって実現し，$\{ h_i \}$の最尤推定量の式を導出せよ．

</div>

※ ノンパラメトリック法に関連した問題だが、手法として最尤推定を使うので、2.2 多値変数の手法を見直しながらラグランジュ未定乗数法で対数尤度関数の最大化を目指し、$\{ h_i \}$の最尤推定量を求めていく。しかし、その上で観測データ点$\mathbf{x}_n$が領域$j$にあることを示す変数$j(n)$を使うというのは発想として難しいと思われる。

観測データ点$\mathbf{x}_n$が領域$j$にあることを示す変数$j(n)$を定義すると、点$\mathbf{x}_n$での密度$p(\mathbf{x})$の値は$h_{j(n)}$で与えられることになる。これを用いると、観測データセット$\mathbf{X} = \{ \mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\}$が発生する尤度関数は

$$
\prod_{n=1}^{N}p(\mathbf{x}_n) = \prod_{n=1}^{N}h_{j(n)}
$$

と表せる。すると、この対数尤度関数は

$$
\ln \prod_{n=1}^{N}h_{j(n)} = \sum_{n=1}^{N}\ln h_{j(n)}
$$

となる。

$\{h_i\}$の最尤推定解を求めるには、制約条件として$\displaystyle \sum_{i=1}^{N} h_i \Delta_i = 1$となることを考慮しつつ、$h_i$についての対数尤度関数$\displaystyle \sum_{n=1}^{N}\ln h_{j(n)}$を最大化する必要がある。すなわちラグランジュ乗数$\lambda$を使って

$$
L = \sum_{n=1}^{N}\ln h_{j(n)} + \lambda\left( \sum_{i=1}^{N} h_i \Delta_i - 1 \right)
$$

を最大化する。$h_i$についての導関数を0とおくと

$$
\frac{\partial L}{\partial h_i} = \frac{\partial}{\partial h_i}\sum_{n=1}^{N}\ln h_{j(n)}+\lambda \Delta_i = 0
$$

ここで$\displaystyle \frac{\partial}{\partial h_i}\sum_{n=1}^{N}\ln h_{j(n)}$について、$j(n)=i$となるような観測値は問題文の設定から$n_i$個なので

$$
\frac{\partial}{\partial h_i}\sum_{n=1}^{N}\ln h_{j(n)} = n_i \cdot \frac{1}{h_i}
$$

よって$\displaystyle \frac{n_i}{h_i}+\lambda \Delta_i = 0$。変形すると$n_i + \lambda \Delta_i h_i= 0$。

$i$について和を取ると$\sum_i (n_i + \lambda \Delta_i h_i)= N + \lambda = 0$となるので、$\lambda = -N$が求まる。

以上から、$h_i$の最尤推定解の式は

$$
h_i = -\frac{n_i}{\lambda \Delta_i} = \frac{n_i}{N\Delta_i}
$$

となる。

## 演習 2.61
<div class="panel-primary">

$K$近傍密度モデルでは，全空間上での積分が発散する変則分布になることを示せ．

</div>

【解法1】 ざっくりとしたやり方

ある$D$次元ユークリッド空間上での未知の確率密度$p(\mathbf{x})$から観測値の集合が得られていて、この集合から$p(\mathbf{x})$の値を推定したいとする。$(2.246)$までの議論から、K近傍法では密度$p(\mathbf{x})$を推定したい点$\mathbf{x}$を中心とした半径$r$の$D$次元小球の体積$V(r)$中に$K$個のデータ点が存在する時（これは言い換えれば$r$は$N$個の観測値からなるデータセット内で$\mathbf{x}$から見て$K$番目に近い点までの距離$r$をとった時）、密度$p(\mathbf{x})$の推定値が

$$
p(\mathbf{x}) = \frac{K}{NV(r)}
$$

で与えられることになる。

この問題の題意は「全空間上での積分が発散する」ことを示すことなので、$\displaystyle \int p(\mathbf{x})d\mathbf{x} \to \infty$を示せば良い。

ここで、この$p(\mathbf{x})$を極座標中で考えると、もし十分に大きな半径の値$r$をとったとき、上式から$p(\mathbf{x}) \propto r^{-D}$となることがわかる。また、$D$次元直交座標から極座標に変換するときのヤコビアンは（参考：https://wasan.hatenablog.com/entry/20110321/1300733907）

$$
\begin{aligned}
\left|\frac{\partial\left(x_{1}, \cdots, x_{D}\right)}{\partial\left(r, \theta_{1}, \cdots, \theta_{D-1}\right)}\right| &=\left|\frac{\partial\left(x_{1}, \cdots, x_{D}\right)}{\partial\left(x_{1}, \rho, \theta_{2}, \cdots, \theta_{D-1}\right)}\right|\left|\frac{\partial\left(x_{1}, \rho, \theta_{2}, \cdots, \theta_{D-1}\right)}{\partial\left(r, \theta_{1}, \cdots, \theta_{D-1}\right)}\right| \\ &=\left\{\rho^{D-2} \prod_{i=2}^{D-1}\left(\sin \theta_{i}\right)^{D-i-1}\right\} r \\ &=r\left(r \sin \theta_{1}\right)^{D-2} \prod_{i=2}^{D-1}\left(\sin \theta_{i}\right)^{D-i-1} \quad\left(\because \rho=r \sin \theta_{1}\right) \\ &=r^{D-1} \prod_{i=1}^{D-1}\left(\sin \theta_{i}\right)^{D-i-1} \end{aligned}
$$

より、

$$
d\mathbf{x} = d x_{1} \cdots d x_{D}=r^{D-1}\left\{\prod_{i=1}^{D-1}\left(\sin \theta_{i}\right)^{D-i-1}\right\} d r d \theta_{1} \cdots d \theta_{D-1}
$$
となるので、

$$
\int p(\mathbf{x})d \mathbf{x} \propto \int r^{-D}d\mathbf{x} \propto \int r^{-D}r^{D-1} dr d \theta_{1} \cdots d \theta_{D-1} \propto \int r^{-1}dr = \ln r
$$

これは$r\to \infty$の無限大で$\ln r \to \infty$ となるため全空間上での積分は発散することが示された。すなわち、$K$近傍密度モデルは変則分布であることが示された。

【解法2】より厳密な解き方

https://qiita.com/r-takahama/items/cc03cffd49ad4732ebd3 に書かれてあります。