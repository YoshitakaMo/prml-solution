# PRML第10章演習問題解答 (10.18まで)

<head>
<style>
  div.panel-primary {
	border: 1px solid #000;
    margin: 10px 5px;
    padding: 16px 10px 0px;
  }
</style>
</head>

## 演習 10.1

<div class="panel-primary">

観測データの対数周辺尤度$\ln p(\mathbf{X})$は

$$\ln p(\mathbf{X})=\mathcal{L}(q)+\mathrm{KL}(q \| p) \tag{10.2}$$

のように二つの項に分解できることを確かめよ．ここで，$\mathcal{L}(q)$, $\mathrm{KL}(q \| p)$は$(10.3), (10.4)$

$$
\mathcal{L}(q) = \int q(\mathbf{Z}) \ln \left\{\frac{p(\mathbf{X}, \mathbf{Z})}{q(\mathbf{Z})}\right\} \mathrm{d} \mathbf{Z} \tag{10.3}
$$

$$
\mathrm{KL}(q \| p) =-\int q(\mathbf{Z}) \ln \left\{\frac{p(\mathbf{Z} \mid \mathbf{X})}{q(\mathbf{Z})}\right\} \mathrm{d} \mathbf{Z} \tag{10.4}
$$

で与えられる．

</div>

$(10.3)$と$(10.4)$を足すと

$$
\begin{aligned}
\mathcal{L}(q)+\mathrm{KL}(q \| p)
&=\int q(\mathbf{Z})\left[\ln \frac{p(\mathbf{X}, \mathbf{Z})}{q(\mathbf{Z})}-\ln \frac{p(\mathbf{Z} \mid \mathbf{X})}{q(\mathbf{Z})}\right] d \mathbf{Z} \\
&=\int q(\mathbf{Z})[\ln p(\mathbf{X}, \mathbf{Z})-\ln p(\mathbf{Z} \mid \mathbf{X})] d \mathbf{Z} \\
&=\int q(\mathbf{Z})[\ln p(\mathbf{X}, \mathbf{Z})-\ln p(\mathbf{X}, \mathbf{Z})+\ln p(\mathbf{X})] d\mathbf{Z} \\
&=\ln p(\mathbf{X})\int q(\mathbf{Z})d \mathbf{Z} \\
&=\ln p(\mathbf{X})
\end{aligned}
$$

よって$(10.2)$式が示された。

## 演習 10.2

<div class="panel-primary">

$\mathbb{E}\left[z_{1}\right]=m_{1}$および$\mathbb{E}\left[z_{2}\right]=m_{2}$を用いて連立方程式

$$
\begin{aligned}
m_{1}&=\mu_{1}-\Lambda_{11}^{-1} \Lambda_{12}\left(\mathbb{E}\left[z_{2}\right]-\mu_{2}\right) \quad (10.13) \\ m_{2}&=\mu_{2}-\Lambda_{22}^{-1} \Lambda_{21}\left(\mathbb{E}\left[z_{1}\right]-\mu_{1}\right) \quad (10.15)
\end{aligned}
$$

を解き，もともとの分布$p(\mathbf{z})$が非特異ならば，近似された因子分布の平均についての一意な解は$\mathbb{E}\left[z_{1}\right]=\mu_{1}$および$\mathbb{E}\left[z_{2}\right]=\mu_{2}$となることを示せ．

</div>

(10.13)式と(10.15)式に、$\mathbb{E}\left[z_{1}\right]=m_{1}$と$\mathbb{E}\left[z_{2}\right]=m_{2}$を代入して、

$$
\begin{aligned}
m_{1}&=\mu_{1}-\Lambda_{11}^{-1} \Lambda_{12}\left(m_2-\mu_{2}\right)\\
m_{2}&=\mu_{2}-\Lambda_{22}^{-1} \Lambda_{21}\left(m_1-\mu_{1}\right)
\end{aligned}
$$

これを行列の形で表すと、

$$
\begin{aligned}
\left[\begin{array}{cc}
1 & \Lambda _{11}^{-1}\Lambda_{12} \\
\Lambda_{22}^{-1}\Lambda_{21} & 1
\end{array}\right]
\left[\begin{array}{rr}
m_1 - \mu_1 \\
m_2- \mu_2
\end{array}\right]
=\left[\begin{array}{rr}
0 \\
0
\end{array}\right]
\end{aligned}
$$

一番左の$2 \times 2$行列には逆行列が存在する(*)ので、左から逆行列をかけて$m_1=\mu_1, m_2=\mu_2$を得る。

(*) 一番左の行列に逆行列が存在しないと仮定すると、行列式が0、つまり

$$
\begin{aligned}
&1-\Lambda _{11}^{-1}\Lambda_{12}
\Lambda_{22}^{-1}\Lambda_{21} =0\\
\Leftrightarrow & \Lambda _{11}\Lambda_{22}-
\Lambda_{12}\Lambda_{21} =0\\
\Leftrightarrow & \det \mathbf \Lambda =0
\end{aligned}
$$

となってしまい、元の分布$p(\mathbf{z})$が特異であることを意味する。（精度行列の逆行列が存在しない、すなわち共分散行列が定義できない。）

## 演習 10.3

<div class="panel-primary">

$$q(\mathbf{Z})=\prod_{i=1}^{M} q_{i}\left(\mathbf{Z}_{i}\right) \tag{10.5}$$
の形の分解された変分分布$q(\mathbf{Z})$を考えよう．ラグランジュ乗数法を用いて，カルバック-ライブラーダイバージェンス$\textrm{KL}(p \| q)$を因子の一つ$q_i(\mathbf{Z}_i)$について他の因子を固定して最小化すると，解
$$q_{j}^{\star}\left(\mathbf{Z}_{j}\right)=\int p(\mathbf{Z}) \prod_{i \neq j} \mathrm{~d} \mathbf{Z}_{i}=p\left(\mathbf{Z}_{j}\right) \tag{10.17}$$
が得られることを確かめよ．

</div>

※
(10.16)式からKLダイバージェンスは

$$
\begin{aligned}
KL(p \parallel q) &= -\int p(\mathbf{Z})\left[\sum^M_{i=1}\ln q_i(\mathbf{Z}_i)\right]d\mathbf{Z}+const\\
&=-\int p(\mathbf{Z})\left[\ln q_j(\mathbf{Z}_j)+\sum^M_{i\neq j}\ln q_i(\mathbf{Z}_i)\right]d\mathbf{Z}+const\\
&=-\int p(\mathbf{Z})\ln q_j(\mathbf{Z}_j)d\mathbf{Z}+const\\
&=-\int\left[\int p(\mathbf{Z})\prod_{i\neq j}d\mathbf{Z}_i\right]\ln q_j(\mathbf{Z}_j)d\mathbf{Z}_j+const\\
&=-\int p(\mathbf{Z}_j)\ln q_j(\mathbf{Z}_j)d\mathbf{Z}_j+const
\end{aligned}
$$

と計算できる．ここでconstの項は同一の項にはなっていないことに留意．2行目から3行目への式変形では$q_j$に依存しない積分をconstに押し込んだ．最後の式変形では$\mathbf{Z}$の積分を各$\mathbf{Z}$の添字($1\dots i\dots j \dots M$)についてバラして添字$j$以外の積分の順序を入れ替え，$p(\mathbf{Z})$において$j$以外の添字で積分周辺化したため$p(\mathbf{Z}_j)$のみが残っている．

$q_j(\mathbf{Z}_j)$が正規化されているという条件を利用してラグランジュ乗数$\lambda$を導入して，ラグランジュ未定乗数法によりKLダイバージェンスの最小化は以下の式の最小化に書き換えることができて

$$
L = -\int p(\mathbf{Z}_j)\ln q_j(\mathbf{Z}_j)d\mathbf{Z}_j+\lambda\left(\int q_j(\mathbf{Z}_j)d\mathbf{Z}_j-1\right)
$$

を最小化すれば良いことがわかる．ここで元のKLダイバージェンスの式にあった定数項は$\mathbf{Z}_j$に依存しない項なので最小化に影響はなく無視した．

これを積分汎関数の形に変形して変分法を用いて解けるようにしたい．
$\mathbf{Z}_j$に依存しない項を積分に含めるために$\delta$関数を用いて$L$は
以下のように書き直すことができる

$$
L=\int\left\{-p(\mathbf{Z}_j)\ln q_j(\mathbf{Z}_j)+\lambda q_j(\mathbf{Z}_j)-\lambda\delta(\mathbf{Z}_j)\right\}d\mathbf{Z}_j
$$

被積分関数を

$$
G(p,q;\delta)=-p(\mathbf{Z}_j)\ln q_j(\mathbf{Z}_j)+\lambda q_j(\mathbf{Z}_j)-\lambda\delta(\mathbf{Z}_j)
$$

とおくと$L$を最小化する$q_j^*$はオイラー・ラグランジュ方程式から

$$
\frac{\partial G}{\partial q}=0
$$

$$
-\frac{p(\mathbf{Z}_j)}{q_j(\mathbf{Z}_j)} + \lambda = 0
$$

$\mathbf{Z}_j$について積分して

$$
\lambda=1
$$

よって

$$
q_j^*=p(\mathbf{Z}_j)=\int p(\mathbf{Z})\prod_{i\neq j}d\mathbf{Z}_i
$$

が得られる．

### 変分法について補足

蛇足かもしれないけど変分法についてちょっと勉強したので補足．上巻の付録Dに変分法の説明が書いてあるけど被積分関数として関数一つとその一回導関数を含む場合についての説明だった．一般化した場合変分問題の解法であるオイラー・ラグランジュ方程式がどのような形になるか調べた．

高階導関数を含む(被積分関数が$G(y,y',y'',...,y^{(m)}, x)$と書ける)場合は

$$
\frac{\partial G}{\partial y}-\frac{d}{dx}\frac{\partial G}{\partial y'}+\frac{d^2}{dx^2}\frac{\partial G}{\partial y''}+...+(-1)^{(m)}\frac{d^m}{dx^m}\frac{\partial G}{\partial y^{(m)}}=0
$$

複数の関数を含む(被積分関数が$G(y,y',z, z',x)$と書ける)場合には

$$
\frac{\partial G}{\partial y}-\frac{d}{dx}\frac{\partial G}{\partial y'}=0
$$
$$
\frac{\partial G}{\partial z}-\frac{d}{dx}\frac{\partial G}{\partial z'}=0
$$

のように書けるらしい．今回の場合，最小化したい積分汎関数は同関数を含まず，複数の関数を含む形になっていたため単に注目する関数の偏微分を考えるだけでよかった（という理解であってますか...）

## 演習 10.4
<div class="panel-primary">

ある固定された分布$p(\mathbf{x})$をガウス分布$q(\mathbf{x}) = \mathcal{N}(\mathbf{x}\mid \boldsymbol{\mu}, \mathbf{\Sigma})$を用いて近似したいとしよう．KLダイバージェンス$\textrm{KL}(p \| q)$をガウス分布$q(\mathbf{x})$に関して書き下して微分することにより，$\textrm{KL}(p \| q)$を$\boldsymbol{\mu}$および$\mathbf{\Sigma}$について最小化すると，結果として$\boldsymbol{\mu}$は$p(\mathbf{x})$の下での$\mathbf{x}$の期待値になり，$\mathbf{\Sigma}$はその共分散になることを示せ．

</div>

$$
\begin{aligned}
\mathrm{KL}(p \| q) &=-\int p(\mathbf{x}) \ln \left\{\frac{q(\mathbf{x})}{p(\mathbf{x})}\right\} d \mathbf{x} \\
&=-\int p(\mathbf{x}) \ln q(\mathbf{x}) d \mathbf{x}+\text { const } \\
&=-\int p(\mathbf{x})\left[-\frac{D}{2} \ln 2 \pi-\frac{1}{2} \ln |\boldsymbol{\Sigma}|-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^{T} \boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right] d \mathbf{x}+\text { const } \\
&=\int p(\mathbf{x})\left[\frac{1}{2} \ln |\boldsymbol{\Sigma}|+\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^{T} \boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right] d \mathbf{x}+\text { const } \\
&=\frac{1}{2} \ln |\boldsymbol{\Sigma}|+\int p(\mathbf{x})\left[\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^{T} \boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right] d \mathbf{x}+\text { const } \\
&=\frac{1}{2} \ln |\boldsymbol{\Sigma}|+\int p(\mathbf{x}) \frac{1}{2}\left[\mathbf{x}^{T} \boldsymbol{\Sigma}^{-1} \mathbf{x}-2 \boldsymbol{\mu}^{T} \boldsymbol{\Sigma}^{-1} \mathbf{x}+\boldsymbol{\mu}^{T} \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}\right] d \mathbf{x}+\text { const } \\
&=\frac{1}{2} \ln |\boldsymbol{\Sigma}|+\frac{1}{2} \int p(\mathbf{x}) \operatorname{Tr}\left[\boldsymbol{\Sigma}^{-1}\left(\mathbf{x} \mathbf{x}^{T}\right)\right] d \mathbf{x}-\boldsymbol{\mu}^{T} \boldsymbol{\Sigma}^{-1} \mathbb{E}[\mathbf{x}]+\frac{1}{2} \boldsymbol{\mu}^{T} \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}+\text { const } \\
&=\frac{1}{2} \ln |\boldsymbol{\Sigma}|+\frac{1}{2} \operatorname{Tr}\left[\boldsymbol{\Sigma}^{-1} \mathbb{E}\left(\mathbf{x} \mathbf{x}^{T}\right)\right]-\boldsymbol{\mu}^{T} \boldsymbol{\Sigma}^{-1} \mathbb{E}[\mathbf{x}]+\frac{1}{2} \boldsymbol{\mu}^{T} \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}+\text { const }
\end{aligned}
$$
 $D$ : $\mathbf{x}$の次元.
 $\mathrm{KL}(p \| q)$ を $\boldsymbol{\mu}$ について微分:
$$
\frac{\partial \mathrm{KL}}{\partial \boldsymbol{\mu}}=-\Sigma^{-1} \mathbb{E}[x]+\Sigma^{-1} \mu=0
$$
よって
$\boldsymbol{\mu}=\mathbb{E}[\mathbf{x}]$.  $\boldsymbol{\mu}=\mathbb{E}[\mathbf{x}]$ のとき, KL divergenceは:
$$
\mathrm{KL}(p \| q)=\frac{1}{2} \ln |\boldsymbol{\Sigma}|+\frac{1}{2} \operatorname{Tr}\left[\boldsymbol{\Sigma}^{-1} \mathbb{E}\left(\mathbf{x} \mathbf{x}^{T}\right)\right]-\frac{1}{2} \boldsymbol{\mu}^{T} \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}+\text { const }
$$
この$\mathrm{KL}(p \| q)$ を $\Sigma$ について微分すると:
$$
\frac{\partial \mathrm{KL}}{\partial \Sigma}=\frac{1}{2} \Sigma^{-1}-\frac{1}{2} \Sigma^{-1} \mathbb{E}\left[\mathbf{x} \mathbf{x}^{T}\right] \Sigma^{-1}+\frac{1}{2} \Sigma^{-1} \mu \mu^{T} \Sigma^{-1}=0
$$
'MatrixCookBook'内の$\mathrm{Eq}(61)$ と $\mathrm{Eq}(124)$ ,を用いた. $\Sigma, \mathbb{E}\left[\mathbf{x x}^{T}\right]$ は対象行列:
$\frac{\partial \mathbf{a}^{T} \mathbf{X}^{-1} \mathbf{b}}{\partial \mathbf{X}}=-\mathbf{X}^{-T} \mathbf{a b}^{T} \mathbf{X}^{-T} \quad$ and $\quad \frac{\partial \operatorname{Tr}\left(\mathbf{A} \mathbf{X}^{-1} \mathbf{B}\right)}{\partial \mathbf{X}}=-\mathbf{X}^{-T} \mathbf{A}^{T} \mathbf{B}^{T} \mathbf{X}^{-T}$
整理すると:
$$
\Sigma=\mathbb{E}\left[\mathbf{x x}^{T}\right]-\boldsymbol{\mu} \boldsymbol{\mu}^{T}=\mathbb{E}\left[\mathbf{x} \mathbf{x}^{T}\right]-\mathbb{E}[\mathbf{x}] \mathbb{E}[\mathbf{x}]^{T}=\operatorname{cov}[\mathbf{x}]
$$



## 演習 10.5
<div class="panel-primary">

すべての隠れ確率変数の集合$\mathbf{Z}$が，潜在変数$\mathbf{z}$とモデルパラメータ$\boldsymbol{\theta}$に分けられるようなモデルを考える．この変分分布を潜在変数とパラメータに$q(\mathbf{z}, \boldsymbol{\theta}) = q_{\mathbf{z}}(\mathbf{z}) q_{\theta}(\boldsymbol{\theta})$のように分解し，分布$q_{\theta}(\boldsymbol{\theta})$を$q_{\theta}(\boldsymbol{\theta}) = \delta(\boldsymbol{\theta} - \boldsymbol{\theta}_0)$の形の点推定で近似することを考える．ここで，$\boldsymbol{\theta}_0$は自由パラメータのベクトルである．このとき，この分解された分布を変分ベイズ法により最適化することは， Eステップで$q_{\mathbf{z}}(\mathbf{z})$を最適化し， Mステップで$\boldsymbol{\theta}$の完全データの対数事後分布の期待値を$\boldsymbol{\theta}_0$について最大化するEMアルゴリズムと等価になることを示せ．

</div>

変分ベイズの点推定がEMアルゴリズムに相当することを確かめる問題。
10.1節で述べられている通り、EMアルゴリズムと変分推論の違いの一つは、Zにθを含めないか、含めるかである。今回はZとθを分離して考えているためEMアルゴリズムの枠組みで考えられる。変分ベイズ法では、Pをよく表すようなqをKLダイバージェンス基準で求める。つまり（10.2）において、KLダイバージェンスの項を最小化することに相当する（Eステップ）
（つまり変分ベイズはEEアルゴリズムのように捉えることもできる）

実際に計算をする。θを固定して

$$
\begin{aligned}
\mathrm{KL}(q \| p) &=-\iint q(\mathbf{Z}) \ln \left\{\frac{p(\mathbf{Z} \mid \mathbf{X})}{q(\mathbf{Z})}\right\} d \mathbf{Z} \\
&=-\iint q_{\mathbf{z}}(\mathbf{z}) q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln \left\{\frac{p(\mathbf{z}, \boldsymbol{\theta} \mid \mathbf{X})}{q_{\mathbf{z}}(\mathbf{z}) q_{\boldsymbol{\theta}}(\boldsymbol{\theta})}\right\} d \mathbf{z} d \boldsymbol{\theta} \\
&=-\iint q_{\mathbf{z}}(\mathbf{z}) q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln \left\{\frac{p(\mathbf{z}, \boldsymbol{\theta} \mid \mathbf{X})}{q_{\mathbf{z}}(\mathbf{z})}\right\} d \mathbf{z} d \boldsymbol{\theta}+\int q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) d \boldsymbol{\theta} \\
&=-\iint q_{\mathbf{z}}(\mathbf{z}) q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln \left\{\frac{p(\mathbf{z}, \boldsymbol{\theta} \mid \mathbf{X})}{q_{\mathbf{z}}(\mathbf{z})}\right\} d \mathbf{z} d \boldsymbol{\theta}+\text { const } \\
&=-\int q_{\boldsymbol{\theta}}(\boldsymbol{\theta})\left\{\int q_{\mathbf{z}}(\mathbf{z}) \ln \left\{\frac{p(\mathbf{z}, \boldsymbol{\theta} \mid \mathbf{X})}{q_{\mathbf{z}}(\mathbf{z})}\right\} d \mathbf{z}\right\} d \boldsymbol{\theta}+\text { const } \\
&=-\int q_{\mathbf{z}}(\mathbf{z}) \ln \left\{\frac{p\left(\mathbf{z}, \boldsymbol{\theta}_{0} \mid \mathbf{X}\right)}{q_{\mathbf{z}}(\mathbf{z})}\right\} d \mathbf{z}+\text { const } \\
&=-\int q_{\mathbf{z}}(\mathbf{z}) \ln \left\{\frac{p\left(\mathbf{z} \mid \boldsymbol{\theta}_{0}, \mathbf{X}\right) p\left(\boldsymbol{\theta}_{0} \mid \mathbf{X}\right)}{q_{\mathbf{z}}(\mathbf{z})}\right\} d \mathbf{z}+\text { const } \\
&=-\int q_{\mathbf{z}}(\mathbf{z}) \ln \left\{\frac{p\left(\mathbf{z} \mid \boldsymbol{\theta}_{0}, \mathbf{X}\right)}{q_{\mathbf{z}}(\mathbf{z})}\right\} d \mathbf{z}+\text { const }
\end{aligned}
$$

よって、$\mathrm{KL}(q \| p)$を最小にする$q_{\mathbf{z}}(\mathbf{z})$は$p\left(\mathbf{z} \mid \boldsymbol{\theta}_{0}, \mathbf{X}\right)$が解となる。

続いて最適なθを求める。これは下限$\mathcal{L}(q)$を最大にするようなθを求めることに相当する。

$$
\begin{aligned}
L(q) &=\iint q(\mathbf{Z}) \ln \left\{\frac{p(\mathbf{X}, \mathbf{Z})}{q(\mathbf{Z})}\right\} d \mathbf{Z} \\
&=\iint q_{\mathbf{z}}(\mathbf{z}) q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln \left\{\frac{p(\mathbf{X}, \mathbf{z}, \boldsymbol{\theta})}{q_{\mathbf{z}}(\mathbf{z}) q_{\boldsymbol{\theta}}(\boldsymbol{\theta})}\right\} d \mathbf{z} d \boldsymbol{\theta} \\
&=\iint q_{\mathbf{z}}(\mathbf{z}) q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln \left\{\frac{p(\mathbf{X}, \mathbf{z}, \boldsymbol{\theta})}{q_{\mathbf{z}}(\mathbf{z})}\right\} d \mathbf{z} d \boldsymbol{\theta}-\int q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) d \boldsymbol{\theta} \\
&=\iint q_{\mathbf{z}}(\mathbf{z}) q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln \{p(\mathbf{X}, \mathbf{z}, \boldsymbol{\theta})\} d \mathbf{z} d \boldsymbol{\theta}-\int q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) d \boldsymbol{\theta}+\text { const } \\
&=\int q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \mathbb{E}_{q_{\mathbf{z}}}[\ln p(\mathbf{X}, \mathbf{z}, \boldsymbol{\theta})] d \boldsymbol{\theta}-\int q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) d \boldsymbol{\theta}+\text { const } \\
&=\mathbb{E}_{q_{\mathbf{z}}(\mathbf{z})}\left[\ln p\left(\mathbf{X}, \mathbf{z}, \boldsymbol{\theta}_{0}\right)\right]-\int q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) d \boldsymbol{\theta}+\text { const }
\end{aligned}
$$

$\int q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) \ln q_{\boldsymbol{\theta}}(\boldsymbol{\theta}) d \boldsymbol{\theta}$は−∞になるので無視して良いので、第一項の最大化を考えれば良い。
これは、対数事後分布の期待値を$\boldsymbol{\theta}_{0}$について最大化すれば良い。

## 演習 10.6

<div class="panel-primary">

$\alpha$ダイバージェンスは
$$
\mathrm{D}_{\alpha}(p \| q)=\frac{4}{1-\alpha^{2}}\left(1-\int p(x)^{(1+\alpha) / 2} q(x)^{(1-\alpha) / 2} \mathrm{~d} x\right) \tag{10.19}
$$
で定義される．カルバック-ライブラーダイバージェンス$\textrm{KL}(p \| q)$はこのとき$\alpha \to 1$の場合に対応することを示せ．これには$p^{\epsilon} = \exp (\epsilon \ln p)=1+\epsilon \ln p+O\left(\epsilon^{2}\right)$と書き，$\epsilon \to 0$とすればよい．同様にして，$\textrm{KL}(q \| p)$は$\alpha \to -1$の場合に対応することを示せ．

</div>

$\alpha\rightarrow1$の時は、$p^{\epsilon}=1+\epsilon \ln p+O\left(\epsilon^{2}\right)$を利用すべく、以下のように式変形する。

$$
\begin{aligned} D_{\alpha}(p \| q) &=\frac{4}{1-\alpha^{2}}\left(1-\int p^{(1+\alpha) / 2} q^{(1-\alpha) / 2} d x\right) \\
&=\frac{4}{1-\alpha^{2}}\left\{1-\int \frac{p}{p^{(1-\alpha) / 2}}\left[1+\frac{1-\alpha}{2} \ln q+O\left(\frac{1-\alpha}{2}\right)^{2}\right] d x\right\} \\
&=\frac{4}{1-\alpha^{2}}\left\{1-\int p \cdot \frac{1+\frac{1-\alpha}{2} \ln q+O\left(\frac{1-\alpha}{2}\right)^{2}}{1+\frac{1-\alpha}{2} \ln p+O\left(\frac{1-\alpha}{2}\right)^{2}} d x\right\} \\ &\approx \frac{4}{1-\alpha^{2}}\left\{1-\int p \cdot \frac{1+\frac{1-\alpha}{2} \ln q}{1+\frac{1-\alpha}{2} \ln p} d x\right\} \\
&=\frac{4}{1-\alpha^{2}}\left\{-\int p \cdot\left[\frac{1+\frac{1-\alpha}{2} \ln q}{1+\frac{1-\alpha}{2} \ln p}-1\right] d x\right\} \\ &=\frac{4}{(1+\alpha)(1-\alpha)}\left\{-\int p \cdot \frac{\frac{1-\alpha}{2} \ln q-\frac{1-\alpha}{2} \ln p}{1+\frac{1-\alpha}{2} \ln p} d x\right\} \\ &=\frac{2}{1+\alpha}\left\{-\int p \cdot \frac{\ln q-\ln p}{1+\frac{1-\alpha}{2} \ln p} d x\right\} \\
&D_{\alpha\rightarrow1}(p \| q)= -\int p \cdot(\ln q-\ln p) d x=\int p \cdot \ln \frac{p}{q}dx = \textrm{KL}(p \| q)
\end{aligned}
$$

同様に$\alpha\rightarrow-1$の時は、以下のように式変形する。

$$
\begin{aligned} D_{\alpha}(p \| q) &=\frac{4}{1-\alpha^{2}}\left(1-\int p^{(1+\alpha) / 2} q^{(1-\alpha) / 2} dx\right) \\
&=\frac{4}{1-\alpha^{2}}\left\{1-\int \left[1+\frac{1+\alpha}{2} \ln p+O\left(\frac{1+\alpha}{2}\right)^{2}\right]\frac{q}{q^{(1+\alpha)/ 2}}dx\right\} \\
&=\frac{4}{1-\alpha^{2}}\left\{1-\int q \cdot \frac{1+\frac{1+\alpha}{2} \ln p+O\left(\frac{1+\alpha}{2}\right)^{2}}{1+\frac{1+\alpha}{2} \ln q+O\left(\frac{1+\alpha}{2}\right)^{2}} dx\right\} \\
& \approx \frac{4}{1-\alpha^{2}}\left\{1-\int q \cdot \frac{1+\frac{1+\alpha}{2} \ln p}{1+\frac{1+\alpha}{2} \ln q}dx\right\} \\
&=\frac{4}{1-\alpha^{2}}\left\{-\int q \cdot\left[\frac{1+\frac{1+\alpha}{2} \ln p}{1+\frac{1+\alpha}{2} \ln q}-1\right] d x\right\} \\ &=\frac{4}{(1+\alpha)(1-\alpha)}\left\{-\int q \cdot \frac{\frac{1+\alpha}{2} \ln p-\frac{1+\alpha}{2} \ln q}{1+\frac{1+\alpha}{2} \ln q}dx\right\} \\ &=\frac{2}{1-\alpha}\left\{-\int q \cdot \frac{\ln p-\ln q}{1+\frac{1+\alpha}{2} \ln q}dx\right\} \\
&D_{\alpha\rightarrow-1}(p \| q)= -\int q \cdot(\ln p-\ln q)dx=\int q \cdot \ln \frac{q}{p}dx = \textrm{KL}(q \| p)
\end{aligned}
$$

## 演習 10.7

<div class="panel-primary">

一変数ガウス分布の平均と精度を，分解した変分近似を用いて求める10.1.3節の問題を考える．このとき，因子$q_{\mu}(\mu)$はガウス分布$\mathcal{N}\left(\mu \mid \mu_{N}, \lambda_{N}^{-1}\right)$となり，この平均と精度はそれぞれ
$$\mu_{N} =\frac{\lambda_{0} \mu_{0}+N \bar{x}}{\lambda_{0}+N} \tag{10.26}$$
$$\lambda_{N} =\left(\lambda_{0}+N\right) \mathbb{E}[\tau] \tag{10.27}$$
で与えられることを示せ．同様にして因子$q_{\tau}(\tau)$はガンマ分布$\textrm{Gam}(\gamma \mid a_N, b_N)$となり，そのパラメータは
$$a_{N}=a_{0}+\frac{N+1}{2} \tag{10.29}$$
$$b_{N}=b_{0}+\frac{1}{2} \mathbb{E}_{\mu}\left[\sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2}+\lambda_{0}\left(\mu-\mu_{0}\right)^{2}\right] \tag{10.30}$$
で与えられることを示せ．

</div>

※

$(10.25)$式から

$$
\begin{aligned} \ln q_{\mu}^{\star}(\mu) &=-\frac{\mathbb{E}[\tau]}{2}\left\{\lambda_{0}\left(\mu-\mu_{0}\right)^{2}+\sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2}\right\}+\text { const } \\ &=-\frac{\mathbb{E}[\tau]}{2}\left\{\lambda_{0} \mu^{2}-2 \lambda_{0} \mu_{0} \mu+\lambda_{0} \mu_{0}^{2}+N \mu^{2}-2\left(\sum_{n=1}^{N} x_{n}\right) \mu+\sum_{n=1}^{N} x_{n}^{2}\right\}+\text { const } \\ &=-\frac{\mathbb{E}[\tau]}{2}\left\{\left(\lambda_{0}+N\right) \mu^{2}-2\left(\lambda_{0} \mu_{0}+\sum_{n=1}^{N} x_{n}\right) \mu+\left(\lambda_{0} \mu_{0}^{2}+\sum_{n=1}^{N} x_{n}^{2}\right)\right\}+\text { const } \\ &=-\frac{\mathbb{E}[\tau]\left(\lambda_{0}+N\right)}{2}\left\{\mu^{2}-2 \frac{\lambda_{0} \mu_{0}+\sum_{n=1}^{N} x_{n}}{\lambda_{0}+N} \mu+\frac{\lambda_{0} \mu_{0}^{2}+\sum_{n=1}^{N} x_{n}^{2}}{\lambda_{0}+N}\right\}+\text { const } \end{aligned}
$$

## 演習 10.8

<div class="panel-primary">

パラメータが
$$a_{N}=a_{0}+\frac{N+1}{2} \tag{10.29}$$
$$b_{N}=b_{0}+\frac{1}{2} \mathbb{E}_{\mu}\left[\sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2}+\lambda_{0}\left(\mu-\mu_{0}\right)^{2}\right] \tag{10.30}$$
で与えられる一変数ガウス分布の精度の変分事後分布を考える．ガンマ分布の平均と分散についての標準的な結果
$$\mathbb{E}[\tau] =\frac{a}{b} \tag{B.27}$$
$$\operatorname{var}[\tau] =\frac{a}{b^{2}} \tag{B.28}$$
を用いて，$N\to \infty$のとき，この変分事後分布の期待値はデータの分散の最尤推定値の逆数となり，事後分布の分散は$0$に近づくことを示せ．

</div>

精度$\tau$はガンマ分布に従う。すなわち、

$$
\begin{aligned}
p(\tau) = \frac{1}{\Gamma(a_N)}b_N^{a_N}\tau^{a_N-1}e^{-b\tau}
\end{aligned}
$$

を満たす。今、ガンマ分布の標準的な結果$(B.27)$、$(B.28)$に代入すると、

$$
\begin{aligned}
\mathbb{E}[\tau] &= \frac{a_N}{b_N} \\
&= \frac{a_{0}+\frac{N+1}{2}}{b_{0}+\frac{1}{2} \mathbb{E}_{\mu}\left[\sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2}+\lambda_{0}\left(\mu-\mu_{0}\right)^{2}\right]} \\
&= \frac{2 a_{0}+N+1}{2 b_{0}+\mathbb{E}_{\mu}\left[\sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2} + \lambda_{0}\left(\mu-\mu_{0}\right)\right]} \\
&\xrightarrow[N\to\infty]{} \frac{N}{\mathbb{E}_{\mu}\left[ \sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2} \right]}
\end{aligned}
$$

これは$N\to \infty$の極限でデータ分散の最尤推定量$\displaystyle \frac{\sum_{n=1}^{N}(x_n-\mu)^2}{N}$の逆数になっている事がわかる。

分散は

$$
\begin{aligned}
\operatorname{var}[\tau] &= \frac{a_N}{{b_N}^2} \\
&=\frac{2\mathbb{E}[\tau]}{2b_{0}+\mathbb{E}_{\mu}\left[\sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2} + \lambda_{0}\left(\mu-\mu_{0}\right)\right]} \\
&\xrightarrow[N\to\infty]{} 0
\end{aligned}
$$

となる。


## 演習 10.9

<div class="panel-primary">

ガンマ分布の平均が$\mathbb{E}[\tau] = a_N/b_N$になるという標準的な結果，および
$$\mu_{N} =\frac{\lambda_{0} \mu_{0}+N \bar{x}}{\lambda_{0}+N} \tag{10.26}$$
$$\lambda_{N} =\left(\lambda_{0}+N\right) \mathbb{E}[\tau] \tag{10.27}$$
$$a_{N}=a_{0}+\frac{N+1}{2} \tag{10.29}$$
$$b_{N}=b_{0}+\frac{1}{2} \mathbb{E}_{\mu}\left[\sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2}+\lambda_{0}\left(\mu-\mu_{0}\right)^{2}\right] \tag{10.30}$$
を用いて，一変数ガウス分布の分解された変分近似の持つ精度の期待値の逆数についての結果
$$\frac{1}{\mathbb{E}[\tau]} =\overline{x^{2}}-\bar{x}^{2} =\frac{1}{N} \sum_{n=1}^{N}\left(x_{n}-\bar{x}\right)^{2} \tag{10.33}$$
を導け．

</div>

※問題文には書かれていないが、PRML下巻P.186の設定から$\mu_{0}=a_{0}=b_{0}=\lambda_{0}=0$であるとする。

まず$\displaystyle \frac{1}{\mathbb{E}[\tau]}$を計算する。

$$
\begin{aligned}
\dfrac{1}{{\mathbb E}[\tau]} &= \left(\frac{a_N}{b_N}\right)^{-1} \\
&= \frac{b_N}{a_N}\\
&=\frac{b_0+\dfrac{1}{2}{\mathbb E}_\mu\left[\displaystyle\sum_{n=1}^N(x_n-\mu)^2+\lambda_0(\mu-\mu_0)^2\right]}{a_0+\dfrac{N+1}{2}} \\
&=\frac{{\mathbb E}_\mu\left[\displaystyle\sum_{n=1}^N(x_n-\mu)^2\right]}{N+1} \\
&=\frac{N}{N+1}\cdot\frac{1}{N}{\mathbb E}_\mu\left[\displaystyle\sum_{n=1}^N(x_n-\mu)^2\right] \\
&=\frac{N}{N+1}{\mathbb E}_\mu\left[\frac{1}{N}\sum_{n=1}^N(x_n-\mu)^2\right] \\
&=\frac{N}{N+1}{\mathbb E}_\mu\left[\frac{1}{N}\sum_{n=1}^N(x_n^2-2\mu x_n+\mu^2)\right] \\
&=\frac{N}{N+1}{\mathbb E}_\mu\left[\frac{1}{N}\sum_{n=1}^Nx_n^2-2\mu\frac{1}{N}\sum_{n=1}^Nx_n+\frac{1}{N}\sum_{n=1}^N\mu^2\right] \\
&=\frac{N}{N+1}{\mathbb E}_\mu\left[\overline{x^2}-2\overline{x}\mu+\mu^2\right] \\
&=\frac{N}{N+1}\left(\overline{x^2}-2\overline{x}{\mathbb E}_\mu[\mu]+{\mathbb E}_\mu[\mu^2]\right)
\end{aligned}
$$

これと

$$
\begin{aligned}
{\mathbb E}_\mu[\mu]&= \mu_N \\
&=\frac{\lambda_0\mu_0+N\overline{x}}{\lambda_0+N} \\
&=\frac{N\overline{x}}{N}\ (\because \lambda_0 = \mu_0 = 0 )\\
&=\overline{x}
\end{aligned}
$$

$$
\begin{aligned}
\mathbb{E}_{\mu}\left[\mu^{2}\right] &=\operatorname{var}[\mu]+\mathbb{E}_{\mu}[\mu]^{2} \\ &=\lambda_{N}^{-1}+\overline{x}^{2} \\ &=\left(\left(\lambda_{0}+N\right) \mathbb{E}[\tau]\right)^{-1}+\overline{x}^{2} \\ &=(N \mathbb{E}[\tau])^{-1}+\overline{x}^{2} \\ &=\frac{1}{N \mathbb{E}[\tau]}+\overline{x}^{2}
\end{aligned}
$$

よって

$$
\begin{aligned}
\dfrac{1}{{\mathbb E}[\tau]} &= \frac{N}{N+1}\left(\overline{x^2}-2\overline{x}\cdot\overline{x}+\frac{1}{N{\mathbb E}[\tau]}+\overline{x}^2\right) \\
&=\frac{N}{N+1}\left(\overline{x^2}-\overline{x}^2+\frac{1}{N{\mathbb E}[\tau]}\right) \\
\therefore \dfrac{1}{{\mathbb E}[\tau]} &= \overline{x^2}-\overline{x}^2
\end{aligned}
$$
一方で
$$
\begin{aligned}
\frac{1}{N} \sum_{n=1}^{N}\left(x_{n}-\overline{x}\right)^{2} &=\frac{1}{N} \sum_{n=1}^{N}\left(x_{n}^{2}-2 \overline{x} x_{n}+\overline{x}^{2}\right) \\ &=\frac{1}{N} \sum_{n=1}^{N} x_{n}^{2}-2 \overline{x} \frac{1}{N} \sum_{n=1}^{N} x_{n}+\frac{1}{N} \sum_{n=1}^{N} \overline{x}^{2} \\ &=\overline{x^{2}}-2 \overline{x} \cdot \overline{x}+\overline{x}^{2} \\ &=\overline{x^{2}}-\overline{x}^{2}
\end{aligned}
$$

よって
$$
\frac{1}{\mathbb{E}[\tau]} =\overline{x^{2}}-\overline{x}^{2} =\frac{1}{N} \sum_{n=1}^{N}\left(x_{n}-\overline{x}\right)^{2} \tag{10.33}
$$

を得る。

## 演習 10.10

<div class="panel-primary">

モデルの事後分布を変分推論を用いて近似する際の分解
$$\ln p(\mathbf{X})=\mathcal{L}-\sum_{m} \sum_{\mathbf{Z}} q(\mathbf{Z} \mid m) q(m) \ln \left\{\frac{p(\mathbf{Z}, m \mid \mathbf{X})}{q(\mathbf{Z} \mid m) q(m)}\right\} \tag{10.34}$$
を導け．

</div>

$$
\begin{aligned}
\mathcal{L} &= \sum_m \sum_{\mathbf{Z}} q(\mathbf{Z}|m)q(m)\ln\left\{\frac{p(\mathbf{X}, \mathbf{Z}, m)}{q(\mathbf{Z}|m)q(m)}\right\} \\
&= \sum_m \sum_{\mathbf{Z}} q(\mathbf{Z}|m)q(m)\ln\left\{\frac{p(\mathbf{Z}, m|\mathbf{X})p(\mathbf{X})}{q(\mathbf{Z}|m)q(m)}\right\} \\
&= \sum_m \sum_{\mathbf{Z}} q(\mathbf{Z}|m)q(m)\ln\left\{\frac{p(\mathbf{Z}, m|\mathbf{X})}{q(\mathbf{Z}|m)q(m)}\right\} + \sum_m \sum_{\mathbf{Z}} q(\mathbf{Z}|m)q(m)\ln\left\{p(\mathbf{X})\right\} \\
&= \sum_m \sum_{\mathbf{Z}} q(\mathbf{Z}|m)q(m)\ln\left\{\frac{p(\mathbf{Z}, m|\mathbf{X})}{q(\mathbf{Z}|m)q(m)}\right\} + \ln p(\mathbf{X})
\end{aligned}
$$

上式を整理することで、式 (10.34) を得る。

## 演習 10.11

<div class="panel-primary">

分布$q(m)$の正規化条件をラグランジュ乗数法を用いて扱うことにより，下限
$$\mathcal{L}=\sum_{m} \sum_{\mathbf{Z}} q(\mathbf{Z} \mid m) q(m) \ln \left\{\frac{p(\mathbf{Z}, \mathbf{X}, m)}{q(\mathbf{Z} \mid m) q(m)}\right\} \tag{10.35}$$
の最大値は
$$q(m) \propto p(m) \exp \left\{\mathcal{L}_{m}\right\} \tag{10.36}$$
によって得られることを示せ．

</div>

問題には「ラグランジュ乗数法を用いて」とあるが、ラグランジュ乗数法を用いない方が簡単に解ける (実際公式の解答も使っていない)。
まず、変分下限$\mathcal{L}$を式変形する。
$$
\begin{aligned}
\mathcal{L} &= \sum_m \sum_{\mathbf{Z}} q(\mathbf{Z}|m)q(m)\ln\left\{\frac{p(\mathbf{X}, \mathbf{Z}, m)}{q(\mathbf{Z}|m)q(m)}\right\} \\
&= \sum_m \sum_{\mathbf{Z}} q(\mathbf{Z}|m)q(m)\ln\left\{\frac{p(\mathbf{Z}, m|\mathbf{X})p(\mathbf{X})}{q(\mathbf{Z}|m)q(m)}\right\} \\
&= \sum_m \sum_{\mathbf{Z}} q(\mathbf{Z}|m)q(m)\left\{\ln p(\mathbf{Z}, m|\mathbf{X}) + \ln p(\mathbf{X}) - \ln q(\mathbf{Z}|m) - \ln q(m)\right\} \\
&= \sum_m q(m) \left(\ln p(m) - \ln q(m) + \sum_{\mathbf{Z}} q(\mathbf{Z}|m)\left\{\ln p(\mathbf{Z}, m|\mathbf{X}) - \ln q(\mathbf{Z}|m)\right\} \right) \\
&= \sum_m q(m)\left\{\ln\left(p(m)\exp(\mathcal{L}_m)\right) - \ln q(m)\right\} \\
&= \sum_m q(m)\ln\left\{\frac{p(m)\exp(\mathcal{L}_m)}{q(m)}\right\}
\end{aligned}
$$

これは$p(m)\exp(\mathcal{L}_m)$と$q(m)$とのKLダイバージェンスに$-1$をかけたものに等しいので、
$$
q(m) \propto p(m)\exp(\mathcal{L}_m)
$$
のとき$\mathcal{L}$が最大となる。
($=$ではなく$\propto$なのは、$p(m)\exp(\mathcal{L}_m)$が正規化されているとは限らないため)

## 演習 10.12

<div class="panel-primary">

同時分布
$$p(\mathbf{X}, \mathbf{Z}, \boldsymbol{\boldsymbol{\pi}}, \boldsymbol{\mu}, \mathbf{\Lambda})=p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \mathbf{\Lambda}) p(\mathbf{Z} \mid \boldsymbol{\boldsymbol{\pi}}) p(\boldsymbol{\boldsymbol{\pi}}) p(\boldsymbol{\mu} \mid \mathbf{\Lambda}) p(\mathbf{\Lambda}) \tag{10.41}$$
から始めて一般的な結果
$$\ln q_{j}^{\star}\left(\mathbf{Z}_{j}\right)= \mathbb{E}_{i \neq j}[\ln p(\mathbf{X}, \mathbf{Z})]+\mathrm{const} \tag{10.9}$$
を適用することで，ベイズ混合ガウス分布の潜在変数の最適な変分事後分布$q^{\star}(\mathbf{Z})$は
$$q^{\star}(\mathbf{Z})=\prod_{n=1}^{N} \prod_{k=1}^{K} r_{n k}^{z_{n k}} \tag{10.48}$$
で与えられることを，本文の段階を確かめることで示せ．

</div>

※教科書P.190の$(10.43)–(10.49)$の導出を確認する問題。

$$
\begin{aligned} \ln q^{\star}(\mathbf{Z}) &=\mathbb{E}_{\boldsymbol{\boldsymbol{\pi}}, \boldsymbol{\mu} \mathbf{\Lambda}}[\ln p(\mathbf{X}, \mathbf{Z}, \boldsymbol{\mu}, \boldsymbol{\boldsymbol{\pi}}, \mathbf{\Lambda})]+\text { const. } \\
&=\mathbb{E}_{\boldsymbol{\boldsymbol{\pi}}, \boldsymbol{\mu}, \mathbf{\Lambda}}[\ln [p(\mathbf{Z} \mid \boldsymbol{\boldsymbol{\pi}}) p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \mathbf{\Lambda}) p(\boldsymbol{\boldsymbol{\pi}}) p(\boldsymbol{\mu} \mid \mathbf{\Lambda}) p(\mathbf{\Lambda})]]+\text { const } \end{aligned}
$$

$Z$に依存しない項はconst.となるので、

$$
\ln q^{\star}(\mathbf{Z})=\mathbb{E}_{\boldsymbol{\pi}}[\ln p(\mathbf{Z} \mid \boldsymbol{\boldsymbol{\pi}})]+\mathbb{E}_{\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}}[\ln p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \mathbf{\Lambda})]+\text { const. }
$$

$(10.37)$と$(10.38)$を代入して

$$
\begin{aligned} \ln q^{\star}(\mathbf{Z})&=\mathbb{E}_{\boldsymbol{\pi}}\left[\sum_{n=1}^{N} \sum_{k=1}^{K} z_{nk} \ln \pi_{k} \right]+\mathbb{E}_{\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}}\left[\sum_{n=1}^{N} \sum_{k=1}^{K} z_{n k} \ln \mathcal{N}\left(\mathbf{x}_{n} \mid \boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}^{-1}\right)\right] + \textrm{const.} \\
&=\sum_{n=1}^{N} \sum_{k=1}^{K}\left\{z_{n k}\left(\mathbb{E}_{\boldsymbol{\pi}}\left[\ln \pi_{k} \right]+\mathbb{E}_{\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}}\left[\ln \mathcal{N}\left(\mathbf{x}_{n} \mid \boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}^{-1}\right)\right]\right)\right\} + \textrm{const.} \\
&=\sum_{n=1}^{N} \sum_{k=1}^{K}\left\{z_{nk} \left(\mathbb{E}_{\boldsymbol{\pi}}\left[\ln \pi_{k} \right]+\frac{1}{2} \mathbb{E}[\ln \mathbf{\Lambda}]-\frac{D}{2} \ln (2 \pi)-\frac{1}{2} \mathbb{E}_{\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}}\left[\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{n}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{n}\right)\right]\right)\right\} + \textrm{const.} \\
&\equiv\sum_{n=1}^{N} \sum_{k=1}^{K} z_{nk}\ln \rho_{nk} + \textrm{const.}
\end{aligned}
$$

最後に本文中で定義した

$$
\begin{aligned} \ln \rho_{n k} &= \mathbb{E}\left[\ln \pi_{k}\right]+\frac{1}{2} \mathbb{E}\left[\ln \left|\mathbf{\Lambda}_{k}\right|\right]-\frac{D}{2} \ln (2 \pi) \\ &-\frac{1}{2} \mathbb{E}_{\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}}\left[\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right] \end{aligned} \tag{10.46}
$$

を用いた。

これを用いて両辺の指数を取れば

$$
q^{\star}(\mathbf{Z}) \propto \prod_{n=1}^{N} \prod_{k=1}^{K} \rho_{n k}^{z_{n k}} \tag{10.47}
$$

を得る。また、この分布は正規化されている必要があることと，各$n$の値について$z_{nk}$は二値ですべての$k$の値にわたる和が$1$であることに注意すると，$(10.48), (10.49)$を得る。

$$
q^{\star}(\mathbf{Z})=\prod_{n=1}^{N} \prod_{k=1}^{K} r_{n k}^{z_{n k}}, \quad r_{n k}=\frac{\rho_{n k}}{\sum_{j=1}^{K} \rho_{n j}}
$$

## 演習 10.13

<div class="panel-primary">

$$
\begin{aligned} \ln q^{\star} &(\boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{\Lambda})=\ln p(\boldsymbol{\pi})+\sum_{n=1}^{N} \ln p\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right)+\mathbb{E}_{\mathbf{Z}}[\ln p(\mathbf{Z} \mid \boldsymbol{\pi})] \\ &+\sum_{n=1}^{N} \sum_{n=1}^{N} \mathbb{E}\left[z_{n k}\right] \ln \mathcal{N}\left(\mathbf{x}_{n} \mid \boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}^{-1}\right)+\text { const. } \end{aligned} \tag{10.54}$$
から始めて，ベイズ混合ガウス分布における$\boldsymbol{\mu}_k$と$\mathbf{\Lambda}_k$の最適な変分事後分布についての結果
$$q^{\star}\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right)=\mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}\right) \mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{k}, \nu_{k}\right) \tag{10.59}$$
を導き，この分布のパラメータが

$$
\begin{align} \beta_{k} &=\beta_{0}+N_{k} \tag{10.60} \\ \mathbf{m}_{k} &=\frac{1}{\beta_{k}}\left(\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}\right) \tag{10.61} \\ \mathbf{W}_{k}^{-1} &=\mathbf{W}_{0}^{-1}+N_{k} \mathbf{S}_{k}+\frac{\beta_{0} N_{k}}{\beta_{0}+N_{k}}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{0}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \tag{10.62} \\ \nu_{k} &=\nu_{0}+N_{k} \tag{10.63} \end{align}
$$

で与えられることを確かめよ．

</div>


※多変数で平均と精度がともに未知な場合、上巻P.100の$(2.157)$式にあるガウス–ウィシャート分布の形の共役事前分布を取ることを利用する。

$$
\mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_0,\left(\beta_{0} \mathbf{\Lambda}_{k}\right)^{-1}\right)=\left(\frac{1}{2 \pi \beta_{0}}\right)^{\frac{D}{2}}\left(\left|\mathbf{\Lambda}_{k}\right|\right)^{\frac{1}{2}} \exp \left\{-\frac{\beta_{0}}{2}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_0\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_0\right)\right\}
$$

$$
\mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{0}, \nu_{0}\right)=B\left(\mathbf{W}_{0}, \nu_{0}\right)\left|\mathbf{\Lambda}_{k}\right|^{\left(\nu_{0}-D-1\right) / 2} \exp \left(-\frac{1}{2} \operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{\Lambda}_{k}\right)\right) \tag{B .78}
$$

を利用して$(10.54)$式のうち$\boldsymbol{\mu}_k$と$\mathbf{\Lambda}_k$に依存する項を考える。ただし

$$q^{\star}(\boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{\Lambda})=q^{\star}(\boldsymbol{\pi}) \prod_{k=1}^{K} q^{\star}\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right) \tag{10.55}$$

で示されているように、$\prod_{k=1}^{K}$の部分は外に出ていることに留意する。

$$
\begin{aligned}\ln q^{\star}(\boldsymbol{\mu}_k, \mathbf{\Lambda}_k) &= \ln p\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right)+\sum_{n=1}^{N} \mathbb{E}\left[z_{n k}\right] \ln \mathcal{N}\left(\mathbf{x}_n \mid \boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}^{-1}\right) \\
&= \ln \left[\mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_0,\left(\beta_{0} \mathbf{\Lambda}_{k}\right)^{-1}\right) \mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{0}, \nu_{0}\right)\right] +\sum_{n=1}^{N} \mathbb{E}\left[z_{n k}\right] \ln \mathcal{N}\left(\mathbf{x}_n \mid \boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}^{-1}\right) \\
&= \ln \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_0,\left(\beta_{0} \mathbf{\Lambda}_{k}\right)^{-1}\right)+ \ln \mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{0}, \nu_{0}\right) +\sum_{n=1}^{N} \mathbb{E}\left[z_{n k}\right] \ln \mathcal{N}\left(\mathbf{x}_n \mid \boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}^{-1}\right) \\
&=\frac{1}{2}\ln |\mathbf{\Lambda}_k| - \frac{\beta_0}{2}(\boldsymbol{\mu}_k - \mathbf{m}_0)^{\mathrm T}\mathbf{\Lambda}_k(\boldsymbol{\mu}_k - \mathbf{m}_0) +\frac{\nu_{0}-D-1}{2} \ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2} \operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{\Lambda}_{k}\right) \\
&+\sum_{n=1}^{N} \mathbb{E}\left[z_{nk}\right]\left(\frac{1}{2}\ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2}\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)\right)+\textrm{const.}
\end{aligned}
$$

これをさらに$\ln q^{\star}\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right ) = \ln q^{\star}\left(\boldsymbol{\mu}_{k} \mid \mathbf{\Lambda}_{k}\right) + \ln q^{\star}\left(\mathbf{\Lambda}_{k}\right)$の形に分解する。$\boldsymbol{\mu}_{k}$に依存する項の部分を取り出す。

$$
\begin{aligned}\ln q^{*}\left(\boldsymbol{\mu}_{k} \mid \mathbf{\Lambda}_{k}\right) &= -\frac{1}{2} \boldsymbol{\mu}_{k}^{\mathrm T}\left[\beta_{0}+\sum_{n=1}^{N} \mathbb{E}\left[z_{n k}\right]\right] \mathbf{\Lambda}_{k} \boldsymbol{\mu}_{k} +\boldsymbol{\mu}_{k}^{\mathrm T} \mathbf{\Lambda}_{k}\left[\beta_{0} \mathbf{m}_0+\sum_{n=1}^{N} \mathbb{E}\left[z_{nk}\right] \mathbf{x}_{n}\right]+\textrm{const.} \\
&= -\frac{1}{2} \boldsymbol{\mu}_{k}^{\mathrm T}(\beta_{0}+N_k) \mathbf{\Lambda}_{k} \boldsymbol{\mu}_{k} +\boldsymbol{\mu}_{k}^{\mathrm T} \mathbf{\Lambda}_{k}\left[\beta_{0} \mathbf{m}_0+ N_k \overline{\mathbf{x}}_k \right]+\textrm{const.}\quad (\because (10.50)-(10.52))\end{aligned}
$$

この形は$\boldsymbol{\mu}_{k}$についての二次形式となっており、両辺の指数を取れば多変数ガウス分布の形で

$$q^{\star}\left(\boldsymbol{\mu}_{k}\mid \mathbf{\Lambda}_{k}\right)=\mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}\right)$$

と書ける。ただし

$$
\begin{aligned} \beta_{k} &=\beta_{0}+N_{k} \\ \mathbf{m}_{k} &=\frac{1}{\beta_{k}}\left(\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}\right) \end{aligned}
$$

である。

続いて$q^{\star}(\mathbf{\Lambda}_k)$について、これは$\ln q^{\star}(\mathbf{\Lambda}_k) = \ln q^{\star}\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right ) -\ln q^{\star}\left(\boldsymbol{\mu}_{k} \mid \mathbf{\Lambda}_{k}\right)$から求めると

$$
\begin{aligned}
\ln q^{*}\left(\mathbf{\Lambda}_{k}\right) &=\frac{1}{2} \ln \left|\mathbf{\Lambda}_{k}\right|-\frac{\beta_{0}}{2}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right) +\frac{\nu_{0}-D-1}{2}\ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2} \operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{\Lambda}_{k}\right) \\
&+\sum_{n=1}^{N} \mathbb{E}\left[z_{n k}\right]\left(\frac{1}{2}\ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2}\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)\right) - \ln q^{\star}\left(\boldsymbol{\mu}_{k}\mid \mathbf{\Lambda}_{k}\right) +\textrm{const.}\\
&= \frac{1}{2} \ln \left|\mathbf{\Lambda}_{k}\right|-\frac{\beta_{0}}{2}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right) +\frac{\nu_{0}-D-1}{2}\ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2} \operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{\Lambda}_{k}\right) \\
&+\sum_{n=1}^{N} \mathbb{E}\left[z_{n k}\right]\left(\frac{1}{2}\ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2}\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)\right) \\
&-\frac{1}{2} \ln \left|\beta_{k} \mathbf{\Lambda}_{k}\right|-\frac{\beta_{k}}{2}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{k}\right) +\textrm{const.}\\
&=\frac{\nu_{0}-D-1}{2}\ln|\mathbf{\Lambda}_k|+\frac{1}{2}\sum_{n=1}^{N}\mathbb{E}[z_{nk}]\ln |\mathbf{\Lambda}_k| \\
&-\frac{1}{2} \operatorname{Tr}\left[\left\{\beta_{0}\left(\boldsymbol{\mu}_k-\mathbf{m}_{0}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}+\sum_{n=1}^{N} \mathbb{E}[z_{nk}]\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)\left(\mathbf{x}_n-\boldsymbol{\mu}_k\right)^{\mathrm T} \right.\right. \\
&\left.\left.-\beta_{k}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{k}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{k}\right)^{\mathrm T}+\mathbf{W}_{0}^{-1}\right\} \mathbf{\Lambda}_{k}\right]+\textrm{const.}
\end{aligned}
$$

これがウィシャート分布の対数形

$$
\ln \mathcal{W}=\ln B(\mathbf{W}_k, \nu_{k})+\frac{\nu_{k}-D-1}{2}\ln\left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2} \operatorname{Tr}\left(\mathbf{W}_{k}^{-1} \mathbf{\Lambda}_{k}\right)
$$

となれば良い（$B(\mathbf{W}_{k},\nu_{k})$は正規化の定数項）。係数を比較して、

$$
\nu_{k}=\nu_{0}+\sum_{n=1}^{N} \mathbb{E}\left[z_{nk}\right]=\nu_{0}+N_{k}
$$

$$ \mathbf{W}_{k}^{-1}=\mathbf{W}_{0}^{-1}+\beta_{0}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}-\beta_{k}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{k}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{k}\right)^{\mathrm T}+\sum_{n=1}^{N} \mathbb{E}\left[z_{nk}\right]\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)^{\mathrm T}
$$

となる。

最後の$\mathbf{W}_k^{-1}$が$(10.62)$の形になることを**がんばって**計算で示す。

$$
\begin{aligned}\mathbf{W}_{k}^{-1}&=\mathbf{W}_{0}^{-1}+\beta_{0}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}-\beta_{k}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{k}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{k}\right)^{\mathrm T}+\sum_{n=1}^{N} \mathbb{E}\left[z_{nk}\right]\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)\left(\mathbf{x}_n-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \\
&=\mathbf{W}_{0}^{-1}+\beta_{0} \boldsymbol{\mu}_{k} \boldsymbol{\mu}_{k}^{\mathrm T}-2 \beta_{0} \mathbf{m}_{0} \boldsymbol{\mu}_{k}^{\mathrm T}+\beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}-\beta_{k} \boldsymbol{\mu}_{k} \boldsymbol{\mu}_{k}^{\mathrm T}+2 \beta_{k} \mathbf{m}_{k} \boldsymbol{\mu}_{k}^{\mathrm T} -\beta_{k} \mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm T}
+\sum_{n=1}^{N} r_{n k} \mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm T}-2 \sum_{n=1}^{N} r_{n k} \mathbf{x}_{n} \boldsymbol{\mu}_{k}^{\mathrm T}+\sum_{n=1}^{N} r_{n k} \boldsymbol{\mu}_{k} \boldsymbol{\mu}_{k}^{\mathrm T} \\
&=\mathbf{W}_{0}^{-1}+\underbrace{\left( \sum_{n=1}^{N}r_{nk}+\beta_{0}-\beta_{k} \right)}_{0}\boldsymbol{\mu}_{k} \boldsymbol{\mu}_{k}^{\mathrm T} -2\underbrace{\left(\sum_{n=1}^{N} r_{n k} \mathbf{x}_{n}+\beta_{0} \mathbf{m}_{0}-\beta_{k} \mathbf{m}_{k}\right)}_{0} \boldsymbol{\mu}_{k}^{\mathrm T} + \sum_{n=1}^{N} r_{nk} \mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm T}+\beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}-\beta_{k} \mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm T} \\
&=\mathbf{W}_{0}^{-1}+ \underbrace{\sum_{n=1}^{N} r_{nk} \mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm T}}_{(A)} + \underbrace{\beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}-\beta_{k} \mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm T}}_{(B)} \quad (\because \beta_{k} \mathbf{m}_{k}=\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}) \\
&=\mathbf{W}_{0}^{-1} + \underbrace{N_{k} \mathbf{S}_{k}+N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}}_{(A)} + \underbrace{\frac{\beta_{0} N_{k}}{\beta_{k}} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}-\frac{N_{k}^{2}}{\beta_{k}} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}-\frac{\beta_{0} N_{k}}{\beta_{k}}\left(2 \mathbf{m}_{0} \overline{\mathbf{x}}_{k}^{\mathrm T}\right)}_{(B)} \\
&=\mathbf{W}_{0}^{-1} + N_{k} \mathbf{S}_{k} + \frac{\beta_{0}N_{k}}{\beta_{k}}\left( \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T} -2\mathbf{m}_{0}\overline{\mathbf{x}}_{k}^{\mathrm T} + \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T} \right) \\
&=\mathbf{W}_{0}^{-1} + N_{k} \mathbf{S}_{k} + \frac{\beta_{0}N_{k}}{\beta_{0} + N_{k}}\left( \overline{\mathbf{x}}_{k} - \mathbf{m}_{0} \right)\left( \overline{\mathbf{x}}_{k} - \mathbf{m}_{0} \right)^{\mathrm T}
\end{aligned}
$$

以上で$(10.62)$が示された。

途中の式変形$(A)$について

$$
\begin{aligned}
\sum_{n=1}^{N} r_{n k} \mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm T}&=\sum_{n=1}^{N} r_{n k}\left[\left(\mathbf{x}_{n}-\overline{\mathbf{x}}_{k}\right)\left(\mathbf{x}_{n}-\overline{\mathbf{x}}_{k}\right)^{\mathrm T}-\overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}+2 \mathbf{x}_{n} \overline{\mathbf{x}}_{k}^{\mathrm T}\right]\\
&=\sum_{n=1}^{N} r_{n k}\left[\left(\mathbf{x}_{n}-\overline{\mathbf{x}}_{k}\right)\left(\mathbf{x}_{n}-\overline{\mathbf{x}}_{k}\right)^{\mathrm T}+\overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}+2\left(\mathbf{x}_{n}-\overline{\mathbf{x}}_{k}\right) \overline{\mathbf{x}}_{k}^{\mathrm T}\right]\\
&=N_{k} \mathbf{S}_{k}+\sum_{n=1}^{N} r_{n k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}+2 \sum_{n=1}^{N} r_{n k}\left[\left(\mathbf{x}_{n}-\overline{\mathbf{x}}_{k}\right) \overline{\mathbf{x}}_{k}^{\mathrm T}\right] \\
&=N_{k} \mathbf{S}_{k}+\sum_{n=1}^{N} r_{n k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}+2 \sum_{n=1}^{N} r_{n k} \mathbf{x}_{n} \overline{\mathbf{x}}_{k}^{\mathrm T}-2 \sum_{n=1}^{N} r_{nk} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}\\
&=N_{k} \mathbf{S}_{k}+N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}+2 N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}-2 N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}\\
&=N_{k} \mathbf{S}_{k}+N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}
\end{aligned}
$$

途中の式変形$(B)$について

$$
\begin{aligned}
\beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}-\beta_{k} \mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm T} &=\beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}-\frac{1}{\beta_{k}}\left(\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}\right)\left(\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}\right)^{\mathrm T} \\
&=\left(1-\frac{\beta_{0}}{\beta_{k}}\right) \beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}-\frac{N_{k}^{2}}{\beta_{k}} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}-\frac{2}{\beta_{k}} \beta_{0} N_{k} \mathbf{m}_{0} \overline{\mathbf{x}}_{k}^{\mathrm T} \\
&=\frac{\beta_{0} N_{k}}{\beta_{k}} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}-\frac{N_{k}^{2}}{\beta_{k}} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}-\frac{\beta_{0} N_{k}}{\beta_{k}}\left(2 \mathbf{m}_{0} \overline{\mathbf{x}}_{k}^{\mathrm T}\right)
\end{aligned}
$$

となることを用いた。

## 演習 10.14

<div class="panel-primary">

$$
q^{\star}\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right)=\mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}\right) \mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{k}, \nu_{k}\right) \tag{10.59}
$$
の分布を使って，
$$
\begin{aligned}& \mathbb{E}_{\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}}\left[\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right] \\
=&\ D \beta_{k}^{-1}+\nu_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)\end{aligned}\tag{10.64}
$$
の結果を確かめよ．

</div>

期待値の定義を使って計算していく。

$$
\begin{aligned} & \mathbb{E}_{\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}}\left[\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right] \\
=& \iint\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right) q^{\star}\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right) d \boldsymbol{\mu}_{k} d \mathbf{\Lambda}_{k} \\
=&\int\left\{\int\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right) q^{\star}\left(\boldsymbol{\mu}_{k} \mid \mathbf{\Lambda}_{k}\right) d \boldsymbol{\mu}_{k}\right\} q^{\star}\left(\mathbf{\Lambda}_{k}\right) d \mathbf{\Lambda}_{k} \\
=&\int\underbrace{\left\{\int\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right) \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}\right) d \boldsymbol{\mu}_{k}\right\}}_{(A)} q^{\star}\left(\mathbf{\Lambda}_{k}\right) d \mathbf{\Lambda}_{k}
\end{aligned}
$$

$(A)$について、

$$
\begin{aligned} & \int\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right) \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \Lambda_{A}\right)^{-1}\right) d \boldsymbol{\mu}_{k} \\
=&\ \mathbb{E}_{\boldsymbol{\mu}_{k}}\left[\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right]\quad \left(\boldsymbol{\mu}_{k} \sim \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}\right)\right) \\
=&\ \mathbb{E}_{\boldsymbol{\mu}_{k}}\left[\operatorname{Tr}\left[\mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T}\right]\right] \\
=&\ \mathbb{E}_{\boldsymbol{\mu}_{k}}\left[\operatorname{Tr}\left[\mathbf{\Lambda}_{k}\left(\mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm T}-2 \mathbf{x}_{n}^{\mathrm T} \boldsymbol{\mu}_{k}+\boldsymbol{\mu}_{k} \boldsymbol{\mu}_{k}^{\mathrm T}\right)\right]\right] \\
=&\operatorname{Tr}\left[\mathbb{E}_{\boldsymbol{\mu}_{k}}\left[\mathbf{\Lambda}_{k} \mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm T}\right]-2 \mathbb{E}_{\boldsymbol{\mu}_{k}}\left[\mathbf{\Lambda}_{k} \mathbf{x}_{n}^{\mathrm T} \boldsymbol{\mu}_{k}\right]+\mathbb{E}_{\boldsymbol{\mu}_{k}}\left[\mathbf{\Lambda}_{k} \boldsymbol{\mu}_{k} \boldsymbol{\mu}_{k}^{\mathrm T}\right]\right] \\
=&\operatorname{Tr}\left[\mathbf{\Lambda}_{k}\left\{\mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm T}-2 \mathbf{x}_{n}^{\mathrm T} \mathbb{E}_{\boldsymbol{\mu}_{k}}\left[\boldsymbol{\mu}_{k}\right]+\mathbb{E}_{\boldsymbol{\mu}_{k}}\left[\boldsymbol{\mu}_{k} \boldsymbol{\mu}_{k}^{\mathrm T}\right]\right\}\right] \\
=&\operatorname{Tr}\left[\mathbf{\Lambda}_{k}\left\{\mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm T}-2 \mathbf{x}_{n}^{\mathrm T} \mathbf{m}_{k}+\mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm T}+\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}\right\}\right] \\
=&\operatorname{Tr}\left[\mathbf{\Lambda}_{k}\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)^{\mathrm T}\right]+\operatorname{Tr}\left[\beta_{k}^{-1} \mathbf{I}\right] \\
=&\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)^{\mathrm T}\mathbf{\Lambda}_{k}\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)+D\beta_{k}^{-1}
\end{aligned}
$$

となる。ここで、$\mathbb{E}_{\boldsymbol{\mu}_{k}}\left[\boldsymbol{\mu}_{k}\right] = \mathbf{m}_{k}$と$\mathbb{E}_{\boldsymbol{\mu}_{k}}\left[\boldsymbol{\mu}_{k} \boldsymbol{\mu}_{k}^{\mathrm T}\right] = \mathbf{m}_k \mathbf{m}_k^{\mathrm T}+\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}$、さらにトレース演算子と期待値演算子はともに線形演算子で交換可能であることを用いた。$D$は$\mathbf{x}_n$の次元数である。

これと演習問題10.13で得られた$q^{\star}(\mathbf{\Lambda}_k) = \mathcal{W}(\mathbf{\Lambda}_k \mid \mathbf{W}_k, \nu_k)$を用いると

$$
\begin{aligned}
\mathbb{E}_{\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}}\left[\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right] &= \int \left( \left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)^{\mathrm T}\mathbf{\Lambda}_{k}\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)+D\beta_{k}^{-1} \right)q^{\star}(\mathbf{\Lambda}_k)d\mathbf{\Lambda}_k \\
&=\mathbb{E}_{\mathbf{\Lambda}_k}\left[ \left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)^{\mathrm T}\mathbf{\Lambda}_{k}\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)+D\beta_{k}^{-1} \right] \quad \left( \mathbf{\Lambda}_{k} \sim \mathcal{W}(\mathbf{\Lambda}_k \mid \mathbf{W}_k, \nu_k) \right)\\
&=\mathbb{E}_{\mathbf{\Lambda}_k}[D \beta_{k}^{-1}]+\mathbb{E}_{\mathbf{\Lambda}_{k}}\left[\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)^{\mathrm T} \Lambda_{k}\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)\right] \\
&=D \beta_{k}^{-1}+\mathbb{E}_{\mathbf{\Lambda}_{k}}\left[\operatorname{Tr}\left[\mathbf{\Lambda}_{k} \left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)^{\mathrm T}\right]\right] \\
&=D \beta_{k}^{-1}+\operatorname{Tr}\left[\mathbb{E}_{\mathbf{\Lambda}_{k}}\left[\mathbf{\Lambda}_{k}\right] \left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)^{\mathrm T}\right] \\
&=D \beta_{k}^{-1}+\operatorname{Tr}\left[\nu_{k} \mathbf{W}_{k} \left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)^{\mathrm T}\right] \\
&=D \beta_{k}^{-1}+\nu_{k}\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{x}_{n} - \mathbf{m}_{k}\right)
\end{aligned}
$$

となり、$(10.64)$式が得られた。

> 「これは容易に計算できて」とは？

## 演習 10.15

<div class="panel-primary">

$$
\mathbb{E}\left[\mu_{k}\right]=\frac{\alpha_{k}}{\widehat{\alpha}}=\frac{\alpha_k}{\sum_{k=1}^{K}\alpha_k}\tag{B.17}
$$
の結果を用いて，変分混合ガウス分布の混合係数の期待値は

$$
\mathbb{E}\left[\pi_{k}\right]=\frac{\alpha_{0}+N_{k}}{K \alpha_{0}+N}\tag{10.69}
$$

で与えられることを示せ．

</div>

単純に$\mu_k \to \pi_k$とし、$(10.58)$を用いて式を変形すれば求まる。

$$
\begin{aligned} \mathbb{E}\left[\pi_{k}\right] &=\frac{\alpha_{k}}{\sum_{k=1}^{K} \alpha_{k}}\quad \because(\textrm{B} .17) \\ &=\frac{\alpha_{0}+N_{k}}{\sum_{k=1}^{K}\left(\alpha_{0}+N_{k}\right)}\quad \because(10.58) \\
&=\frac{\alpha_{0}+N_{k}}{K \alpha_{0}+\sum_{k=1}^{K} N_{k}}=\frac{\alpha_{0}+N_{k}}{K \alpha_{0}+N} \end{aligned}
$$

以上で$(10.69)$式が求められた。

## 演習 10.16

<div class="panel-primary">

$$
\begin{aligned} \mathcal{L} &=\sum_{\mathbf{Z}} \iiint q(\mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{\Lambda}) \ln \left\{\frac{p(\mathbf{X}, \mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{\Lambda})}{q(\mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{\Lambda})}\right\} \mathrm{d} \pi \mathrm{d} \boldsymbol{\mu} \mathrm{d} \mathbf{\Lambda} \\ &=\mathbb{E}[\ln p(\mathbf{X}, \mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{\Lambda})]-\mathbb{E}[\ln q(\mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{\Lambda})] \\ &= \mathbb{E}[\ln p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \mathbf{\Lambda})]+\mathbb{E}[\ln p(\mathbf{Z} \mid \boldsymbol{\pi})]+\mathbb{E}[\ln p(\boldsymbol{\pi})]+\mathbb{E}[\ln p(\boldsymbol{\mu}, \mathbf{\Lambda})] \\ &-\mathbb{E}[\ln q(\mathbf{Z})]-\mathbb{E}[\ln q(\boldsymbol{\pi})]-\mathbb{E}[\ln q(\boldsymbol{\mu}, \mathbf{\Lambda})] \end{aligned} \tag{10.70}$$
で与えられる変分ガウス混合モデルの下界の，最初の二項についての結果
$$
\begin{aligned} \mathbb{E}[\ln p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \mathbf{\Lambda})]&= \frac{1}{2} \sum_{k=1}^{K} N_{k}\left\{\ln \widetilde{\Lambda}_{k}-D \beta_{k}^{-1}-\nu_{k} \operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right)\right.\\ &\left.-\nu_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)-D \ln (2 \pi)\right\} \end{aligned} \tag{10.71}$$
$$
\begin{aligned} \mathbb{E}[\ln p(\mathbf{Z} \mid \boldsymbol{\pi})]= \sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln \tilde{\pi}_{k} \end{aligned} \tag{10.72}$$
を確かめよ．

</div>

容易に計算できるらしいのでやってみる。$(10.71)$について$(10.38)$の観測データベクトルの条件付き分布の式

$$
p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \mathbf{\Lambda})=\prod_{n=1}^{N} \prod_{k=1}^{K} \mathcal{N}\left(\mathbf{x}_{n} \mid \boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}^{-1}\right)^{z_{n k}} \tag{10.38}
$$

を用いると

$$
\begin{aligned}\mathbb{E}[\ln p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \mathbf{\Lambda})]&=\mathbb{E}\left[z_{nk} \sum_{n=1}^{N} \sum_{k=1}^{K} \ln \mathcal{N}\left(\mathbf{x}_{n} \mid \boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}^{-1}\right)\right] \\
&=\sum_{n=1}^{N} \sum_{k=1}^{K} \mathbb{E}\left[z_{n k}\left\{-\frac{D}{2} \ln (2 \pi)+\frac{1}{2} \ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right\}\right]
\end{aligned}
$$

今は負担率$\mathbb{E}[z_{nk}]= r_{nk}$を固定したときのパラメータの変分事後分布を求めているので、$\mathbb{E}[z_{nk}]$は分離＆固定して考える（ってことで合ってるのか？）。

$$
\begin{aligned}
&=\sum_{n=1}^{N} \sum_{k=1}^{K} \mathbb{E}\left[z_{n k}\right] \mathbb{E}\left[-\frac{D}{2} \ln (2 \pi)+\frac{1}{2} \ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right] \\
&=\frac{1}{2} \sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \mathbb{E}[-D \ln (2 \pi)]+\mathbb{E}_{\mathbf{\Lambda}_{k}}\left[\ln \left|\mathbf{\Lambda}_{k}\right|\right]-\mathbb{E}_{\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}}\left[\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm T} \mathbf{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right] \\
&=\frac{1}{2} \sum_{k=1}^{N} \sum_{k=1}^{K} r_{n k}\left[-D \ln (2 \pi)+\ln \tilde{\Lambda}_{k}-\left(D \beta_{k}^{-1}+\nu_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\right)\right] \quad (\because (10.64))\\
&=\frac{1}{2} \sum_{k=1}^{K}\left\{\sum_{n=1}^{N} r_{n k}\left(-D \ln (2 \pi)+\ln \tilde{\Lambda}_{k}-D \beta_{k}^{-1}\right)-\sum_{n=1}^{N} r_{n k} \nu_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)\right\} \\
&= \frac{1}{2} \sum_{k=1}^{K} \left\{ N_{k}\left(-D \ln(2 \pi)+\ln \tilde{\Lambda}_{k}-D \beta_{k}^{-1}\right)-\sum_{n=1}^{N} r_{nk} \nu_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)\right\} \\
&= \frac{1}{2} \sum_{k=1}^{K} N_{k} \left\{ \ln \tilde{\Lambda}_{k}-D \beta_{k}^{-1}- \nu_{k}\operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right) -\nu_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right) -D \ln(2 \pi) \right\} \quad (\because (*))
\end{aligned}
$$

以上で$(10.71)$式が示された。

<hr>

$(*)$の式変形の$\sum_{n=1}^{N} r_{nk} \nu_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)$について

$$
\begin{aligned}
\sum_{n=1}^{N} r_{nk} \nu_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)
&=\nu_{k} \sum_{n=1}^{N} r_{n k}\left[\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)\right] \\
&=\nu_{k} \sum_{n=1}^{N} r_{n k}\left[\operatorname{Tr}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\right] \\
&=\nu_{k} \operatorname{Tr}\left[\sum_{n=1}^{N} r_{n k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\right] \\
&=\nu_{k} N_{k} \operatorname{Tr}\left[\mathbf{S}_{k} \mathbf{W}_{k}+\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\right] \quad (\because (**))\\
&=\nu_{k} N_{k}\left\{\operatorname{Tr}\left[\mathbf{S}_{k} \mathbf{W}_{k}\right]+\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\right\}
\end{aligned}
$$

<hr>

$(**)$の式変形について

$$
\begin{aligned} \sum_{n=1}^{N} r_{n k}\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)\left(\mathbf{x}_{n}-\mathbf{m}_{k}\right)^{\mathrm T} &= \sum_{n=1}^{N} r_{n k} \mathbf{x}_{n} \mathbf{x}_{n}^{\mathrm T}-2 \sum_{n=1}^{N} r_{n k} \mathbf{m}_{k}^{\mathrm T} \mathbf{x}_{n}+\sum_{n=1}^{N} r_{n k} \mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm T} \\
&=N_{k} \mathbf{S}_{k}+N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm T}-2 N_{k} \mathbf{m}_{k}^{\mathrm T} \overline{\mathbf{x}}_{k}+N_{k} \mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm T} \quad (\because 演習10.13の式変形(A))\\
&=N_{k}\left(\mathbf{S}_{k}+\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T}\right) \end{aligned}
$$

<hr>

$(10.72)$については
$$
p(\mathbf{Z} \mid \boldsymbol{\pi})=\prod_{n=1}^{N} \prod_{k=1}^{K} \pi_{k}^{z_{n k}} \tag{10.37}
$$
から直ちに求められる。

$$
\begin{aligned}
\mathbb{E}_{\mathbf{Z},\boldsymbol{\pi}}[\ln p(\mathbf{Z}\mid \boldsymbol{\pi})] &= \sum_{n=1}^{N}\sum_{k=1}^{K}\mathbb{E}_{\mathbf{Z},\boldsymbol{\pi}} \left[ z_{nk} \ln \pi_{k} \right] \\
&= \sum_{n=1}^{N}\sum_{k=1}^{K}\mathbb{E}_{\mathbf{Z}} \left[ z_{nk} \right]  \mathbb{E}_{\boldsymbol{\pi}} \left[\ln \pi_{k} \right] \\
&= \sum_{n=1}^{N}\sum_{k=1}^{K}r_{nk}\ln\tilde{\pi}_k \quad (\because (10.66))
\end{aligned}
$$

## 演習 10.17

<div class="panel-primary">

$$
\begin{aligned} \mathcal{L} &= \mathbb{E}[\ln p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \mathbf{\Lambda})]+\mathbb{E}[\ln p(\mathbf{Z} \mid \boldsymbol{\pi})]+\mathbb{E}[\ln p(\boldsymbol{\pi})]+\mathbb{E}[\ln p(\boldsymbol{\mu}, \mathbf{\Lambda})] \\ &-\mathbb{E}[\ln q(\mathbf{Z})]-\mathbb{E}[\ln q(\boldsymbol{\pi})]-\mathbb{E}[\ln q(\boldsymbol{\mu}, \mathbf{\Lambda})] \end{aligned} \tag{10.70}$$
で与えられる変分ガウス混合モデルの下界の，残りの項についての結果
$$\mathbb{E}[\ln p(\boldsymbol{\pi})]=\ln C(\boldsymbol{\alpha}_{0})+\left(\alpha_{0}-1\right) \sum_{k=1}^{K} \ln \widetilde{\pi}_{k} \tag{10.73}$$
$$
\begin{aligned}
\mathbb{E}[\ln p(\boldsymbol{\mu}, \mathbf{\Lambda})] &=\frac{1}{2} \sum_{k=1}^{K}\left\{D \ln \left(\beta_{0} / 2 \pi\right)+\ln \widetilde{\Lambda}_{k}-\frac{D \beta_{0}}{\beta_{k}}\right. \\ &\left.-\beta_{0} \nu_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\}+K \ln B\left(\mathbf{W}_{0}, \nu_{0}\right) \\ &+\frac{\left(\nu_{0}-D-1\right)}{2} \sum_{k=1}^{K} \ln \widetilde{\Lambda}_{k}-\frac{1}{2} \sum_{k=1}^{K} \nu_{k} \operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right) \end{aligned}\tag{10.74}$$
$$\mathbb{E}[\ln q(\mathbf{Z})]=\sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln r_{n k} \tag{10.75}$$
$$\mathbb{E}[\ln q(\boldsymbol{\pi})]=\sum_{k=1}^{K}\left(\alpha_{k}-1\right) \ln \tilde{\pi}_{k}+\ln C(\boldsymbol{\alpha}) \tag{10.76}$$
$$\mathbb{E}[\ln q(\boldsymbol{\mu}, \mathbf{\Lambda})]=\sum_{k=1}^{K}\left\{\frac{1}{2} \ln \widetilde{\Lambda}_{k}+\frac{D}{2} \ln \left(\frac{\beta_{k}}{2 \pi}\right)-\frac{D}{2}-\mathrm{H}\left[q\left(\mathbf{\Lambda}_{k}\right)\right]\right\} \tag{10.77}$$
を確かめよ．

</div>

$(10.39)$より$p(\boldsymbol{\pi}) = \operatorname{Dir}(\boldsymbol{\pi}\mid \boldsymbol{\alpha}_{0})$となることを用いて

$$
\begin{aligned}
\mathbb{E}[\ln p(\boldsymbol{\pi})] &=\mathbb{E}\left[\ln C(\boldsymbol{\alpha}_{0}) \prod_{k=1}^{K} \pi_{k}^{\alpha_{0}-1}\right] \\
&=\mathbb{E}\left[\ln C(\boldsymbol{\alpha}_{0})\right]+\mathbb{E}\left[\sum_{k=1}^{K} \ln \pi_{k}^{\alpha_{0}-1}\right] \\
&=\ln C(\boldsymbol{\alpha}_{0})+\mathbb{E}\left[\sum_{k=1}^{K}\left(\alpha_{0}-1\right) \ln \pi_{k}\right] \\
&=\ln C(\boldsymbol{\alpha}_{0})+\left(\alpha_{0}-1\right) \sum_{k=1}^{K} \mathbb{E}[\ln \pi_{k}] \\
&=\ln C(\boldsymbol{\alpha}_{0})+\left(\alpha_{0}-1\right) \sum_{k=1}^{K} \ln \tilde{\pi}_{k}
\end{aligned}
$$

以上で$(10.73)$式が求まった。

<hr>

$(10.40)$で導入したガウス–ウィシャート事前分布
$$
p(\boldsymbol{\mu}, \mathbf{\Lambda}) = \prod_{k=1}^{K} \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{0},\left(\beta_{0} \mathbf{\Lambda}_{k}\right)^{-1}\right) \mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{0}, \nu_{0}\right) \tag{10.40}
$$
を用いて

$$
\begin{aligned}
\mathbb{E}[\ln p(\boldsymbol{\mu}, \mathbf{\Lambda})] &=\mathbb{E}\left[\ln \left[\prod_{k=1}^{K} \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{0},\left(\beta_{0} \mathbf{\Lambda}_{k}\right)^{-1}\right) \mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{0}, \nu_{0}\right)\right]\right] \\
&=\mathbb{E}\left[\sum_{k=1}^{K} \ln \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{0},\left(\beta_{0} \mathbf{\Lambda}_{k}\right)^{-1}\right)\right]+\mathbb{E}\left[\sum_{k=1}^{K} \ln \mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{0}, \nu_{0}\right)\right] \\
&=\sum_{k=1}^{K} \mathbb{E}\left[-\frac{D}{2} \ln (2 \pi)+\frac{1}{2} \ln \left|\beta_{0} \mathbf{\Lambda}_{k}\right|-\frac{1}{2}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\left(\beta_{0} \mathbf{\Lambda}_{k}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)\right] \\
&+\sum_{k=1}^{K} \mathbb{E}\left[\ln B\left(\mathbf{W}_{0}, \nu_{0}\right)+\frac{\nu_{0}-D-1}{2} \ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2} \operatorname{Tr}\left[\mathbf{W}_{0}^{-1} \mathbf{\Lambda}_{k}\right]\right] \\
&=\frac{1}{2}\left\{\sum_{k=1}^{K} D \ln \left( \frac{\beta_{0}}{2 \pi} \right)+\mathbb{E}\left[\ln \left|\mathbf{\Lambda}_{k}\right|\right]-\mathbb{E}\left[\sum_{k=1}^{K}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\left(\beta_{0} \mathbf{\Lambda}_k\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)\right]\right\} \\
&+K \ln B\left(\mathbf{W}_{0}, \nu_{0}\right)+\frac{\nu_{0}-D-1}{2} \sum_{k=1}^{K} \mathbb{E}\left[\ln | \mathbf{\Lambda}_{k} | \right]-\frac{1}{2} \sum_{k=1}^{K} \mathbb{E}\left[\operatorname{Tr}\left[\mathbf{W}_{0}^{-1} \mathbf{\Lambda}_{k}\right]\right] \\
&=\frac{1}{2}\left\{\sum_{k=1}^{K} D \ln \left( \frac{\beta_{0}}{2 \pi} \right)+\ln \tilde{\Lambda}_{k}-\mathbb{E}\left[\sum_{k=1}^{K}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\left(\beta_{0} \mathbf{\Lambda}_k\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)\right]\right\} \\
&+K \ln B\left(\mathbf{W}_{0}, \nu_{0}\right)+\frac{\nu_{0}-D-1}{2} \sum_{k=1}^{K} \ln \tilde{\Lambda}_{k}-\frac{1}{2} \sum_{k=1}^{K} \mathbb{E}\left[\operatorname{Tr}\left[\mathbf{W}_{0}^{-1} \mathbf{\Lambda}_{k}\right]\right] \\
\end{aligned}
$$

$(10.74)$との係数を比較して、

$$
\mathbb{E}\left[\sum_{k=1}^{K}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\left(\beta_{0} \mathbf{\Lambda}_{k}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)\right]=\sum_{k=1}^{K}\left\{\frac{D \beta_{0}}{\beta_{k}}+\beta_{0} \nu_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\} \tag{*}$$
および
$$\sum_{k=1}^{K} \mathbb{E}_{\mathbf{\Lambda}_{k}}\left[\operatorname{Tr}\left[\mathbf{W}_{0}^{-1} \mathbf{\Lambda}_{k}\right]\right]=\sum_{k=1}^{K} \nu_{k} \operatorname{Tr}\left[\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right] \tag{**}
$$
であることを示せば良い。まず$(*)$について

$$
\begin{aligned}
\sum_{k=1}^{K} \mathbb{E}\left\{\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\left(\beta_{0} \mathbf{\Lambda}_{k}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)\right\} &=\beta_{0} \sum_{k=1}^{K} \mathbb{E}\left\{\operatorname{Tr}\left[\mathbf{\Lambda}_{k} \cdot\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\right]\right\} \\
&=\beta_{0} \sum_{k=1}^{K} \mathbb{E}_{\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}}\left\{\operatorname{Tr}\left[\mathbf{\Lambda}_{k} \cdot\left(\boldsymbol{\mu}_{k} \boldsymbol{\mu}_{k}^{\mathrm T}-2 \boldsymbol{\mu}_{k} \mathbf{m}_{0}^{\mathrm T}+\mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}\right)\right]\right\} \\
&=\beta_{0} \sum_{k=1}^{K} \mathbb{E}_{\mathbf{\Lambda}_{k}}\left\{\operatorname{Tr}\left[\mathbf{\Lambda}_{k} \cdot\left(\mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm T}+\beta_{k}^{-1} \mathbf{\Lambda}_{k}^{-1}-2 \mathbf{m}_{k} \mathbf{m}_{0}^{\mathrm T}+\mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}\right)\right]\right\} \\
&=\beta_{0} \sum_{k=1}^{K} \mathbb{E}_{\mathbf{\Lambda}_{k}}\left\{\operatorname{Tr}\left[\beta_{k}^{-1} \mathbf{I}+\mathbf{\Lambda}_{k} \cdot\left(\mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm T}-2 \mathbf{m}_{k} \mathbf{m}_{0}^{\mathrm T}+\mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm T}\right)\right]\right\} \\
&=\beta_{0} \sum_{k=1}^{K} \mathbb{E}_{\mathbf{\Lambda}_{k}}\left\{D \cdot \beta_{k}^{-1}+\operatorname{Tr}\left[\mathbf{\Lambda}_{k} \cdot\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\right]\right\} \\
&=\beta_{0} \sum_{k=1}^{K} \left\{\frac{D}{\beta_{k}}+\mathbb{E}_{\mathbf{\Lambda}_{k}}\operatorname{Tr}\left[\mathbf{\Lambda}_{k} \cdot\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\right]\right\} \\
&=\beta_{0} \sum_{k=1}^{K} \left\{\frac{D}{\beta_{k}}+\operatorname{Tr}\left[\mathbb{E}_{\mathbf{\Lambda}_{k}}\left[\mathbf{\Lambda}_{k}\right] \cdot\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\right]\right\} \\
&=\beta_{0} \sum_{k=1}^{K} \left\{\frac{D}{\beta_{k}}+\operatorname{Tr}\left[\nu_{k}\mathbf{W}_{k} \left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\right]\right\} \quad (\because (B.80))\\
&=\beta_{0} \sum_{k=1}^{K} \left\{\frac{D}{\beta_{k}}+\nu_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T} \mathbf{W}_{k} \left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\} \\
&=\sum_{k=1}^{K}\left\{\frac{D \beta_{0}}{\beta_{k}}+\beta_{0} \nu_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\}
\end{aligned}
$$

$(**)$について、

$$
\begin{aligned}
\mathbb{E}_{\mathbf{\Lambda}_{k}}\left[\operatorname{Tr}\left[\mathbf{W}_{0}^{-1} \mathbf{\Lambda}_{k}\right]\right] &=\operatorname{Tr}\left[\mathbf{W}_{0}^{-1} \cdot \mathbb{E}_{\mathbf{\Lambda}_{k}}[\mathbf{\Lambda}_{k}]\right] \\
&=\operatorname{Tr}\left[\mathbf{W}_{0}^{-1} \cdot \nu_{k} \mathbf{W}_{k}\right]\quad (\because (B .80)) \\
&=\nu_{k} \operatorname{Tr}\left[\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right]
\end{aligned}
$$

以上で$(10.74)$が示された。

<hr>

$$
\begin{aligned} \mathbb{E}\left[\ln q^{\star}(\mathbf{Z})\right] &=\mathbb{E}_{\mathbf{Z}}\left[\ln \left(\prod_{n=1}^{N} \prod_{k=1}^{K} r_{n k}^{z_{n k}}\right)\right] \quad(\because(10.48)) \\
&=\mathbb{E}_{\mathbf{Z}}\left[\sum_{n=1}^{N} \sum_{k=1}^{K} z_{n k} \ln r_{n k}\right] \\
&=\sum_{n=1}^{N} \sum_{k=1}^{K} \mathbb{E}_{\mathbf{Z}}\left[\mathbf{Z}_{n k}\right] \mathbb{E}_{z}\left[\ln r_{n k}\right] \\
&=\sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln r_{n k}
\end{aligned}
$$

<hr>

$$
\begin{aligned} \mathbb{E}\left[\ln q^{\star}(\pi)\right] &=\mathbb{E}_{\pi}[\ln (\operatorname{Dir}(\boldsymbol{\pi} \mid \boldsymbol{\alpha}))] \quad(\because(10.57)) \\
&=\mathbb{E}_{\pi}\left[\ln C(\boldsymbol{\alpha}) \prod_{k=1}^{K} \pi_{k}^{\alpha_{k}-1}\right](\because(B. 16)) \\
&=\mathbb{E}_{\pi}[\ln C(\boldsymbol{\alpha})]+\mathbb{E}_{\pi}\left[\sum_{k=1}^{K}\left(\alpha_{k}-1\right) \ln \pi_{k}\right] \\
&=\sum_{k=1}^{K}\left(\alpha_{k}-1\right) \ln \tilde{\pi}_{k}+\ln C(\boldsymbol{\alpha}) \end{aligned}
$$

<hr>

$$
\begin{aligned} \mathbb{E}\left[\ln q^{\star}(\boldsymbol{\mu}, \mathbf{\Lambda})\right]
&=\mathbb{E}_{\boldsymbol{\mu}_k, \mathbf{\Lambda}_k}\left[\ln \left[\prod_{k=1}^{K} q^{\star}\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right)\right]\right] \quad(\because(10.55)) \\
&=\mathbb{E}_{\boldsymbol{\mu}_k, \mathbf{\Lambda}_k}\left[\sum_{k=1}^{K} \ln q^{\star}\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right)\right] \\
& =\sum_{k=1}^{K} \mathbb{E}_{\boldsymbol{\mu}_k, \mathbf{\Lambda}_k}\left[\ln \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}\right)\right]+\sum_{k=1}^{K} \mathbb{E}_{\boldsymbol{\mu}_k, \mathbf{\Lambda}_k}\left[\ln \mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{k}, \nu_{k}\right)\right] \\
&= \sum_{k=1}^{K} \mathbb{E}_{\boldsymbol{\mu}_k, \mathbf{\Lambda}_k}\left\{-\frac{D}{2} \ln 2 \pi+\frac{D}{2} \ln \beta_{k}+\frac{1}{2} \ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{k}\right)^{\mathrm T}\left(\beta_{k} \mathbf{\Lambda}_{k}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{k}\right)\right\} \\
&+\sum_{k=1}^{K} \mathbb{E}_{\boldsymbol{\mu}_k, \mathbf{\Lambda}_k}\left\{\ln B\left(\mathbf{W}_{k}, \nu_{k}\right)+\frac{\nu_{k}-D-1}{2} \ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2} \operatorname{Tr}\left[\mathbf{W}_{k}^{-1} \mathbf{\Lambda}_{k}\right]\right\} \\
&= \sum_{k=1}^{K} \left\{ \frac{1}{2} \mathbb{E}_{\boldsymbol{\mu}_k, \mathbf{\Lambda}_k} \left[ \ln \left|\mathbf{\Lambda}_{k}\right| \right] + \frac{D}{2} \ln \left(\frac{\beta_{k}}{2\pi}\right) -\frac{1}{2} \operatorname{Tr}\left[\left(\beta_{k} \mathbf{\Lambda}_{k}\right)\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}\right] \right\} \\
&+\sum_{k=1}^{K} \mathbb{E}_{\boldsymbol{\mu}_k, \mathbf{\Lambda}_k}\left\{\ln B\left(\mathbf{W}_{k}, \nu_{k}\right)+\frac{\nu_{k}-D-1}{2} \ln \left|\mathbf{\Lambda}_{k}\right|-\frac{1}{2} \nu_{k} \operatorname{Tr}\left[\mathbf{W}_{k}^{-1} \mathbf{W}_{k}\right]\right\} \quad (\because 先述の(**)を利用) \\
&= \sum_{k=1}^{K} \left\{ \frac{1}{2} \ln \tilde{\Lambda}_{k} + \frac{D}{2} \ln \left(\frac{\beta_{k}}{2\pi}\right) -\frac{D}{2} \right\} +\sum_{k=1}^{K} \left\{\ln B\left(\mathbf{W}_{k}, \nu_{k}\right)+\frac{\nu_{k}-D-1}{2} \mathbb{E}_{\mathbf{\Lambda}_k}\ln \left|\mathbf{\Lambda}_{k}\right|-\frac{\nu_{k} D}{2}\right\}  \\
\end{aligned}
$$

途中でMatrix Cookbook (380)の公式
$$
\mathbb{E}_{\mathbf{x} \sim \mathcal{N}(\mathbf{x}\mid \mathbf{m}, \mathbf{\Sigma})}\left[\left(\mathbf{x}-\mathbf{m}^{\prime}\right)^{\mathrm T} \mathbf{A}\left(\mathbf{x}-\mathbf{m}^{\prime}\right)\right]=\left(\mathbf{m}-\mathbf{m}^{\prime}\right)^{\mathrm T} \mathbf{A}\left(\mathbf{m}-\mathbf{m}^{\prime}\right)+\operatorname{Tr}(\mathbf{A} \mathbf{\Sigma})
$$
を用いた。

$(\textrm{B}.82)$からウィシャート分布$\mathcal{W}(\mathbf{\Lambda} \mid \mathbf{W}, \nu)$のエントロピーは

$$
-\ln B(\mathbf{W}, \nu)-\frac{(\nu-D-1)}{2} \mathbb{E}[\ln |\mathbf{\Lambda}|]+\frac{\nu D}{2} \tag{B.82}
$$

であり、これを教科書P.196では$\mathrm{H}\left[q\left(\mathbf{\Lambda}_{k}\right)\right]$とおいているので、

$$
\mathbb{E}\left[\ln q^{\star}(\boldsymbol{\mu}, \mathbf{\Lambda})\right] =
\sum_{k=1}^{K} \left\{ \frac{1}{2} \ln \tilde{\Lambda}_{k} + \frac{D}{2} \ln \left(\frac{\beta_{k}}{2\pi}\right) -\frac{D}{2} - \mathrm{H}\left[q\left(\mathbf{\Lambda}_{k}\right)\right]\right\} \tag{10.77}
$$

となり$(10.77)$を得た。

## 演習 10.18

<div class="panel-primary">

この演習問題では，ガウス混合モデルでの変分ベイズ法の再推定を行う方程式を，下界を直接微分することで導出する．これを行うため，変分事後分布が
$$
q(\mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{\Lambda})=q(\mathbf{Z}) q(\boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{\Lambda}) \tag{10.42}
$$
と
$$
q(\boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{\Lambda})=q(\boldsymbol{\pi}) \prod_{k=1}^{K} q\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right) \tag{10.55}
$$
で定義されるように分解され，各因子が
$$
q^{\star}(\mathbf{Z})=\prod_{n=1}^{N} \prod_{k=1}^{K} r_{n k}^{z_{n k}} \tag{10.48}
$$
$$
q^{\star}(\boldsymbol{\pi})=\operatorname{Dir}(\boldsymbol{\pi} \mid \boldsymbol{\alpha}) \tag{10.57}
$$
$$
q^{\star}\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right)=\mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}\right) \mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{k}, \nu_{k}\right) \tag{10.59}
$$
で与えられることを仮定する．これらを
$$
\begin{aligned} \mathcal{L} &= \mathbb{E}[\ln p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \mathbf{\Lambda})]+\mathbb{E}[\ln p(\mathbf{Z} \mid \boldsymbol{\pi})]+\mathbb{E}[\ln p(\boldsymbol{\pi})]+\mathbb{E}[\ln p(\boldsymbol{\mu}, \mathbf{\Lambda})] \\ &-\mathbb{E}[\ln q(\mathbf{Z})]-\mathbb{E}[\ln q(\boldsymbol{\pi})]-\mathbb{E}[\ln q(\boldsymbol{\mu}, \mathbf{\Lambda})] \end{aligned} \tag{10.70}
$$
に代入し，下界を変分事後分布の持つパラメータの関数として与えよ．次にこの下界をパラメータに関して最大化することで，変分事後分布の因子を再推定する方程式を導出しこれらが10.2.1節で得たものと一致することを示せ．

</div>

※やろうとすることは変分ベイズ法の再推定式$(10.58)$とか$(10.60)–(10.63)$を変分下界$(10.70)$を用いることでも求められるということを示せばいい……のだが非常に計算が多い。

各因子が$(10.48),(10.57),(10.59)$のように表せる場合、10.2.2節で得た$(10.71)–(10.77)$の変分下界をまず$\mathcal{L}$に代入すると

$$
\begin{aligned} \mathcal{L} &= \mathbb{E}[\ln p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \mathbf{\Lambda})]+\mathbb{E}[\ln p(\mathbf{Z} \mid \boldsymbol{\pi})]+\mathbb{E}[\ln p(\boldsymbol{\pi})]+\mathbb{E}[\ln p(\boldsymbol{\mu}, \mathbf{\Lambda})] \\ &-\mathbb{E}[\ln q(\mathbf{Z})]-\mathbb{E}[\ln q(\boldsymbol{\pi})]-\mathbb{E}[\ln q(\boldsymbol{\mu}, \mathbf{\Lambda})] \\
&=\frac{1}{2} \sum_{k=1}^{K} N_{k}\left\{\ln \widetilde{\Lambda}_{k}-D \beta_{k}^{-1}-\nu_{k} \operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right)\right. \\ &-\left.\nu_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)-D \ln (2 \pi)\right\} \\
&+\sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln \widetilde{\pi}_{k} + \ln C\left(\boldsymbol{\alpha}_{0}\right)+\left(\alpha_{0}-1\right) \sum_{k=1}^{K} \ln \widetilde{\pi}_{k} \\
&+ \frac{1}{2} \sum_{k=1}^{K}\left\{D \ln \left(\beta_{0} / 2 \pi\right)+\ln \widetilde{\Lambda}_{k}-\frac{D \beta_{0}}{\beta_{k}}-\beta_{0} \nu_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\} \\
&+K \ln B\left(\mathbf{W}_{0}, \nu_{0}\right) +\frac{\left(\nu_{0}-D-1\right)}{2} \sum_{k=1}^{K} \ln \widetilde{\Lambda}_{k}-\frac{1}{2} \sum_{k=1}^{K} \nu_{k} \operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right) \\
&-\sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln r_{n k} - \sum_{k=1}^{K}\left(\alpha_{k}-1\right) \ln \tilde{\pi}_{k} - \ln C(\boldsymbol{\alpha}) \\
&-\sum_{k=1}^{K}\left\{\frac{1}{2} \ln \widetilde{\Lambda}_{k}+\frac{D}{2} \ln \left(\frac{\beta_{k}}{2 \pi}\right)-\frac{D}{2}-\mathrm{H}\left[q\left(\boldsymbol{\Lambda}_{k}\right)\right]\right\}
\end{aligned}
$$

$\mathcal{L}$を整理する。$\ln\widetilde{\Lambda}_k$,$\ln\widetilde{\pi}_k$,$\beta_k$,$\nu_k$の項に分ける。

$$
\begin{aligned}
\mathcal{L}=&\ \frac{1}{2} \sum_{k=1}^K N_{k}\left\{\ln \tilde{\Lambda}_{k}-D \beta_{k}^{-1}-\nu_{k} \operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right)-\nu_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)-D \ln (2 \pi)\right\} \\
&+\sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln \tilde{\pi}_{k}+\ln C\left(\boldsymbol{\alpha}_{0}\right)+\left(\alpha_{0}-1\right) \sum_{k=1}^{K} \ln \tilde{\pi}_{k} \\
&+\frac{1}{2} \sum_{k=1}^{K}\left\{D \ln \left(\frac{\beta_{0}}{2 \pi}\right)+\ln \tilde{\Lambda}_{k}-\frac{D \beta_0}{\beta_{k}}-\beta_{0} \nu_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\} \\
&+K \ln B\left(\mathbf{W}_{0}, \nu_{0}\right)+\frac{\nu_{0}-D-1}{2} \sum_{k=1}^{K} \ln \tilde{\Lambda}_{k}-\frac{1}{2} \sum_{k=1}^{K} \nu_{k} \operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right) \\
&-\sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln r_{n k}-\sum_{k=1}^{K}\left(\alpha_{k}-1\right) \ln \widetilde{\pi}_{k}-\ln C(\boldsymbol{\alpha}) \\
&-\sum_{k=1}^{K}\left\{\frac{1}{2} \ln \tilde{\Lambda}_{k}+\frac{D}{2} \ln \left(\frac{\beta_{k}}{2 \pi}\right)-\frac{D}{2}+\ln B\left(\mathbf{W}_{k}, \nu_{k}\right)+\frac{\nu_{k}-D-1}{2} \ln \tilde{\Lambda}_{k}-\frac{\nu_{k} D}{2}\right\} \\
=&\ \frac{1}{2} \sum_{k=1}^{K} \ln \tilde{\Lambda}_{k}\left\{N_{k}+1+\left(\nu_{0}-D-1\right)-1-\left(\nu_{k}-D-1\right)\right\} \\
&+\sum_{k=1}^{K} \ln \tilde{\pi}_{k}\left\{\sum_{n=1}^{N} r_{n k}+\left(\alpha_{0}-1\right)-\left(\alpha_{k}-1\right)\right\} \\
&+\frac{1}{2} \sum_{k=1}^{K}\left\{\beta_{k}^{-1}\left(-N_{k} D-D \beta_{0}\right)-D \ln \left(\frac{\beta_{k}}{2 \pi}\right)\right\} \\
&+\frac{1}{2} \sum_{k=1}^{K} N_{k}\left\{-\nu_{k} \operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right)-\nu_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\right\} \\
&+\frac{1}{2} \sum_{k=1}^{K}\left\{-\nu_{k} \operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right)-\beta_{0} \nu_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\} \\
&-\sum_{k=1}^{K}\left\{\ln B\left(\mathbf{W}_{k}, \nu_{k}\right)-\frac{\nu_{k} D}{2}\right\} \\
&-\frac{1}{2} \sum_{k=1}^{K} N_{k} D \ln (2 \pi)+\ln C\left(\boldsymbol{\alpha}_{0}\right)+\frac{1}{2} \sum_{k=1}^{K} D \ln \left(\frac{\beta_{0}}{2 \pi}\right)+K \ln B\left(\mathbf{W}_{0}, \nu_{0}\right) \\
&-\sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln r_{n k}-\ln C(\boldsymbol{\alpha})-\sum_{k=1}^{K}\left(-\frac{D}{2}\right) \\
=&\ \frac{1}{2} \sum_{k=1}^{K} \ln \tilde{\Lambda}_{k}\left(N_{k}+\nu_{0}-\nu_{k}\right) \\
&+\sum_{k=1}^{K} \ln \tilde{\pi}_{k}\left(N_{k}+\alpha_{0}-\alpha_{k}\right) \\
&-\frac{D}{2} \sum_{k=1}^{K}\left\{\beta_{k}^{-1}\left(N_{k}+\beta_{0}\right)+\ln \left(\frac{\beta_{k}}{2 \pi}\right)\right\} \\
&-\frac{1}{2} \sum_{k=1}^{K} N_{k} \nu_{k}\left\{\operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right)+\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\right\} \\
&-\frac{1}{2} \sum_{k=1}^{K} \nu_{k}\left\{\operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right)+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\} \\
&-\sum_{k=1}^{K}\left\{\ln B\left(\mathbf{W}_{k}, \nu_{k}\right)-\frac{\nu_{k} D}{2}\right\} \\
&-\sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln r_{n k}-\ln C(\boldsymbol{\alpha}) \\
&-\frac{1}{2} N D \ln (2 \pi)+\ln C\left(\boldsymbol{\alpha}_{0}\right)+\frac{1}{2} K D \ln \left(\frac{B_{0}}{2 \pi}\right)+K \ln B\left(\mathbf{W}_{0}, \nu_{0}\right)+\frac{D K}{2}
\end{aligned}
$$

$\mathcal{L}$の停留条件からパラメータの更新式を得る。パラメータはEステップで決めるパラメータ$r_{nk}$とMステップで決める$\alpha_k, \beta_k, \mathbf{m}_k, \mathbf{W}_k,\nu_{k}$。

$\alpha_k$について、$\mathcal{L}$の$\alpha_k$についての停留条件から更新式$(10.58)$を得ることを示す。

$$
\begin{aligned}
\frac{\partial \alpha}{\partial \alpha_{k}}
&=\frac{\partial}{\partial \alpha_{k}}\left\{\sum_{k=1}^{K} \ln \tilde{\pi}_{k}\left(N_{k}+\alpha_{0}-\alpha_{t}\right)-\ln C(\boldsymbol{\alpha})\right\} \\
&=\frac{\partial}{\partial \alpha_{k}}\left\{\sum_{k=1}^{K}(\underbrace{\psi\left(\alpha_{k}\right)-\psi(\hat{\alpha})}_{(10.66)})\left(N_{k}+\alpha_{0}-\alpha_{k}\right)-\underbrace{\ln \Gamma(\hat{\alpha})+\sum_{k=1}^{K} \ln \Gamma\left(\alpha_{k}\right)}_{(B .23)}\right\}
\end{aligned}
$$

$(B.24)$にあるように、$\displaystyle \widehat{\alpha} = \sum_{k=1}^{K}\alpha_k$である。$\displaystyle \frac{\partial \mathcal{L}}{\partial \alpha_k}=0$のとき

$$
\begin{aligned}
0 =&\ \left\{\frac{\partial}{\partial \alpha_{k}} \psi\left(\alpha_{k}\right)\left(N_{k}+\alpha_{0}-\alpha_{k}\right)-\psi\left(\alpha_{k}\right)-\frac{\partial \hat{\alpha}}{\partial \alpha_{k}} \frac{\partial \psi(\hat{\alpha})}{\partial \hat{\alpha}}\left(N_{k}+\alpha_{0}-\alpha_{k}\right)+\psi(\hat{\alpha})\right\} \\
&-\frac{\partial \hat{\alpha}}{\partial \alpha_{k}} \frac{\partial}{\partial \hat{\alpha}} \ln \Gamma(\hat{\alpha})+\frac{\partial}{\partial \alpha_{k}} \ln \Gamma\left(\alpha_{k}\right) \\
=&\ \frac{\partial \psi\left(\alpha_{k}\right)}{\partial \alpha_{k}}\left(N_{k}+\alpha_{0}-\alpha_{k}\right)-\frac{\partial \psi(\hat{\alpha})}{\partial \hat{\alpha}}\left(N_{k}+\alpha_{0}-\alpha_{k}\right)-\psi\left(\alpha_{k}\right)+\psi(\hat{\alpha}) \\
&-\psi(\hat{\alpha})+\psi\left(\alpha_{k}\right) \\
=&\ \left(N_{k}+\alpha_{0}-\alpha_{k}\right)\left(\frac{\partial \psi\left(\alpha_{k}\right)}{\partial \alpha_{k}}-\frac{\partial \psi(\hat{\alpha})}{\partial \hat{\alpha}}\right)
\end{aligned}
$$

よって停留条件は$N_k+\alpha_0-\alpha_k = 0$、すなわち

$$
\alpha_k = \alpha_0 + N_k \tag{10.58}
$$

である。

----

$\beta_{k}$について停留条件を求める。

$$
\begin{aligned} \frac{\partial \mathcal{L}}{\partial \beta_{k}}
&=-\frac{D}{2} \frac{\partial}{\partial \beta_{k}}\left\{\beta_{k}^{-1}\left(N_{k}+\beta_{0}\right)+\ln \beta_{k}-\ln (2 \pi)\right\} \\
&=-\frac{D}{2}\left(-\frac{N_{k}+\beta_{0}}{\beta_{k}^{2}}+\frac{1}{\beta_{k}}\right) \\ &=\frac{D}{2 \beta_{k}^{2}}\left(N_{k}+\beta_{0}-\beta_{k}\right)=0
\end{aligned}
$$

以上から

$$
\beta_{k} =\beta_{0} +N_{k} \tag{10.60}
$$

のとき停留する。

----

$\mathbf{m}_{k}$について停留条件を求める。

$$
\begin{aligned} \frac{\partial \mathcal{L}}{\partial \mathbf{m}_{k}}
=&\ \frac{\partial}{\partial \mathbf{m}_{k}}\left\{-\frac{1}{2} N_{k} \nu_{k}\left(\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\right)\right.\\ &\left.-\frac{1}{2} \nu_{k} \beta_{0}\left(\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right)\right\} \\
=&\ N_{k} \nu_{k} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)-\nu_{k} \beta_{0} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right) \\
=&\ \nu_{k} \mathbf{W}_{k}\left\{N_{k} \overline{\mathbf{x}}_{k}+\beta_{0} \mathbf{m}_{0}-\left(N_{k}+\beta_{0}\right) \mathbf{m}_{k}\right\}=0
\end{aligned}
$$

以上から

$$
\mathbf{m}_{k}=\frac{N_{k} \overline{\mathbf{x}}_{k}+\beta_{0} \mathbf{m}_{0}}{N_{k}+\beta_{0}}=\frac{N_{k} \overline{\mathbf{x}}_{k}+\beta_{0} \mathbf{m}_{0}}{\beta_{k}} \tag{10.61}
$$

のとき停留する。

----

$\nu_k$について、

$$
\begin{aligned}
\mathcal{L}=&\ \frac{1}{2} \sum_{k=1}^{K}\left\{\sum_{i=1}^{D}\psi\left(\frac{\nu_{k}+1-i}{2}\right)+D \ln 2+\ln \left|\mathbf{W}_{k}\right|\right\}\left(N_{k}+\nu_{0}-\nu_{k}\right) \\
&-\frac{1}{2} \sum_{k=1}^{K} N_{k} \nu_{k}\left\{\operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right)+\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\right\} \\
&-\frac{1}{2} \sum_{k=1}^{K} \nu_{k}\left\{\operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right)+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\} \\
&-\sum_{k=1}^{K} \left\{ \ln B\left(\mathbf{W}_{k}, \nu_{k}\right) - \frac{\nu_{k}D}{2} \right\}+\text {const.} \\
=&\ \frac{1}{2} \sum_{k=1}^{K}\left\{\sum_{i=1}^{D}\psi\left(\frac{\nu_{k}+1-i}{2}\right)+D \ln 2+\ln \left|\mathbf{W}_{k}\right|\right\}\left(N_{k}+\nu_{0}-\nu_{k}\right) \\
&-\frac{1}{2} \sum_{k=1}^{K} N_{k} \nu_{k}\left\{\operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right)+\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\right\} \\
&-\frac{1}{2} \sum_{k=1}^{K} \nu_{k}\left\{\operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right)+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\} \\
&-\sum_{k=1}^{K} \left\{ \ln |\mathbf{W}_{k}|^{-\nu_{k} / 2} - \ln \left(2^{\frac{\nu_{k} D}{2}} \pi^{D(D-1) / 4} \prod_{i=1}^{D} \Gamma\left(\frac{\nu_{k}+1-i}{2}\right)\right) - \frac{\nu_{k}D}{2}\right\}+\text {const.}
\end{aligned}
$$

停留条件は

$$
\begin{aligned} \frac{\partial \mathcal{L}}{\partial \nu_{k}}=&\ \frac{1}{2}\left\{\sum_{i=1}^{D} \frac{\partial}{\partial \nu_{k}} \psi\left(\frac{\nu_{k}+1-i}{2}\right)\right\}\left(N_{k}+\nu_{0}-\nu_{k}\right) \\ &-\frac{1}{2}\left\{\sum_{i=1}^{D} \psi\left(\frac{\nu_{k}+1-i}{2}\right)+D \ln 2+\ln \left|\mathbf{W}_{k}\right|\right\} \\
&-\frac{1}{2} N_{k}\left(\operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right)+\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\right) \\
&-\frac{1}{2}\left\{\operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right)+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\} \\
&-\left\{-\frac{1}{2} \ln \left|\mathbf{W}_{k}\right|-\frac{D}{2} \ln 2-\sum_{i=1}^{D} \underbrace{\frac{1}{2} \psi\left(\frac{\nu_{k}+1-i}{2}\right)}_{(B .25)}\right\}+\frac{D}{2} \\
=&\ \frac{1}{2} \sum_{i=1}^{D} \frac{\partial}{\partial \nu_{k}} \psi\left(\frac{\nu_{k}+1-i}{2}\right)\left(N_{k}+\nu_{0}-\nu_{k}\right) \\
&-\frac{1}{2} N_{k}\left(\operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right)+\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\right) \\
&-\frac{1}{2}\left\{\operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right)+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\}+\frac{D}{2}
\end{aligned}
$$

$\displaystyle \frac{\partial \mathcal{L}}{\partial \nu_{k}} = 0$は

$$
\begin{aligned}
& \sum_{i=1}^{D} \frac{\partial}{\partial \nu_{k}} \psi\left(\frac{\nu_{k}+1-i}{2}\right)\left(N_{k}+\nu_{0}-\nu_{k}\right) \\
&-\operatorname{Tr}\left\{\left(N_{k} \mathbf{S}_{k}+N_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}}+\mathbf{W}_{0}^{-1}+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}}\right) \mathbf{W}_{k}\right\} \\
&+D=0\end{aligned}
$$

のときに成立する。よってこれを簡単にしていく。$\operatorname{Tr}()$の中について

$$
\begin{aligned}
& N_{k} \mathbf{S}_{k}+N_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}}+\mathbf{W}_{0}^{-1}+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \\
=&\ N_{k} \mathbf{S}_{k}+N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}}-N_{k} \overline{\mathbf{x}}_{k} \mathbf{m}_{k}^{\mathrm{T}}-N_{k} \mathbf{m}_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}}+N_{k} \mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm{T}}+w_{0}^{-1}+\beta_{0} \mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm{T}}-\beta_{0} \mathbf{m}_{k} \mathbf{m}_{0}^{\mathrm{T}}-\beta_{0} \mathbf{m}_{0} \mathbf{m}_{k}^{\mathrm{T}}+\beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm{T}} \\
=&\ \mathbf{W}_{0}^{-1}+N_{k} \mathbf{S}_{k}+N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}}-\left(N_{k} \overline{\mathbf{x}}_{k}+\beta_{0} \mathbf{m}_{0}\right) \mathbf{m}_{k}^{\mathrm{T}}-\mathbf{m}_{k}\left(N_{k} \overline{\mathbf{x}}_{k}+\beta_{0} \mathbf{m}_{0}\right)^{\mathrm{T}}+\left(N_{k}+\beta_{0}\right) \mathbf{m}_{k} \mathbf{m}_{k}^{\mathrm{T}}+\beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm{T}}\\
=&\ \mathbf{W}_{0}^{-1}+N_{k} \mathbf{S}_{k}+N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}}-\frac{1}{N_{k}+\beta_{0}}\left(N_{k} \overline{\mathbf{x}}_{k}+\beta_{0} \mathbf{m}_{0}\right)\left(N_{k} \overline{\mathbf{x}}_{k}+\beta_{0} \mathbf{m}_{0}\right)^{\mathrm T}+\beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm{T}} \left(\because \mathbf{m}_{k}=\frac{1}{N_{k}+\beta_{0}}\left(N_{k} \overline{\mathbf{x}}_{k}+\beta_{0} \mathbf{m}_{0}\right) \right) \\
=&\ \mathbf{W}_{0}^{-1}+N_{k} \mathbf{S}_{k}+\frac{1}{N_{k}+\beta_{0}}\left\{\left(N_{k}+\beta_{0}\right) N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}}-N_{k}^{2} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}}-N_{k} \beta_{0} \overline{\mathbf{x}}_{k} \mathbf{m}_{0}^{\mathrm{T}}-\beta_{0} N_{k} \mathbf{m}_{0} \overline{\mathbf{x}}_{k}^{\mathrm{T}}-\beta_{0}^{2} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm{T}}+\left(N_{k}+\beta_{0}\right) \beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm{T}}\right\} \\
=&\ \mathbf{W}_{0}^{-1}+N_{k} \mathbf{S}_{k}+\frac{N_{k} \beta_{0}}{N_{k}+\beta_{0}}\left(\overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}}-\overline{\mathbf{x}}_{k} \mathbf{m}_{0}^{\mathrm{T}}-\mathbf{m}_{0} \overline{\mathbf{x}}_{k}^{\mathrm{T}}+\mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm{T}}\right) \\
=&\ \mathbf{W}_{0}^{-1}+N_{k} \mathbf{S}_{k}+\frac{N_{k} \beta_{0}}{N_{k}+\beta_{0}}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{0}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \\
=&\ \frac{N_{k}+\nu_{0}}{\nu_{k}}\mathbf{W}_{k}^{-1}
\end{aligned}
$$

これより停留条件を書き直すと

$$
\begin{aligned}
\sum_{i=1}^{D} \frac{\partial}{\partial \nu_{k}} \psi\left(\frac{\nu_{k}+1-i}{2}\right)\left(N_{k}+\nu_{0}-\nu_{k}\right) - \operatorname{Tr}\left\{ \frac{N_{k}+\nu_{0}}{\nu_{k}}\mathbf{W}_{k}^{-1}\mathbf{W}_{k} \right\} + D = 0 \\
\sum_{i=1}^{D} \frac{\partial}{\partial \nu_{k}} \psi\left(\frac{\nu_{k}+1-i}{2}\right)\left(N_{k}+\nu_{0}-\nu_{k}\right) - \frac{N_{k}+\nu_{0}}{\nu_{k}} D + D = 0 \\
\sum_{i=1}^{D} \frac{\partial}{\partial \nu_{k}} \psi\left(\frac{\nu_{k}+1-i}{2}\right)\left(N_{k}+\nu_{0}-\nu_{k}\right) - \frac{D}{\nu_{k}}\left( N_{k} + \nu_{0} - \nu_{k} \right) = 0 \\
\end{aligned}
$$

以上から

$$
\nu_{k} = \nu_{0} + N_{k} \tag{10.63}
$$

のとき停留する。

----

$\mathbf{W}_k$について、

$$
\ln \widetilde{\Lambda}_{k} \equiv \mathbb{E}\left[\ln \left|\mathbf{\Lambda}_{k}\right|\right]=\sum_{i=1}^{D} \psi\left(\frac{\nu_{k}+1-i}{2}\right)+D \ln 2+\ln \left|\mathbf{W}_{k}\right| \tag{10.65}
$$

を用いて計算する

$$
\begin{aligned}
\mathcal{L}=&\ \frac{1}{2} \sum_{k=1}^{K}\left\{\sum_{i=1}^{D}\psi\left(\frac{\nu_{k}+1-i}{2}\right)+D \ln 2+\ln \left|\mathbf{W}_{k}\right|\right\}\left(N_{k}+\nu_{0}-\nu_{k}\right) \\
&-\frac{1}{2} \sum_{k=1}^{K} N_{k} \nu_{k}\left\{\operatorname{Tr}\left(\mathbf{S}_{k} \mathbf{W}_{k}\right)+\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\right\} \\
&-\frac{1}{2} \sum_{k=1}^{K} \nu_{k}\left\{\operatorname{Tr}\left(\mathbf{W}_{0}^{-1} \mathbf{W}_{k}\right)+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\right\} \\
&-\sum_{k=1}^{K} \ln B\left(\mathbf{W}_{k}, \nu_{k}\right)+\text {const.}
\end{aligned}
$$

停留条件は、$\mathbf{S}_{k}^{\mathrm T} = \mathbf{S}_{k}, \mathbf{W}_{k}^{\mathrm T} = \mathbf{W}_{k}$である（対称行列）ことに注意して

$$
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial \mathbf{W}_{k}}
=&\ \frac{1}{2} \underbrace{\mathbf{W}_{k}^{-1}}_{(C.28)} \left(N_{k}+\nu_{0}-\nu_{k}\right) \\
&-\frac{1}{2} N_{k} \nu_{k}\left\{\mathbf{S}_{k}+\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}}\right\} \\
&-\frac{1}{2} \nu_{k}\left\{\mathbf{W}_{0}^{-1}+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}}\right\} \\
&+\frac{\nu_{k}}{2}\mathbf{W}_{k}^{-1} \\
=&\ 0
\end{aligned}
$$

これより

$$
\begin{aligned}
&\ \mathbf{W}_{k}^{-1}\left(N_{k}+\nu_{0}\right)-N_{k} \nu_{k}\left\{\mathbf{S}_{k} +\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T}\right\} \\
&-\nu_{k}\left\{w_{0}^{-1}+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\right\} = 0
\end{aligned}
$$

$$
\begin{aligned}
\therefore \mathbf{W}_{k}^{-1}
&=\frac{\nu_{k}}{N_{k}+\nu_{0}} \mathbf{W}_{0}^{-1}+\frac{N_{k} \nu_{k}}{N_{k}+\nu_{0}} \mathbf{S}_{k}+\frac{N_{k} \nu_{k}}{N_{k}+\nu_{0}}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T}+\frac{\nu_{k} \beta_{0}}{N_{k}+\nu_{0}}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T} \\
&=\frac{\nu_{k}}{N_{k}+\nu_{0}}\left\{\mathbf{W}_{0}^{-1}+N_{k} \mathbf{S}_{k}+N_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T}+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\right\} \\
&=\mathbf{W}_{0}^{-1}+N_{k} \mathbf{S}_{k}+N_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm T}+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm T}\ (\because \nu_{k}の停留条件 \nu_{k} = \nu_{0} + N_{k}) \\
&=\mathbf{W}_{0}^{-1}+N_{k} \mathbf{S}_{k}+\frac{N_{k}\beta_{0}}{\beta_{0}+N_{k}}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{0}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}}\hspace{1em}(10.62)
\end{aligned}
$$

となり、$\mathbf{W}_{k}^{-1}$の更新式を得た。ただし最後の変形は

$$
\begin{aligned}
&\ N_{k}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{k}\right)^{\mathrm{T}}+\beta_{0}\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)\left(\mathbf{m}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \\
=&\ N_{k} \overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}}-N_{k} \overline{\mathbf{x}}_{k} \frac{\left(\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}\right)^{\mathrm{T}}}{\beta_{0}+N_{k}}-\frac{\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}}{\beta_{0}+N_{k}} N_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}} \\
& +\frac{N_{k}\left(\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}\right)\left(\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}\right)^{\mathrm{T}}}{\left(\beta_{0}+N_{k}\right)^{2}}+\frac{\beta_{0}\left(\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}\right)\left(\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}\right)^{\mathrm{T}}}{\left(\beta_{0}+N_{k}\right)^{2}} \\
& -\beta_{0} \mathbf{m}_{0} \frac{\left(\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}\right)^{\mathrm{T}}}{\beta_{0}+N_{k}}-\frac{\beta_{0} \mathbf{m}_{0}+N_{k} \overline{\mathbf{x}}_{k}}{\beta_{0}+N_{k}} \beta_{0}\mathbf{m}_{0}^{\mathrm{T}}+\beta_{0} \mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm{T}} \\
=& \left( N_{k}-\frac{N_{k}^{2}}{\beta_{0}+N_{k}}-\frac{N_{k}^{2}}{\beta_{0}+N_{k}}+\frac{N_{k}^{3}}{\left(\beta_{0}+N_{k}\right)^{2}}+\frac{\beta_{0} N_{k}^{2}}{\left(\beta_{0}+N_{k}\right)^{2}} \right)\overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}} \\
& +\left( -\frac{N_{k} \beta_{0}}{\beta_{0}+N_{k}}+\frac{\beta_{0} N_{k}^{2}}{\left(\beta_{0}+N_{k}\right)^{2}}+\frac{\beta_{0}^{2} N_{k}}{\left(\beta_{0}+N_{k}\right)^{2}}-\frac{N_{k} \beta_{0}}{\beta_{0}+N_{k}} \right)\overline{\mathbf{x}}_{k}\mathbf{m}_{0}^{\mathrm{T}} \\
& +\left( -\frac{N_{k} \beta_{0}}{\beta_{0}+N_{k}}+\frac{\beta_{0} N_{k}^{2}}{\left(\beta_{0}+N_{k}\right)^{2}}+\frac{\beta_{0}^{2} N_{k}}{\left(\beta_{0}+N_{k}\right)^{2}}-\frac{N_{k} \beta_{0}}{\beta_{0}+N_{k}} \right)\mathbf{m}_{0}\overline{\mathbf{x}}_{k}^{\mathrm{T}} \\
& +\left( \frac{N_{k} \beta_{0}^{2}}{\left(\beta_{0}+N_{k}\right)^{2}}+\frac{\beta_{0}^{3}}{\left(\beta_{0}+N_{k}\right)^{2}}-\frac{2 \beta_{0}^{2}}{\beta_{0}+N_{k}}+\beta_{0} \right)\mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm{T}} \\
=&\ \frac{N_{k}\beta_{0}}{\beta_{0}+N_{k}}\overline{\mathbf{x}}_{k} \overline{\mathbf{x}}_{k}^{\mathrm{T}} - \frac{N_{k}\beta_{0}}{\beta_{0}+N_{k}}\overline{\mathbf{x}}_{k}\mathbf{m}_{0}^{\mathrm{T}} - \frac{N_{k}\beta_{0}}{\beta_{0}+N_{k}}\mathbf{m}_{0}\overline{\mathbf{x}}_{k}^{\mathrm{T}} + \frac{N_{k}\beta_{0}}{\beta_{0}+N_{k}}\mathbf{m}_{0} \mathbf{m}_{0}^{\mathrm{T}} \\
=&\ \frac{N_{k}\beta_{0}}{\beta_{0}+N_{k}}\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{0}\right)\left(\overline{\mathbf{x}}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}}
\end{aligned}
$$

を用いた。

## 演習 10.19
<div class="panel-primary">

ベイズ混合ガウスモデルの変分ベイズ法における予測分布
$$p(\widehat{\mathrm{x}} \mid \mathbf{X}) \simeq \frac{1}{\widehat{\alpha}} \sum_{k=1}^{K} \alpha_{k} \operatorname{St}\left(\widehat{\mathbf{x}} \mid \mathbf{m}_{k}, \mathbf{L}_{k}, \nu_{k}+1-D\right) \tag{10.81}$$
を導出せよ．

</div>

P.197の$(10.81)$式の導出を行うためにこの節での手順を一から踏む。

$$
p(\mathbf{Z} \mid \pi)=\prod_{n=1}^{N} \prod_{k=1}^{K} \pi_{k}^{z_{n k}} \tag{10.37}
$$
$$
p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \boldsymbol{\Lambda})=\prod_{n=1}^{N} \prod_{k=1}^{K} \mathcal{N}\left(\mathbf{x}_{n} \mid \boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}^{-1}\right)^{z_{n k}} \tag{10.38}
$$

データセット$\mathbf{X}$に対する新しい観測値$\mathbf{\hat{x}}$の予測分布についてこれに対応する潜在分布$\mathbf{\hat{z}}$が存在し、よって予測分布はしたがって以下で与えられる（純粋なベイズの定理・周辺化を用いた）。

$$
p(\widehat{\mathbf{x}} \mid \mathbf{X})=\sum_{\widehat{\mathbf{z}}} \iiint p(\widehat{\mathbf{x}} \mid \widehat{\mathbf{z}}, \boldsymbol{\mu}, \boldsymbol{\Lambda}) p(\widehat{\mathbf{z}} \mid \pi) p(\boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol{\Lambda} \mid \mathbf{X}) \mathrm{d} \boldsymbol{\pi} \mathrm{d} \boldsymbol{\mu} \mathrm{d} \boldsymbol{\Lambda} \tag{10.78}
$$

$(10.37)$と$(10.38)$を代入して、

$$
p(\widehat{\mathbf{x}} \mid \mathbf{X})=\sum_{k=1}^{K} \iiint \pi_{k} \mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}^{-1}\right) p(\boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol{\Lambda} \mid \mathbf{X}) \mathrm{d} \boldsymbol{\pi} \mathrm{d} \boldsymbol{\mu} \mathrm{d} \boldsymbol{\Lambda} \tag{10.79}
$$

となる。真の事後分布$p(\boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol{\Lambda} \mid \mathbf{X})$を変分近似で置き換える。このとき

$$
q(\boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol{\Lambda})=q(\boldsymbol{\pi}) \prod_{j=1}^{K} q\left(\boldsymbol{\mu}_{j}, \boldsymbol{\Lambda}_{j}\right) \tag{10.55}
$$

を用いて、和$\displaystyle \sum_{k=1}^{K}$のうち1つの項に注目する（＝$k$を固定する）。$j\neq k$であるような$j$についての$\displaystyle \int d\mu_{j}\int d\Lambda_{j}$を考えると、積分の中身は$\displaystyle \int q(\boldsymbol{\mu}_{j}, \boldsymbol{\Lambda}_{j})d\boldsymbol{\mu}_{j}d\boldsymbol{\Lambda}_{j} = 1$（確率の定義より）となるので、$k$番目の積分$\displaystyle \int d\mu_{k}\int d\Lambda_{k}$しか残らない。これより

$$
\begin{aligned}
p(\widehat{\mathbf{x}} \mid \mathbf{X}) &=\sum_{k=1}^{K} \iiint \pi_{k} \mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}^{-1}\right) p(\boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol{\Lambda} \mid \mathbf{X}) \mathrm{d} \boldsymbol{\pi} \mathrm{d} \boldsymbol{\mu} \mathrm{d} \boldsymbol{\Lambda} \\
&\simeq \sum_{k=1}^{K} \iiint \pi_{k} \mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}^{-1}\right) q(\boldsymbol{\pi}) q\left(\boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}\right) \mathrm{d} \boldsymbol{\pi} \mathrm{d} \boldsymbol{\mu}_{k} \mathrm{~d} \boldsymbol{\Lambda}_{k} \\
&=\sum_{k=1}^{K} \iiint \pi_{k} \mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}^{-1}\right) \underbrace{\operatorname{Dir}(\boldsymbol{\pi}\mid \boldsymbol{\alpha})}_{(10.57)} \underbrace{\mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \boldsymbol{\Lambda}_{k}\right)^{-1}\right) \mathcal{W}\left(\boldsymbol{\Lambda}_{k} \mid \mathbf{W}_{k}, \boldsymbol{\nu}_{k}\right)}_{(10.59)} \mathrm{d} \boldsymbol{\pi} \mathrm{d} \boldsymbol{\mu}_{k} \mathrm{d} \boldsymbol{\Lambda}_{k} \\
&=\sum_{k=1}^{K} \int\pi_{k} \operatorname{Dir}(\boldsymbol{\pi}\mid \boldsymbol{\alpha}) \mathrm{d} \boldsymbol{\pi} \int \left[ \int \mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}^{-1}\right) \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \boldsymbol{\Lambda}_{k}\right)^{-1}\right) \mathrm{d} \boldsymbol{\mu}_{k} \right]\mathcal{W}\left(\boldsymbol{\Lambda}_{k} \mid \mathbf{W}_{k}, \boldsymbol{\nu}_{k}\right) \mathrm{d} \boldsymbol{\Lambda}_{k} \cdots (\textrm{A})\\
\end{aligned}
$$

$\boldsymbol{\pi}$の積分に関係するのは$\pi_{k}\operatorname{Dir}(\boldsymbol{\pi}\mid \boldsymbol{\alpha})$のみで、$\int\pi_{k} \operatorname{Dir}(\boldsymbol{\pi}\mid \boldsymbol{\alpha}) \mathrm{d} \boldsymbol{\pi}$はディリクレ分布以下での$\pi_{k}$の期待値であるから

$$
\int\pi_{k} \operatorname{Dir}(\boldsymbol{\pi}\mid \boldsymbol{\alpha}) \mathrm{d} \boldsymbol{\pi} = \frac{\alpha_{k}}{\widehat{\alpha}}\ (\because{(B.17)})
$$

次に$\displaystyle \int \mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}^{-1}\right) \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \boldsymbol{\Lambda}_{k}\right)^{-1}\right) \mathrm{d} \boldsymbol{\mu}_{k}$について、これを

$$
\begin{aligned}
p\left(\boldsymbol{\mu}_{k}\right)&=\mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \boldsymbol{\Lambda}_{k}\right)^{-1}\right) \\
p\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}\right)&=\mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}^{-1}\right)
\end{aligned}
$$

とみなして$(2.115)$の公式を用いると

$$
\begin{aligned}
& \int \mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}^{-1}\right) \mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \boldsymbol{\Lambda}_{k}\right)^{-1}\right) d \boldsymbol{\mu}_{k} \\
=&\ \mathcal{N}\left(\widehat{\mathbf{x}} \mid \mathbf{m}_{k},\left(\boldsymbol{\Lambda}_{k}^{-1}+\beta_{k}^{-1} \boldsymbol{\Lambda}_{k}^{-1}\right)\right) \\
=&\ \mathcal{N}\left(\widehat{\mathbf{x}} \mid \mathbf{m}_{k},\left(1+\beta_{k}^{-1}\right) \boldsymbol{\Lambda}_{k}^{-1}\right) \end{aligned}
$$

となる。以上から$(\textrm{A})$式に戻ると

$$
\begin{aligned} p(\widehat{\mathbf{x}} \mid \mathbf{X})\simeq & \sum_{k=1}^{K} \frac{\alpha_{k}}{\widehat{\alpha}} \int \mathcal{N}\left(\widehat{\mathbf{x}} \mid \mathbf{m}_{k},\left(1+\beta_{k}^{-1}\right) \boldsymbol{\Lambda}_{k}^{-1}\right) \mathcal{W}\left(\boldsymbol{\Lambda}_{k} \mid \mathbf{W}_{k}, \nu_{k}\right) \mathrm{d} \boldsymbol{\Lambda}_{k} \\
=&\ \sum_{k=1}^{K} \frac{\alpha_{k}}{\widehat{\alpha}} \int \frac{1}{(2 \pi)^{D / 2}} \frac{\left|\boldsymbol{\Lambda}_{k}\right|^{1 / 2}}{\left(1+\beta_{k}^{-1}\right)^{D / 2}} \exp \left\{-\frac{\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}} \boldsymbol{\Lambda}_{k}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)}{2\left(1+\beta_{k}^{-1}\right)}\right\} \\ & B\left(\mathbf{W}_{k}, \nu_{k}\right)\left|\boldsymbol{\Lambda}_{k}\right|^{\left(\nu_{k}-D-1\right) / 2} \exp \left\{-\frac{1}{2} \operatorname{Tr}\left[\mathbf{W}_{k}^{-1} \boldsymbol{\Lambda}_{k}\right]\right\} \mathrm{d} \boldsymbol{\Lambda}_{k} \\
=&\ \sum_{k=1}^{K} \frac{\alpha_{k}}{\widehat{\alpha}} \int \frac{B\left(\mathbf{W}_{k}, \nu_{k}\right)}{(2 \pi)^{D / 2}} \frac{\left|\boldsymbol{\Lambda}_{k}\right|^{\left((\nu_{k}+1)-D-1\right) / 2}}{\left(1+\beta_{k}^{-1}\right)^{D / 2}} \exp \left\{-\frac{\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}} \boldsymbol{\Lambda}_{k}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)}{2\left(1+\beta_{k}^{-1}\right)}\right\}  \exp \left\{-\frac{1}{2} \operatorname{Tr}\left[\mathbf{W}_{k}^{-1} \boldsymbol{\Lambda}_{k}\right]\right\} \mathrm{d} \boldsymbol{\Lambda}_{k} \\
=&\ \sum_{k=1}^{K} \frac{\alpha_{k}}{\widehat{\alpha}} \int \frac{B\left(\mathbf{W}_{k}, \nu_{k}\right)}{(2 \pi)^{D / 2}} \frac{\left|\boldsymbol{\Lambda}_{k}\right|^{\left((\nu_{k}+1)-D-1\right) / 2}}{\left(1+\beta_{k}^{-1}\right)^{D / 2}} \exp \left\{-\frac{1}{2} \operatorname{Tr}\left[\left(\frac{\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}}}{1+\beta_{k}^{-1}}+\mathbf{W}_{k}^{-1}\right) \boldsymbol{\Lambda}_{k}\right]\right\} \mathrm{d} \boldsymbol{\Lambda}_{k} \\
=&\ \sum_{k=1}^{K} \frac{\alpha_{k}}{\widehat{\alpha}} \frac{B\left(\mathbf{W}_{k}, \nu_{k}\right)}{(2 \pi)^{D / 2} \left(1+\beta_{k}^{-1}\right)^{D / 2}}
\int \left|\boldsymbol{\Lambda}_{k}\right|^{\left((\nu_{k}+1)-D-1\right) / 2} \exp \left\{-\frac{1}{2} \operatorname{Tr}\left[\left(\frac{\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}}}{1+\beta_{k}^{-1}}+\mathbf{W}_{k}^{-1}\right) \boldsymbol{\Lambda}_{k}\right]\right\} \mathrm{d} \boldsymbol{\Lambda}_{k}
\end{aligned}
$$

ここで、$\int$の中身は

$$
\begin{aligned}
\mathbf{W^{\prime}}_{k}^{-1} &=\left(1+\beta_{k}^{-1}\right)^{-1}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}} + \mathbf{W}_{k}^{-1} \\
{\nu^{\prime}}_{k} &= \nu_{k}+1
\end{aligned}
$$

としたときのウィシャート分布$\mathcal{W}(\boldsymbol{\Lambda}_{k}\mid \mathbf{W^{\prime}}_{k}, {\nu^{\prime}}_{k})$となっているので、この積分結果は正規化定数である$B(\mathbf{W^{\prime}}_{k}, {\nu^{\prime}}_{k})$の逆数になることがわかる。すなわち

$$
p(\widehat{\mathbf{x}} \mid \mathbf{X}) \simeq \sum_{k=1}^{K} \frac{\alpha_{k}}{\widehat{\alpha}} \frac{1}{(2 \pi)^{D / 2} \left(1+\beta_{k}^{-1}\right)^{D / 2}}\frac{B\left(\mathbf{W}_{k}, \nu_{k}\right)}{B(\mathbf{W^{\prime}}_{k}, {\nu^{\prime}}_{k})} \tag{B}
$$

となる。この正規化定数部分をさらに展開していく。

$$
\begin{aligned}
\frac{B(\mathbf{W}_k,\nu_k)}{B(\mathbf{W^{\prime}}_{k},\nu_k+1)}
&=\frac{\left|\mathbf{W}_{k}\right|^{-\frac{\nu_{k}}{2}}\left(2^{\frac{\nu_{k} D}{2}} \pi^{\frac{D(D-1)}{4}} \prod_{i=1}^{D} \Gamma\left(\frac{\nu_{k}+1-i}{2}\right)\right)^{-1}}{\left|\mathbf{W}^{\prime}_{k}\right|^{-\frac{\nu_{k}+1}{2}}\left(2^{\frac{\left(\nu_{k}+1\right) D}{2}} \pi^{\frac{D(D-1)}{4}} \prod_{i=1}^{D} \Gamma\left(\frac{\nu_{k}+2-i}{2}\right)\right)^{-1}} ~~~(\because\ (B.79)) \\
&=\frac{\left|\mathbf{W}_{k}\right|^{-\frac{\nu_{k}}{2}}}{\left|\mathbf{W}^{\prime}_{k}\right|^{-\frac{\nu_{k}+1}{2}}} 2^{\frac{D}{2}} \frac{\prod_{i=1}^{D} \Gamma\left(\frac{\nu_{k}+2-i}{2}\right)}{\prod_{i=1}^{D} \Gamma\left(\frac{\nu_{k}+1-i}{2}\right)} \\
&=2^{D/2}\frac{\left|\mathbf{W}_{k}\right|^{-\frac{\nu_{k}}{2}}}{\left|\left\{\mathbf{W}_{k}^{-1}+\left(1+\beta_{k}^{-1}\right)^{-1}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}}\right\}^{-1}\right|^{-\frac{\nu_{k}}{2}}} \\
&~~~~\frac{\Gamma\left(\frac{\nu_{k}+1}{2}\right) \Gamma\left(\frac{\nu k}{2}\right) \Gamma\left(\frac{\nu_{k}-1}{2}\right) \cdots \Gamma\left(\frac{\nu_{k}+2-D}{2}\right)}{\Gamma\left(\frac{\nu k}{2}\right) \Gamma\left(\frac{\nu_{k}-1}{2}\right) \cdots \Gamma\left(\frac{\nu_{k}+2-D}{2}\right) \Gamma\left(\frac{\nu_{k}+1-D}{2}\right)} \\
&=2^{D/2}\left|\mathbf{W}_{k}\right|^{-\frac{\nu_{k}}{2}}\left|\mathbf{W}_{k}^{-1}\left\{\mathbf{I}+\mathbf{W}_{k}\left(1+\beta_{k}^{-1}\right)^{-1}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}}\right\}\right|^{-\frac{\nu_{k}+1}{2}}\frac{\Gamma\left(\frac{\nu_{k}+1}{2}\right)}{\Gamma\left(\frac{\nu_{k}+1-D}{2}\right)} \\
&=2^{D/2}\left|\mathbf{W}_{k}\right|^{1/2}\left|\mathbf{I}+\mathbf{W}_{k}\left(1+\beta_{k}^{-1}\right)^{-1}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}}\right|^{-\frac{\nu_{k}+1}{2}}\frac{\Gamma\left(\frac{\nu_{k}+1}{2}\right)}{\Gamma\left(\frac{\nu_{k}+1-D}{2}\right)} \\
&=2^{D/2}\left|\mathbf{W}_{k}\right|^{1/2}\left[1+\left\{\mathbf{W}_{k}\left(1+\beta_{k}^{-1}\right)^{-1}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\right\}^{\mathrm{T}}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\right]^{-\frac{\nu_{k}+1}{2}}\frac{\Gamma\left(\frac{\nu_{k}+1}{2}\right)}{\Gamma\left(\frac{\nu_{k}+1-D}{2}\right)} ~~ (\because (\textrm{C}.15))\\
&=2^{D/2}\left|\mathbf{W}_{k}\right|^{1/2}\left\{1+\left(1+\beta_{k}^{-1}\right)^{-1}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\right\}^{-\frac{\nu_{k}+1}{2}}\frac{\Gamma\left(\frac{\nu_{k}+1}{2}\right)}{\Gamma\left(\frac{\nu_{k}+1-D}{2}\right)}~~ (\because \mathbf{W}_{k}^{\mathrm T} = \mathbf{W}_{k})
\end{aligned}
$$

これを$(\textrm{B})$に代入して

$$
\begin{aligned}
p(\widehat{\mathbf{x}} \mid \mathbf{X}) &\simeq \sum_{k=1}^{K} \frac{\alpha_{k}}{\widehat{\alpha}} \frac{\Gamma\left(\frac{\nu_{k}+1}{2}\right)}{\Gamma\left(\frac{\nu_{k}+1-D}{2}\right)}\frac{\left|\mathbf{W}_{k}\right|^{1/2}}{\pi^{D / 2} \left(1+\beta_{k}^{-1}\right)^{D / 2}}\left\{1+\left(1+\beta_{k}^{-1}\right)^{-1}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{W}_{k}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\right\}^{-\frac{\nu_{k}+1}{2}} \\
&= \sum_{k=1}^{K} \frac{\alpha_{k}}{\widehat{\alpha}} \frac{\Gamma\left(\frac{\nu_{k}+1-D}{2} + \frac{D}{2}\right)}{\Gamma\left(\frac{\nu_{k}+1-D}{2}\right)}
\frac{\left|\frac{\nu_{k}+1-D}{1+\beta_{k}^{-1}}\mathbf{W}_{k}\right|^{1/2}}{\pi^{D / 2} \left(\nu_{k}+1-D\right)^{D / 2}} \\
&~~~~\left\{1+\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}} \left( \frac{1}{\nu_{k}+1-D}\frac{\nu_{k}+1-D}{1+\beta_{k}^{-1}}\mathbf{W}_{k} \right)\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)\right\}^{-\frac{\nu_{k}+1-D}{2} - \frac{D}{2}} \\
&= \sum_{k=1}^{K} \frac{\alpha_{k}}{\widehat{\alpha}} \frac{\Gamma\left(\frac{\nu_{k}+1-D}{2} + \frac{D}{2}\right)}{\Gamma\left(\frac{\nu_{k}+1-D}{2}\right)} \frac{\left|\mathbf{L}_{k}\right|^{1/2}}{\left\{\pi (\nu_{k}+1-D)\right\}^{D/2}}\left( 1 + \frac{\Delta^{2}}{\nu_{k}+1-D}\right)^{-\frac{\nu_{k}+1-D}{2} - \frac{D}{2}} \\
&= \frac{1}{\widehat{\alpha}}\sum_{k=1}^{K}\alpha_{k}\operatorname{St} \left( \widehat{\mathbf{x}} \mid \mathbf{m}_{k}, \mathbf{L}_{k}, \nu_{k}+1-D \right) ~~ (\because (\textrm{B}.68))
\end{aligned}
$$

となる。ここで、
$$
\mathbf{L}_{k} =\frac{\nu_{k}+1-D}{1+\beta_{k}^{-1}} \mathbf{W}_{k} = \frac{(\nu_{k}+1-D)\beta_{k}}{(1+\beta_{k})} \mathbf{W}_{k} \tag{10.82}
$$
$$
\Delta^{2} =\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)^{\mathrm{T}} \mathbf{L}_{k}\left(\widehat{\mathbf{x}}-\mathbf{m}_{k}\right)
$$

とした。これより$(10.81)$を得た。

## 演習 10.20

<div class="panel-primary">

この演習問題では，データ集合のサイズ$N$が大きくなった場合の混合ガウスモデルの変分ベイズ法による解を考え，これが(期待通り)9章のEMアルゴリズムに基づく最尤推定の解に近づくことを示す．この演習問題を解くには，付録Bの結果が有用であろう．最初に，精度の事後分布$q^{\star}(\mathbf{\Lambda}_k)$が最尤推定値の周囲に鋭い分布を持つことを示せ．平均の事後分布$q^{\star}(\boldsymbol{\mu}_k \mid \mathbf{\Lambda}_k)$についても同様のことを示せ．次に，混合比の事後分布$q^{\star}(\boldsymbol{\pi})$について考え，これも最尤推定値の周囲に鋭く分布することを示せ．同様に，大きな$N$については負担率は対応する最尤推定値と等しくなることを，大きな$x$についてのディガンマ関数の次の漸近的な結果

$$
\psi(x)=\ln x+O(1 / x)
$$

を利用して示せ．最後に

$$
p(\widehat{\mathbf{x}} \mid \mathbf{X}) \simeq \sum_{k=1}^{K} \iiint \pi_{k} \mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}^{-1}\right) q(\boldsymbol{\pi}) q\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right) \mathrm{d} \boldsymbol{\pi} \mathrm{d} \boldsymbol{\mu}_{k} \mathrm{~d} \mathbf{\Lambda}_{k} \tag{10.80}
$$

を用いて，大きな$N$については予測分布は混合ガウス分布になることを示せ．

</div>

(10.59)式の導出を考えると、(演習10.13より)
$$
q^{\star}\left(\mathbf{\Lambda}_{k}\right)=\mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{k}, \nu_{k}\right)\\
q^{\star}\left(\boldsymbol{\mu}_{k} \mid \boldsymbol{\Lambda}_{k}\right)=\mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k}, \beta_{k} \boldsymbol{\Lambda}_{k}\right)
$$
となる。
これらの分布について、$N \rightarrow \infty$のとき、
$N_{k} \rightarrow \infty$であり、
(10.60)~(10.63)式より、
$$
\beta_{k} \rightarrow N_{k}\\
\mathbf{m}_{k} \rightarrow \overline{\mathrm{x}}_{k}\\
\mathbf{W}_{k} \rightarrow N_{k}^{-1} \mathbf{S}_{k}^{-1}\\
\nu_{k} \rightarrow N_{k}
$$
である。

これらと(B.79)~(B.81)式より,
$$
\mathrm{E}\left[\boldsymbol{\Lambda}_{k}\right]=\nu_{k} \mathbf{W}_{k} \rightarrow \mathbf{S}_{k}^{-1}
$$

$$
\begin{aligned}
-\ln B\left(\mathbf{W}_{k}, \nu_{k}\right)&=-\ln (|\mathbf{W}_{k}|^{-\nu_{k} / 2}\left(2^{\nu_{k} D / 2} \pi^{D(D-1) / 4} \prod_{i=1}^{D} \Gamma\left(\frac{\nu_{k}+1-i}{2}\right)\right)^{-1})\\
&\rightarrow-\frac{N_{k}}{2}\left(D \ln N_{k}+\ln \left|\mathbf{S}_{k}\right|-D \ln 2\right)+\sum_{i=1}^{D} \ln \Gamma\left(\frac{N_{k}+1-i}{2}\right)\\
&\rightarrow-\frac{N_{k}}{2}\left(D \ln N_{k}+\ln \left|\mathbf{S}_{k}\right|-D \ln 2\right)+\sum_{i=1}^{D} \frac{N_{k}}{2}\left(\ln N_{k}-\ln 2-1\right)~~ (\because (\textrm1.146))\\
& \rightarrow-\frac{N_{k} D}{2}\left(\ln N_{k}-\ln 2-\ln N_{k}+\ln 2+1\right)-\frac{N_{k}}{2} \ln \left|\mathbf{S}_{k}\right| \\
&=-\frac{N_{k}}{2}\left(\ln \left|\mathbf{S}_{k}\right|+D\right)
\end{aligned}
$$

$$
\begin{aligned}
\mathbb{E}[\ln |\boldsymbol{\Lambda}_{k}|] &=\sum_{i=1}^{D} \psi\left(\frac{\nu_{k}+1-i}{2}\right)+D \ln 2+\ln |\mathbf{W}_{k}|\\
& \rightarrow D \ln \frac{N_{k}}{2}+D \ln 2-D \ln N_{k}-\ln \left|\mathbf{S}_{k}\right| \\
&=-\ln \left|\mathbf{S}_{k}\right|
\end{aligned}
$$
ただし、$\psi(\cdot)$は(10.241)式:
$$\psi(x)=\ln x+O(1 / x)$$
のディガンマ分布。

よって(B.82)式より
$$
\begin{aligned}
\mathrm{H}[\boldsymbol{\Lambda}_{k}]&=-\ln B(\mathbf{W}_{k}, \nu_{k})-\frac{(\nu_{k}-D-1)}{2} \mathbb{E}[\ln |\boldsymbol{\Lambda}_{k}|]+\frac{\nu_{k} D}{2}\\
& \rightarrow 0
\end{aligned}
$$

これにより $q^{\star}\left(\boldsymbol{\Lambda}_{k}\right)$ については示された。

また、
$$
\mathbf{m}_{k} \rightarrow \overline{\mathrm{x}}_{k}\\
\beta_{k} \mathbf{\Lambda}_{k} \rightarrow \beta_{k} \nu_{k} \mathbf{W}_{k} \rightarrow N_{k} \mathbf{S}_{k}^{-1}
$$
より $q^{\star}\left(\boldsymbol{\mu}_{k} \mid \boldsymbol{\Lambda}_{k}\right)$ についても示された。

$q^{\star}(\pi)$については、
(10.56),(10.57)式にある通り
$$
q^{\star}(\pi)=\operatorname{Dir}(\pi \mid \alpha)\\
\alpha_{k}=\alpha_{0}+N_{k}
$$
であり、$\alpha_{k} \rightarrow N_{k}$である。
(B.17),(B.19)式より、
$$
\begin{aligned}
\mathbb{E}\left[\pi_{k}\right]&=\frac{\alpha_{k}}{\overline{\alpha}}\\
&\rightarrow \frac{N_{k}}{N}
\end{aligned}
$$
$$
\begin{aligned}
\operatorname{cov}\left[\mu_{j} \mu_{k}\right]&=-\frac{\alpha_{j} \alpha_{k}}{\widehat{\alpha}^{2}(\widehat{\alpha}+1)}\\
&\rightarrow 0
\end{aligned}
$$
よって$q^{\star}(\pi)$についても示された。

最後に(10.80)式より、
$$
\begin{aligned}
p(\widehat{\mathbf{x}} \mid \mathbf{X}) &\simeq \sum_{k=1}^{K} \iiint \pi_{k} \mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}^{-1}\right) q(\boldsymbol{\pi}) q\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right) \mathrm{d} \boldsymbol{\pi} \mathrm{d} \boldsymbol{\mu}_{k} \mathrm{~d} \mathbf{\Lambda}_{k}\\
&\rightarrow \sum_{k=1}^{K} \frac{\alpha_{k}}{\bar{\alpha}} \iint \mathcal{N}\left(\widehat{\mathbf{x}} \mid \boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}\right) q\left(\boldsymbol{\mu}_{k}, \boldsymbol{\Lambda}_{k}\right) \mathrm{d} \boldsymbol{\mu}_{k} \mathrm{~d} \boldsymbol{\Lambda}_{k}\\
&\rightarrow \sum_{k=1}^{K} \frac{N_{k}}{N} \mathcal{N}\left(\widehat{\mathbf{x}} \mid \overline{\mathbf{x}}_{k}, \mathbf{W}_{k}\right)
\end{aligned}
$$
ただし最後の行は$q^{\star}\left(\boldsymbol{\Lambda}_{k}\right)$と$q^{\star}\left(\boldsymbol{\mu}_{k} \mid \boldsymbol{\Lambda}_{k}\right)$が特定の位置についてのデルタ関数と近似した。

これにより示された。

## 演習 10.21

<div class="panel-primary">

$K$個の混合要素を持つ混合モデルにおいて，混合要素の入れ替えについての対称性から得られる，同値なパラメータ設定の数は$K!$であることを示せ．

</div>

P.197によれば

> 例として，一つの観測値$x$についての二混合のガウス混合分布を考えよう．パラメータの値は$\pi_{1} = a$，$\pi_{2} = b$，$\pi_{3} = c$，$\pi_{4} = d$，$\pi_{5} = e$，$\pi_{6} = f$とする．このとき，二つの混合要素を入れ替えた別の設定$\pi_{1} = b$，$\pi_{2} = a$，$\pi_{3} = d$，$\pi_{4} = c$，$\pi_{5} = f$，$\pi_{6} = e$も，対称性から同じ$p(x)$を与える．

とあるように、もし$K$個の混合要素が存在する場合は、それらを入れ替えることで同値なパラメータ設定が可能なので、一般に$K!$個存在することは明らかである。

## 演習 10.22

<div class="panel-primary">

これまでにガウス混合モデルの事後分布の持つそれぞれの峰は，$K!$個ある同値な峰の一つであることを見てきた．変分ベイズ推論のアルゴリズムを実行した結果，近似事後分布$q$がどれかの峰の周りに局所化して得られたとしよう．このとき，完全な事後分布はこうした分布$q$の$K!$個の混合分布となり，各混合要素が峰となって同じ混合係数を持つ．この混合分布$q$の混合要素の間の重なりが無視できる程度だと仮定すると，結果として得られる全体の下界は，$q$の一つの混合要素の下界に項$\ln K!$を加えたものになることを示せ．

</div>

今、p166並びに、演習9.24より
$$
\begin{aligned}
\ln  p(\mathbf{X}) = L(q) + KL(q||p)
\end{aligned}
$$
が成り立つ。

この時、$KL(q||p)$はKLダイバージェンスであり、1.6.1の議論から、$KL(q||p) \geq 0$である。よって、$\ln  p(\mathbf{X}) \geq L(q)$であり、$L(q)$は、$\ln  p(\mathbf{X})$の下界である。よって、本題は、求めたい真の分布を$p(\mathbf{Z}|\mathbf{X})$として、$L(p(\mathbf{Z}|\mathbf{X}))$を求めれば良い。

まず、各峰は、pの真の各峰を$r_i$ $(i \in \{1, 2... K!\})$とおくと、pは単純に各$r_i$の平均で表すことができる。

$$
\begin{aligned}
p(\mathbf{Z}|\mathbf{X}) \simeq \sum_i^{K!} \frac{1}{K!} r_i(\mathbf{Z}|\mathbf{X})
\end{aligned}
$$

また、各峰の重なりが無視できるという仮定から、$r_k \neq 0 \rightarrow r_{i \neq k = 0}=0$が成り立つ。

ここで、ある真の峰$r_k$の近似の峰をqとおく。すなわち、この問題では、$p$を混合要素$r_i$を重ね合わせたものと見なし、その近似であるqによって下界を表すことを目指す。

すると、10.3式から、
$$
\begin{aligned}
L(p(\mathbf{Z}|\mathbf{X})) &= \int p(\mathbf{Z}|\mathbf{X}) \ln \{\frac{p(\mathbf{Z}, \mathbf{X})}{p(\mathbf{Z}|\mathbf{X})} \} d\mathbf{Z} \\
 &= \int\sum_i^{K!} \frac{1}{K!} r_i(\mathbf{Z}|\mathbf{X}) \ln \{\frac{p(\mathbf{Z}, \mathbf{X})}{\sum_i^{K!} \frac{1}{K!} r_i(\mathbf{Z}|\mathbf{X})} \} d\mathbf{Z} \\
 &= \frac{1}{K!}  \int r_1(\mathbf{Z}|\mathbf{X}) \ln \{\frac{p(\mathbf{Z}, \mathbf{X})}{\sum_i^{K!} \frac{1}{K!} r_i(\mathbf{Z}|\mathbf{X})} \} d\mathbf{Z} +
 \frac{1}{K!}  \int r_2(\mathbf{Z}|\mathbf{X}) \ln \{\frac{p(\mathbf{Z}, \mathbf{X})}{\sum_i^{K!} \frac{1}{K!} r_i(\mathbf{Z}|\mathbf{X})} \} d\mathbf{Z} + \cdots
 \frac{1}{K!}  \int r_{K!}(\mathbf{Z}|\mathbf{X}) \ln \{\frac{p(\mathbf{Z}, \mathbf{X})}{\sum_i^{K!} \frac{1}{K!} r_i(\mathbf{Z}|\mathbf{X})} \} d\mathbf{Z} \\
&= \frac{1}{K!}  \int r_1(\mathbf{Z}|\mathbf{X}) \ln \{\frac{p(\mathbf{Z}, \mathbf{X})}{\frac{1}{K!} r_1(\mathbf{Z}|\mathbf{X})} \} d\mathbf{Z} +
 \frac{1}{K!}  \int r_2(\mathbf{Z}|\mathbf{X}) \ln \{\frac{p(\mathbf{Z}, \mathbf{X})}{ \frac{1}{K!} r_2(\mathbf{Z}|\mathbf{X})} \} d\mathbf{Z} + \cdots
 \frac{1}{K!}  \int r_{K!}(\mathbf{Z}|\mathbf{X}) \ln \{\frac{p(\mathbf{Z}, \mathbf{X})}{\frac{1}{K!} r_i{K!}\mathbf{Z}|\mathbf{X})} \} d\mathbf{Z} &\because r_k \neq 0 \rightarrow r_{i \neq k = 0}=0 \\
 &= \frac{1}{K!} \sum_i^{K!} \int r_i(\mathbf{Z}|\mathbf{X}) \ln \{\frac{p(\mathbf{Z}, \mathbf{X})}{\frac{1}{K!} r_i(\mathbf{Z}|\mathbf{X})} \} d\mathbf{Z} \\
 &= \frac{1}{K!} \sum_i^{K!} \int r_i(\mathbf{Z}|\mathbf{X}) \{ \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ r_i(\mathbf{Z}|\mathbf{X})} + \ln K!\} d\mathbf{Z} \\
 &= \frac{1}{K!} \{ \sum_i^{K!}  \int r_i(\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ r_i(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z} +
\ln K! \sum_i^{K!} \int r_i(\mathbf{Z}|\mathbf{X})  d\mathbf{Z}\}
 \\
&= \frac{1}{K!} \sum_i^{K!} \int r_i(\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ r_i(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z} +
\ln K! &\because \int r_i(\mathbf{Z}|\mathbf{X})  d\mathbf{Z} = r_i(\mathbf{X}|\mathbf{X})  = 1\\
&=\frac{1}{K!} \{ \int r_1 (\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ r_1(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z}+
\int r_2 (\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ r_2(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z}
\}+\cdots +
\int r_k (\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ r_k(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z}
\}+\cdots +
\int r_{K!} (\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ r_{K!}(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z}
\}+
\ln K! \\
&=\frac{1}{K!} K! \int q(\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ q(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z} +
\ln K! &\because r_i\text{はそれぞれ同値であり、積分は同じ。詳細は最後　}\\
&= L(q) + \ln K! &\because (10.3)
\end{aligned}
$$

今、$L(q)$は一つの混合要素の下界なので、題意は満たされた。

最後から2番目の式変形について、まず、自明に、$\int r_k (\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ r_k(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z} =\int q(\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ q(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z}$が成り立つ。

そして、$i \neq k$について、
$$
\begin{aligned}
\int r_i (\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ r_i(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z}
 &= \int r_i (\mathbf{Z}|\mathbf{X}) \ln p(\mathbf{Z}| \mathbf{X})d\mathbf{Z}
+\int r_i (\mathbf{Z}|\mathbf{X}) \ln p(\mathbf{X})  d\mathbf{Z}
-\int r_i (\mathbf{Z}|\mathbf{X}) \ln r_i (\mathbf{Z}|\mathbf{X}) d\mathbf{Z} \\
&= \int r_i (\mathbf{Z}|\mathbf{X}) \ln \frac{r_i(\mathbf{Z}| \mathbf{X})}{K!} d\mathbf{Z}
+\int r_i (\mathbf{Z}|\mathbf{X}) \ln p(\mathbf{X})  d\mathbf{Z}
-\int r_i (\mathbf{Z}|\mathbf{X}) \ln r_i (\mathbf{Z}|\mathbf{X}) d\mathbf{Z} &\because r_i(\mathbf{Z} \notin \mathbf{Z}_i |\mathbf{X}) = 0\\
&= \int r_k (\mathbf{Z}|\mathbf{X}) \ln \frac{r_k(\mathbf{Z}| \mathbf{X})}{K!} d\mathbf{Z}
+\int r_k (\mathbf{Z}|\mathbf{X}) \ln p(\mathbf{X})  d\mathbf{Z}
-\int r_k (\mathbf{Z}|\mathbf{X}) \ln r_k (\mathbf{Z}|\mathbf{X}) d\mathbf{Z} &\because r_i\text{はそれぞれ同値であり、積分は同じ}\\
&= \int r_k (\mathbf{Z}|\mathbf{X}) \ln p(\mathbf{Z}| \mathbf{X})d\mathbf{Z}
+\int r_k (\mathbf{Z}|\mathbf{X}) \ln p(\mathbf{X})  d\mathbf{Z}
-\int r_k (\mathbf{Z}|\mathbf{X}) \ln r_k (\mathbf{Z}|\mathbf{X}) d\mathbf{Z} &\because r_k(\mathbf{Z} \notin \mathbf{Z}_k |\mathbf{X}) = 0\\
&= \int r_k (\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z},  \mathbf{X})}{r_k (\mathbf{Z}|\mathbf{X})} d\mathbf{Z}\\
&= \int q(\mathbf{Z}|\mathbf{X}) \ln \frac{p(\mathbf{Z}, \mathbf{X})}{ q(\mathbf{Z}|\mathbf{X})}  d\mathbf{Z}
\end{aligned}
$$

最後は冗長かもしれないのでその時はご教示ください。

## 演習 10.23

<div class="panel-primary">

混合係数$\{ \pi_k \}$に事前分布を与えない変分ベイズガウス混合モデルを考えよう．代わりに混合係数はパラメータとして扱い，対数周辺尤度の下界を最大化する際に値を求める．ラグランジュ乗数法を用いて，混合係数の和が$1$になる制約条件の下でこの下界を混合係数について最大化すると，再推定式
$$\pi_{k}=\frac{1}{N} \sum_{n=1}^{N} r_{n k} \tag{10.83}$$
の結果が得られることを示せ．この際，下界のすべての項を考える必要はなく，$\{\pi_k\}$に依存する項だけを考えればよいことに注意せよ．

</div>

変分ベイズガウス混合モデルでは、下界は(10.70)式で与えられる。
本問では、**混合係数$\{ \pi_k \}$に事前分布を与えない**パラメータとして扱うため、対数周辺尤度として第２項のみを考えれば良い。つまり、

$$
\mathscr{L} \propto \mathbb{E}[\ln p(\mathbf{Z} \mid \pi)]=\sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln \pi_{k} \tag{10.72}
$$

$$
L=\sum_{n=1}^{N} \sum_{k=1}^{K} r_{n k} \ln \pi_{k}+\lambda \cdot\left(\sum_{k=1}^{K} \pi_{k}-1\right)
$$

上式のLagrangianについて、$\pi_k$について微分し、=0とおくと、
$$
\frac{\partial L}{\partial \pi_{k}}=\frac{\sum_{n=1}^{N}r_{nk}}{\pi_{k}}+\lambda=\frac{N_{k}}{\pi_{k}}+\lambda=0 \tag{A}
$$

(A)の両辺に$\pi_k$をかけ、$\sum_{k=1}^{K}$をとると、
$$
\sum_{k=1}^{K} N_{k}+\lambda \sum_{k=1}^{K}\pi_{k}=0
$$

$\sum_{k=1}^{K} N_{k}=N$, $\sum_{k=1}^{K}\pi_{k}=1$より、
$$
\lambda=-N \tag{A}
$$

(A)に代入し、$\pi_{k}$について解くと、
$$
\pi_{k}=\frac{N_{k}}{N}=\underline{\frac{1}{N} \sum_{n=1}^{N} r_{n k}}
$$

## 演習 10.24

<div class="panel-primary">

10.2節でガウス混合モデルを最尤推定で扱う際に現れる特異性は，ベイズ的な解では現れないことを見た．こうした特異性は，ベイズモデルを最大事後機率(MAP)推定を使って解く際には現れるかどうか議論せよ．

</div>

最尤推定で現れる特異性とは、9.2.1節で議論した$\left|\boldsymbol{\Lambda}_{k}\right| \rightarrow \infty$に発散してしまうことを意味している。ベイズモデルではこのようなことが起きないことを示す。

混合ガウス分布の事後確率は、(10.9),(10.38),(10.40),(10.50)を利用すれば以下となる。

$$
\begin{aligned}
\mathbb{E}_{q(\mathbf{Z})} &[\ln p(\mathbf{X} \mid \mathbf{Z}, \boldsymbol{\mu}, \boldsymbol{\Lambda}) p(\boldsymbol{\mu}, \mathbf{\Lambda})] \\
=& \frac{1}{2} \sum_{n=1}^{N} r_{k n}\left(\ln \left|\boldsymbol{\Lambda}_{k}\right|-\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)^{\mathrm{T}} \boldsymbol{\Lambda}_{k}\left(\mathbf{x}_{n}-\boldsymbol{\mu}_{k}\right)\right) \\
&+\ln \left|\boldsymbol{\Lambda}_{k}\right|-\beta_{0}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}} \boldsymbol{\Lambda}_{k}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right) \\
&+\left(\nu_{0}-D-1\right) \ln \left|\boldsymbol{\Lambda}_{k}\right|-\operatorname{Tr}\left[\mathbf{W}_{0}{ }^{1} \boldsymbol{\Lambda}_{k}\right]+\text { const. }
\end{aligned}
$$

これを（10.51)-(10.53)を利用して$\mathbf{\Lambda}_{k}$について整理すると（$\mathbf{\Lambda}_{k}$と無関係な項は無視）

$$
\left(\nu_{0}+N_{k}-D\right) \ln \left|\boldsymbol{\Lambda}_{k}\right|-\operatorname{Tr}\left[\left(\mathbf{W}_{0}^{-1}+\beta_{0}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}}+N_{k} \mathbf{S}_{k}\right) \boldsymbol{\Lambda}_{k}\right]
$$

(C.24),(C.28)を使用して$\mathbf{\Lambda}_{k}$で微分してゼロとおくと以下になる。

$$
\mathbf{\Lambda}_{k}^{-1}=\frac{1}{\nu_{0}+N_{k}-D}\left(\mathbf{W}_{0}^{-1}+\beta_{0}\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)\left(\boldsymbol{\mu}_{k}-\mathbf{m}_{0}\right)^{\mathrm{T}}+N_{k} \mathbf{S}_{k}\right)
$$

ウィシャート分布の正式より、$\left|\boldsymbol{\Lambda}_{k}^{-1}\right|$はゼロになることはない。

よって、ベイズモデルでは、$\left|\boldsymbol{\Lambda}_{k}\right| \rightarrow \infty$に発散することはないことが示された。

## 演習 10.25

<div class="panel-primary">

10.2節で議論したベイズ混合ガウス分布の変分ベイス法による解では，事後分布について分解した近似
$$q(\mathbf{Z})=\prod_{i=1}^{M} q_{i}\left(\mathbf{Z}_{i}\right) \tag{10.5}$$
を用いた図10.2で見たように，こうした分解の仮定はパラメータ空間で、の事後分布の特定の方向の分散を過小評価してしまう．この影響がモデルエピデンスの変分近似に及ぼす影響について質的に議論せよ．さらに，この影響が混合モデルの混合要素数に関してどう変わるか述べよ．これから，変分ガウス混合モデルが最適な混合要素数を過小評価しがちか，過大評価しがちか説明せよ．

</div>

混合成分の数が増えると、相関している可能性のある変数の数も増える一方、平均場近似の式(10.5)を用いるとそれらの相関を表現することができない(図10.2,3)。その結果、KLダイバージェンスの最小化を行うときに複数の山をつぶして近似してしまうことが考えられるため、過小評価する。



## 演習 10.26

<div class="panel-primary">

ベイズ線形回帰モデルの変分ベイズ法による解法を拡張し，$\beta$についてガンマ超事前分布$\textrm{Gam}(\beta\mid c_0, d_0)$を導入して，分解された変分事後分布$q(\mathbf{w}) q(\alpha) q(\beta)$を仮定して変分ベイズ法によって解け．変分事後分布の三つの因子の更新式を導出し，さらに下界および予測分布の式を求めよ．

</div>

$\beta$を含めた全ての変数の同時分布は

$$
p(\mathbf{t}, \mathbf{w}, \alpha, \beta)=p(\mathbf{t}|\mathbf{w}, \beta)p(\mathbf{w}|\alpha)p(\alpha)p(\beta)
$$

と書くことができる．本文中の議論をなぞって，$\mathbf{w}, \alpha, \beta$の尤度関数と事前分布を

$$
\begin{aligned}
&p(\mathbf{t} \mid \mathbf{w}, \beta, \mathbf{X})=\prod_{n=1}^{N} N\left(\mathbf{t}_{n} \mid \mathbf{w}^{\mathrm{T}} \phi_{n}, \beta^{-1}\right) \\
&p(\mathbf{w} \mid \alpha)=N\left(\mathbf{w} \mid 0, \alpha^{-1} \mathbf{I}\right) \\
&p(\alpha)=\operatorname{Gam}\left(\alpha \mid a_{0}, b_{0}\right) \\
&p(\beta)=\operatorname{Gam}\left(\beta \mid c_{0}, d_{0}\right)
\end{aligned}
$$

と書くことができる．

ここで変分推論の枠組みで考え，問題中の設定から変分事後分布は

$$
q(\mathbf{w}, \alpha, \beta) = q(\mathbf{w})q(\alpha)q(\beta)
$$

と分解できるとする．

$q(\mathbf{w}),q(\alpha),q(\beta)$の更新式を求める．まず$q(\alpha)$から10.1節で導出した一般的な結果(10.9)を用いて

$$
\begin{aligned}
\ln q^*(\alpha)&=\mathbb{E}_{\mathbf{w}, \beta}[\ln p(\mathbf{t}, \mathbf{w}, \alpha, \beta \mid \mathbf{X})]\\
&=\mathbb{E}_{\mathbf{w}, \beta}[\ln p(\mathbf{t} \mid \mathbf{w}, \beta, \mathbf{X}) p(\mathbf{w} \mid \alpha) p(\alpha) p(\beta)]\\
&=\mathbb{E}_{\mathbf{w}, \beta}[\ln p(\mathbf{t} \mid \mathbf{w}, \beta, \mathbf{X})]+\mathbb{E}_{\mathbf{w}}[\ln \beta(\mathbf{w} \mid \alpha)]+\ln p(\alpha)+\mathbb{E}_{\beta}[\ln p(\beta)]\\
&=\mathbb{E}_{\mathbf{w}}\left[\ln N\left(\mathbf{w} \mid 0, \alpha^{-1} \mathbf{I}\right)\right]+\ln \operatorname{Gam}\left(\alpha \mid a_{0}, b_{0}\right)+\textrm{const}\\
&=\mathbb{E}_{\mathbf{w}}\left[\ln \frac{1}{(2 \pi)^{\frac{M}{2}}} \frac{1}{\left(\alpha^{-1}\right)^{\frac{1}{2}}} \operatorname{exp}\left(-\frac{\alpha}{2} \mathbf{w}^{\mathrm{T}} \mathbf{w}\right)\right]+\ln \frac{1}{\Gamma\left(a_{0}\right)} b_{0}^{a_{0}} \alpha^{a_{0}-1} e^{-b_{0} \alpha}+ \textrm{const.}\\
&=\frac{M}{2} \ln \alpha-\frac{\alpha}{2} \mathbb{E}\left[\mathbf{w}^{\mathrm{T}} \mathbf{w}\right]+\left(a_{0}-1\right) \ln \alpha-b_{0} \alpha+ \textrm{const.}\\
&=\left(\frac{M}{2}+a_{0}-1\right) \ln \alpha-\left(\frac{1}{2} \mathbb{E}\left[\mathbf{w}^{\mathrm{T}} \mathbf{w}\right]+b_{0}\right) \alpha+ \textrm{const.}
\end{aligned}
$$

ここで$\beta$を導入した場合にも$\alpha$に依存しない項はconstに押し込んで計算することができるため，(10.92)-(10.95)式までの議論をそのまま用いることができる．

$$
q^*(\alpha)=\operatorname{Gam}\left(\alpha \mid a_{N}, b_{N}\right) , a_N=\frac{M}{2} + a_0, b_N=\frac{1}{2}\mathbb{E}\left[\mathbf{w}^{\mathrm{T}} \mathbf{w}\right]+b_0
$$

を得る．次に$q(\mathbf{w})$について(10.9)より

$$
\begin{aligned}
\ln q^*(\mathbf{w})&=\mathbb{E}_{\alpha, \beta}[\ln \beta(\mathbf{t}, \mathbf{w}, \alpha, \beta \mid x)]\\
&=\mathbb{E}_{\alpha, \beta}[\ln p(\mathbf{t} \mid \mathbf{w}, \beta, X) p(\mathbf{w} \mid \alpha) \gamma(\alpha) p(\beta)]\\
&=\mathbb{E}_{\beta}\left[\ln \prod_{n=1}^{N} N\left(\mathbf{t}_{n} \mid \mathbf{w}^{\mathrm{T}} \phi_{n}, \beta^{-1}\right)\right]+\mathbb{E}_{\alpha}\left[\ln N\left(w \mid 0, \alpha^{-1} I\right)\right]+ \textrm{const.}\\
&=\mathbb{E}_{\beta}\left[\sum_{n=1}^N\ln \frac{1}{(2 \pi)^{\frac{M}{2}}} \frac{1}{\left(\beta^{-1}\right)^{\frac{1}{2}}} \operatorname{exp}\left\{-\frac{\beta}{2}(\mathbf{t}_n-\mathbf{w}^{\mathrm{T}}\phi_{n})^2 \right\}\right]+\mathbb{E}_{\alpha}\left[\ln \frac{1}{(2 \pi)^{\frac{M}{2}}} \frac{1}{\left(\alpha^{-1}\right)^{\frac{1}{2}}} \operatorname{exp}\left(-\frac{\alpha}{2} \mathbf{w}^{\mathrm{T}} \mathbf{w}\right)\right]+ \textrm{const.}\\
&=\mathbb{E}_{\beta}\left[\beta\right]\left(\mathbf{w}^{\mathrm{T}}\Phi^{\mathrm{T}}\mathbf{t}-\frac{1}{2}\mathbf{w}^{\mathrm{T}}\Phi^{\mathrm{T}}\Phi\mathbf{w}\right)-\frac{1}{2}\mathbb{E}_{\alpha}\left[\alpha\right]\mathbf{w}^{\mathrm{T}}\mathbf{w}+ \textrm{const.}\\
&=-\frac{1}{2}\mathbf{w}^{\mathrm{T}}\left(\mathbb{E}_{\beta}[\beta] \Phi^{\mathrm{T}} \Phi+\mathbb{E}_{\alpha}[\alpha]\mathbf{I}\right) \mathbf{w}+\mathbb{E}_{\beta}[\beta] \mathbf{w}^{\mathrm{T}} \Phi^{\mathrm{T}} \mathbf{t}+ \textrm{const.}\\
\end{aligned}
$$

これは$\mathbf{w}$に関して2次形式なのでガウス分布になり，平方完成すると

$$
q^*(\mathbf{w})=\mathcal{N}(\mathbf{w}\mid \mathbf{m}_N, \mathbf{S}_N)
$$

$$
\mathbf{m}_N=\mathbb{E}_{\beta}[\beta]\mathbf{S}_N\mathbf{\Phi}^{\mathrm{T}}\mathbf{t}
$$

$$
\mathbf{S}_N=\mathbb{E}_{\alpha}[\alpha]\mathbf{I}+\mathbb{E}_{\beta}[\beta]\mathbf{\Phi}^{\mathrm{T}}\mathbf{\Phi}
$$

を得る．最後に$q(\beta)$について(10.9)より

$$
\begin{aligned}
\ln q^{\star}(\beta) &=\mathbb{E}_{\mathbf{w}, \alpha}[\ln p(\mathbf{t}, \mathbf{w}, \alpha, \beta \mid \mathbf{X})]\\
&=\mathbb{E}_{\mathbf{w}, \alpha}[\ln p(\mathbf{t} \mid \mathbf{w}, \beta, \mathbf{X}) p(\mathbf{w} \mid \alpha) p(\alpha) p(\beta)]\\
&=\mathbb{E}_{\mathbf{w}}[\ln p(\mathbf{t} \mid \mathbf{w}, \beta)]+\ln p(\beta)+\text { const } \\
&= \frac{N}{2} \cdot \ln \beta-\frac{\beta}{2} \cdot \mathbb{E}\left[\sum_{n=1}^{N}\left(t_{n}-\mathbf{w}^{\mathrm{T}} \boldsymbol{\phi}_{n}\right)^{2}\right]+\left(c_{0}-1\right) \ln \beta-d_{0} \beta +\text { const }\\
&=\left(\frac{N}{2}+c_{0}-1\right) \cdot \ln \beta-\frac{\beta}{2} \cdot \mathbb{E}\left[\left\|\mathbf{\Phi}_{\mathbf{w}}-\mathbf{t}\right\|^{2}\right]-d_{0} \beta +\text { const }\\
&=\left(\frac{N}{2}+c_{0}-1\right) \cdot \ln \beta-\beta \cdot\left\{\frac{1}{2} \cdot \mathbb{E}\left[\|\mathbf{\Phi} \mathbf{w}-\mathbf{t}\|^{2}\right]+d_{0}\right\} +\text { const }\\
&=\left(\frac{N}{2}+c_{0}-1\right) \cdot \ln \beta-\beta \cdot\left\{\frac{1}{2} \cdot \mathbb{E}\left[\mathbf{w}^{\mathrm{T}} \mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi}_{\mathbf{w}}-2 \mathbf{t}^{\mathrm{T}} \mathbf{\Phi}_{\mathbf{w}}+\mathbf{t}^{\mathrm{T}} \mathbf{t}\right]+d_{0}\right\} +\text { const }\\
&=\left(\frac{N}{2}+c_{0}-1\right) \cdot \ln \beta-\beta \cdot\left\{\frac{1}{2} \cdot \operatorname{Tr}\left[\mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi} \mathbb{E}\left[\mathbf{w} \mathbf{w}^{\mathrm{T}}\right]\right]-\mathbf{t}^{\mathrm{T}} \mathbf{\Phi} \mathbb{E}[\mathbf{w}]+\frac{1}{2} \mathbf{t}^{\mathrm{T}} \mathbf{t}+d_{0}\right\} +\text { const }\\
&=\left(\frac{N}{2}+c_{0}-1\right) \cdot \ln \beta-\beta \cdot\left\{\frac{1}{2} \cdot \operatorname{Tr}\left[\mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi}\left(\mathbf{m}_{N} \mathbf{m}_{N}^{\mathrm{T}}+\mathbf{S}_{N}\right)\right]-\mathbf{t}^{\mathrm{T}} \mathbf{\Phi} \mathbf{m}_{N}+\frac{1}{2} \mathbf{t}^{\mathrm{T}} \mathbf{t}+d_{0}\right\} +\text { const }\\
&=\left(\frac{N}{2}+c_{0}-1\right) \cdot \ln \beta-\beta \cdot\left\{\frac{1}{2} \operatorname{Tr}\left[\mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi} \mathbf{S}_{N}\right]+\frac{1}{2} \mathbf{m}_{N}^{\mathrm{T}} \mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi} \mathbf{m}_{N}-\mathbf{t}^{\mathrm{T}} \mathbf{\Phi} \mathbf{m}_{N}+\frac{1}{2} \mathbf{t}^{\mathrm{T}} \mathbf{t}+d_{0}\right\} +\text { const }\\
&=\left(\frac{N}{2}+c_{0}-1\right) \cdot \ln \beta-\beta \cdot \frac{1}{2}\left\{\operatorname{Tr}\left[\mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi} \mathbf{S}_{N}\right]+\left\|\mathbf{\Phi} \mathbf{m}_{N}-\mathbf{t}\right\|^{2}+2 d_{0}\right\}+\text { const }
\end{aligned}
$$

これより

$$
q^{\star}(\beta)=\operatorname{Gam}\left(\beta \mid c_{N}, d_{N}\right)
$$

$$
c_N=\frac{N}{2}+c_0
$$

$$
d_N=d_{0}+\frac{1}{2}\left\{\operatorname{Tr}\left[\mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi} \mathbf{S}_{N}\right]+\left\|\mathbf{\Phi} \mathbf{m}_{N}-\mathbf{t}\right\|^{2}\right\}
$$

以上から各因子の更新式が得られた．

次に変分下界を求める．変分下界は本文中の式(10.107)を$\beta$を考慮した形に修正すれば得られ，考えるべき項は$\mathbb{E}\left[\ln p(\beta)\right], -\mathbb{E}\left[\ln q^*(\beta)\right]$の二つであるので，それぞれの計算をして，ディガンマ関数$\varphi(a)=\frac{d}{da}\ln\Gamma(a)$として

$$
\begin{aligned}
\mathbb{E}[\ln p(\beta)] &=\left(c_{0}-1\right) \mathbb{E}[\ln \beta]-d_{0} \mathbb{E}[\beta]+c_{0} \ln d_{0}-\ln \Gamma\left(c_{0}\right) \\
&=\left(c_{0}-1\right) \cdot\left(\varphi\left(c_{N}\right)-\ln d_{N}\right)-d_{0} \frac{c_{N}}{d_{N}}+c_{0} \ln d_{0}-\ln \Gamma\left(c_{0}\right)
\end{aligned}
$$

ここで(B.26)(ガンマ分布の関数形についての定義式),(B.30)(ガンマ分布に従う確率変数の自然対数の期待値がディガンマ関数に紐づけられる式)をそれぞれ用いた．また

$$
-\mathbb{E}\left[\ln q^{\star}(\beta)\right]=\left(c_{N}-1\right) \cdot \varphi\left(c_{N}\right)-c_{N}+\ln d_{N}-\ln \Gamma\left(c_{N}\right)
$$

ここでガンマ分布に従う確率変数のエントロピーについての式(B.31)を用いた．(10.107)-(10.112)の式を修正することで$\beta$を考慮に入れた変分下界を得る．

最後に予測分布を考える．

これも本文中の議論を$\beta$を考慮したものに修正して得ることができて(10.105),(10.106)から

$$
\begin{aligned}
p(t \mid \mathbf{x}, \mathbf{t}) &=\int p(t \mid \mathbf{x}, \mathbf{w}) p(\mathbf{w} \mid \mathbf{t}) \mathrm{d} \mathbf{w} \\
& \simeq \int p(t \mid \mathbf{x}, \mathbf{w}) q(\mathbf{w}) \mathrm{d} \mathbf{w} \\
&=\int \mathcal{N}\left(t \mid \mathbf{w}^{\mathrm{T}} \boldsymbol{\phi}(\mathbf{x}), \beta^{-1}\right) \mathcal{N}\left(\mathbf{w} \mid \mathbf{m}_{N}, \mathbf{S}_{N}\right) \mathrm{d} \mathbf{w} \\
&=\mathcal{N}\left(t \mid \mathbf{m}_{N}^{\mathrm{T}} \boldsymbol{\phi}(\mathbf{x}), \sigma^{2}(\mathbf{x})\right)
\end{aligned}
$$

ここで分散は

$$
\sigma^{2}(\mathbf{x})=\frac{1}{\mathbb{E}\left[\beta\right]}+\boldsymbol{\phi}(\mathbf{x})^{\mathrm{T}} \mathbf{S}_{N} \boldsymbol{\phi}(\mathbf{x})
$$

である．

## 演習 10.27

<div class="panel-primary">

付録Bで与えられている公式を用いて， 線形基底関数回帰モデルの変分下界は
$$
\begin{aligned} \mathcal{L}(q)&= \mathbb{E}[\ln p(\mathbf{w}, \alpha, \mathbf{t})]-\mathbb{E}[\ln q(\mathbf{w}, \alpha)] \\
&= \mathbb{E}_{\mathbf{w}}[\ln p(\mathbf{t} \mid \mathbf{w})]+\mathbb{E}_{\mathbf{w}, \alpha}[\ln p(\mathbf{w} \mid \alpha)]+\mathbb{E}_{\alpha}[\ln p(\alpha)] \\
&-\mathbb{E}_{\alpha}[\ln q(\mathbf{w})]_{\mathbf{w}}-\mathbb{E}[\ln q(\alpha)] \end{aligned} \tag{10.107}
$$
の形で書け，その各項は

$$\begin{aligned} \mathbb{E}[\ln p(\mathbf{t} \mid \mathbf{w})]_{\mathbf{w}}=& \frac{N}{2} \ln \left(\frac{\beta}{2 \pi}\right)-\frac{\beta}{2} \mathbf{t}^{\mathrm{T}} \mathbf{t}+\beta \mathbf{m}_{N}^{\mathrm{T}} \mathbf{\Phi}^{\mathrm{T}} \mathbf{t} \\
&-\frac{\beta}{2} \operatorname{Tr}\left[\mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi}\left(\mathbf{m}_{N} \mathbf{m}_{N}^{\mathrm{T}}+\mathbf{S}_{N}\right)\right] \end{aligned} \tag{10.108}$$
$$\begin{aligned} \mathbb{E}[\ln p(\mathbf{w} \mid \alpha)]_{\mathbf{w}, \alpha}=&-\frac{M}{2} \ln (2 \pi)+\frac{M}{2}\left(\psi\left(a_{N}\right)-\ln b_{N}\right) \\
&-\frac{a_{N}}{2 b_{N}}\left[\mathbf{m}_{N}^{\mathrm{T}} \mathbf{m}_{N}+\operatorname{Tr}\left(\mathbf{S}_{N}\right)\right] \end{aligned}\tag{10.109}$$
$$\begin{aligned} \mathbb{E}[\ln p(\alpha)]_{\alpha}=&\ a_{0} \ln b_{0}+\left(a_{0}-1\right)\left[\psi\left(a_{N}\right)-\ln b_{N}\right] \\
&-b_{0} \frac{a_{N}}{b_{N}}-\ln \Gamma\left(a_{0}\right) \end{aligned} \tag{10.110}$$
$$-\mathbb{E}[\ln q(\mathbf{w})]_{\mathbf{w}}=\frac{1}{2} \ln \left|\mathbf{S}_{N}\right|+\frac{M}{2}[1+\ln (2 \pi)] \tag{10.111}$$
$$-\mathbb{E}[\ln q(\alpha)]_{\alpha}=\ln \Gamma\left(a_{N}\right)-\left(a_{N}-1\right) \psi\left(a_{N}\right)-\ln b_{N}+a_{N} \tag{10.112}$$

となることを示せ．

</div>

※演習10.16, 10.17のように各項の確率分布に適切なものを当てはめて計算していくだけ。

$$
\begin{aligned}
\mathbb{E}_{\mathbf{w}}[\ln p(\mathbf{t} \mid \mathbf{w})] &=\mathbb{E}_{\mathbf{w}}\left[\ln \prod_{n=1}^{N} \mathcal{N}\left(t_{n} \mid \mathbf{w}^{\mathrm{T}} \boldsymbol{\phi}_{n}, \beta^{-1}\right)\right]\hspace{1em}(\because(B.87))\\
&=\mathbb{E}_{\mathbf{w}}\left[\sum_{n=1}^{N} \ln \mathcal{N}\left(t_{n} \mid \mathbf{w}^{\mathrm{T}} \boldsymbol{\phi}_{n}, \beta^{-1}\right)\right] \\
&=\mathbb{E}_{\mathbf{w}}\left[\sum_{n=1}^{N} \ln \left\{\left(\frac{\beta}{2 \pi}\right)^{\frac{1}{2}} \exp \left\{-\frac{\beta}{2}\left(t_{n}-\mathbf{w}^{\mathrm{T}} \boldsymbol{\phi}_{n}\right)^{2}\right\}\right.\right.\\
&=\frac{N}{2} \ln \left(\frac{\beta}{2 \pi}\right)-\frac{\beta}{2} \mathbb{E}_{\mathbf{w}}\left[\sum_{n=1}^{N}\left(t_{n}-\mathbf{w}^{\mathrm{T}} \boldsymbol{\phi}_{n}\right)^{2}\right] \\
&=\frac{N}{2} \ln \left(\frac{\beta}{2 \pi}\right)-\frac{\beta}{2} \mathbb{E}_{\mathbf{w}}\left[(\mathbf{t}-\mathbf{\Phi} \mathbf{w})^{\mathrm{T}}(\mathbf{t}-\mathbf{\Phi} \mathbf{w})\right] \\
&=\frac{N}{2} \ln \left(\frac{\beta}{2 \pi}\right)-\frac{\beta}{2} \mathbf{t}^{\mathrm{T}} \mathbf{t}+\beta \mathbb{E}_{\mathbf{w}}\left[\mathbf{w}^{\mathrm{T}}\right] \mathbf{\Phi}^{\mathrm{T}} \mathbf{t}-\frac{\beta}{2} \mathbb{E}_{\mathbf{w}}\left[\mathbf{w}^{\mathrm{T}} \mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi} \mathbf{w}\right] \\
&=\frac{N}{2} \ln \left(\frac{\beta}{2 \pi}\right)-\frac{\beta}{2} \mathbf{t}^{\mathrm{T}} \mathbf{t}+\beta \mathbf{m}_{N}^{\mathrm{T}} \mathbf{\Phi}^{\mathrm{T}} \mathbf{t}-\frac{\beta}{2} \operatorname{Tr}\left[\mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi} \mathbb{E}_{\mathbf{w}}\left[\mathbf{ww}^{\mathrm{T}}\right]\right] \\
&=\frac{N}{2} \ln \left(\frac{\beta}{2 \pi}\right)-\frac{\beta}{2} \mathbf{t}^{\mathrm{T}} \mathbf{t}+\beta_{m N}^{\mathrm{T}} \mathbf{\Phi} \mathbf{t}-\frac{\beta}{2} \operatorname{Tr}\left[\mathbf{\Phi}^{\mathrm{T}} \mathbf{\Phi}\left(\mathbf{m}_{N} \mathbf{m}_{N}^{\mathrm{T}}+\mathbf{S}_{N}\right)\right]
\end{aligned}
$$

----

$$
\begin{aligned} \mathbb{E}_{\mathbf{w}, \alpha}[\ln p(\mathbf{w} \mid \alpha)] &=\mathbb{E}_{\mathbf{w}, \alpha}\left[\ln \mathcal{N}\left(\mathbf{w} \mid \mathbf{0}, \alpha^{-1} \mathbf{I}\right)\right] \\
&=\mathbb{E}_{\mathbf{w}, \alpha}\left[\ln \left\{\left(\frac{\alpha}{2 \pi}\right)^{M / 2} \exp \left\{-\frac{\alpha}{2} \mathbf{w}^{\mathrm{T}} w\right\}\right]\right.\\
&=\mathbb{E}_{\mathbf{w}, \alpha}\left[\frac{M}{2} \ln \left(\frac{\alpha}{2 \pi}\right)\right]-\frac{1}{2} \mathbb{E}_{\mathbf{w}, \alpha}\left[\alpha \mathbf{w}^{\mathrm{T}} \mathbf{w}\right] \\
&=-\frac{M}{2} \ln (2 \pi)+\frac{M}{2} \mathbb{E}_{\alpha}[\ln \alpha]-\frac{\mathbb{E}_{\alpha}[\alpha]}{2} \mathbb{E}_{\mathbf{w}}\left[\mathbf{w}^{\mathrm{T}} \mathbf{w}\right] \\
&=-\frac{M}{2} \ln (2 \pi)+\frac{M}{2} \underbrace{\left(\psi\left(a_{N}\right)-\ln b_{N}\right)}_{(B.30)} - \underbrace{\frac{a_{N}}{2 b_{N}}}_{(B.27)} \mathbb{E}_{\mathbf{w}}\left[\operatorname{Tr}\left(\mathbf{w} \mathbf{w}^{\mathrm{T}}\right)\right] \\
&=-\frac{M}{2} \ln (2 \pi)+\frac{M}{2} \left(\psi\left(a_{N}\right)-\ln b_{N}\right) - \frac{a_{N}}{2 b_{N}} \left[\mathbf{m}_{N}^{\mathrm{T}} \mathbf{m}_{N}+\operatorname{Tr}\left(\mathbf{S}_{N}\right)\right]
\end{aligned}
$$

ここで$\mathbb{E}_{\mathbf{w}}\left[\operatorname{Tr}\left(\mathbf{w} \mathbf{w}^{\mathrm{T}}\right)\right]$の変形についてはトレースと期待値の交換性と
$$
\begin{aligned} & \operatorname{Tr}\left[\mathbb{E}_{\mathbf{w}}\left[\mathbf{w} \mathbf{w}^{\mathrm{T}}\right]\right] \\
= & \operatorname{Tr}\left[\operatorname{cov}[\mathbf{w}]+\mathbb{E}_{\mathbf{w}}[\mathbf{w}] \mathbb{E}_{\mathbf{w}}\left[\mathbf{w}^{\mathrm{T}}\right]\right] \quad(\because(1.42)) \\
= & \operatorname{Tr}\left[\mathbf{S}_{N}+\mathbf{m}_{N} \mathbf{m}_{N}^{\mathrm{T}}\right] \\
= &\ \mathbf{m}_{N}^{\mathrm{T}} \mathbf{m}_{N}+\operatorname{Tr}\left(\mathbf{S}_{N}\right)
\end{aligned}
$$

を用いた。

----

$$
\begin{aligned} \mathbb{E}_{\alpha}[\ln p(\alpha)] &=\mathbb{E}_{\alpha \sim q(\alpha)}\left[\ln \operatorname{Gam}\left(\alpha \mid a_{0}, b_{0}\right)\right] \\
&=\mathbb{E}_{\alpha \sim q(\alpha)}\left[\ln \left\{\frac{1}{\Gamma\left(a_{0}\right)} b_{0}^{a_{0}} \alpha^{a_{0}-1} e^{-b_{0} \alpha}\right\}\right] \\
&=\mathbb{E}_{\alpha \sim q(\alpha)}\left[-\ln \Gamma\left(a_{0}\right)+a_{0} \ln b_{0}+\left(a_{0}-1\right) \ln \alpha-b_{0} \alpha\right] \\
&=a_{0} \ln b_{0}+\left(a_{0}-1\right) \mathbb{E}_{\alpha}[\ln \alpha]-b_{0} \mathbb{E}_{\alpha}[\alpha]-\ln \Gamma\left(a_{0}\right) \\
&=a_{0} \ln b_{0}+\left(a_{0}-1\right)\left(\psi\left(a_{N}\right)-b_{N}\right)-b_{0} \frac{a_{N}}{b_{N}}-\ln \Gamma\left(a_{0}\right) \end{aligned}
$$

----

$$
\begin{aligned}
-\mathbb{E}_{\mathbf{w}}\left[\ln q(\mathbf{w})\right] &=-\mathbb{E}_{\mathbf{w} \sim q(\mathbf{w})}\left[\ln \mathcal{N}\left(\mathbf{w} \mid \mathbf{m}_{N}, \mathbf{S}_{N}\right)\right] \\
&=-\mathbb{E}_{\mathbf{w} \sim q(\mathbf{w})}\left[\ln \left\{\left(\frac{1}{2 \pi}\right)^{\frac{M}{2}} \frac{1}{\left|\mathbf{S}_{N}\right|^{\frac{1}{2}}} \exp \left\{-\frac{1}{2}\left(\mathbf{w}-\mathbf{m}_{N}\right)^{\mathrm{T}} \mathbf{S}_{N}^{-1}\left(\mathbf{w}-\mathbf{m}_{N}\right)\right\}\right]\right.\\
&=\frac{M}{2} \ln (2 \pi)+\frac{1}{2} \ln \left|\mathbf{S}_{N}\right|+\frac{1}{2} \operatorname{Tr}\left[\mathbb{E}_{\mathbf{w}}\left[\left(\mathbf{w}-\mathbf{m}_{N}\right)\left(\mathbf{w}-\mathbf{m}_{N}\right)^{\mathrm{T}}\right] \mathbf{S}_{N}^{-1}\right] \\
&=\frac{M}{2} \ln (2 \pi)+\frac{1}{2} \ln \left|\mathbf{S}_{N}\right|+\frac{1}{2} \operatorname{Tr}\left[\operatorname{cov}[\mathbf{w}] \mathbf{S}_{N}^{-1}\right] \\
&=\frac{M}{2} \ln (2 \pi)+\frac{1}{2} \ln \left|\mathbf{S}_{N}\right|+\frac{1}{2} M \\
&=\frac{1}{2} \ln \left|\mathbf{S}_{N}\right|+\frac{M}{2}[1+\ln (2 \pi)]
\end{aligned}
$$

----

$$
\begin{aligned}-\mathbb{E}_{\alpha}[\ln q(\alpha)] &=-\mathbb{E}_{\alpha \sim q(\alpha)}\left[\ln \operatorname{Gam}\left(\alpha \mid a_{N}, b_{N}\right)\right] \\
&=-\mathbb{E}_{\alpha \sim q(\alpha)}\left[-\ln \Gamma\left(a_{N}\right)+a_{N} \ln b_{N}+\left(a_{N}-1\right) \ln \alpha-b_{N} \alpha\right] \\
&=\ln \Gamma\left(a_{N}\right)-a_{N} \ln b_{N}-(a_N - 1)\mathbb{E}_{\alpha \sim q(\alpha)}[\ln \alpha]+b_{N} \mathbb{E}_{\alpha \sim q(\alpha)}[\alpha] \\
&=\ln \Gamma\left(a_{N}\right)-a_{N} \ln b_{N}-\left(a_{N}-1\right)\left(\psi\left(a_{N}\right)-\ln b_{N}\right)+b_{N} \frac{a_{N}}{b_{N}} \\
&=\ln \Gamma\left(a_{N}\right)-\left(a_{N}-1\right) \psi\left(a_{N}\right)-\ln b_{N}+a_{N} \end{aligned}
$$

## 演習 10.28

<div class="panel-primary">

10.2節で導入したベイズ混合ガウスモデルを10.4節で議論した指数分布族とその共役事前分布のモデルとして書き換えよ．すなわち，一般的な結果
$$\begin{aligned} \ln q^{\star}(\mathbf{Z}) &=\mathbb{E}_{\eta}[\ln p(\mathbf{X}, \mathbf{Z} \mid \eta)]+\text { const } \\ &=\sum_{n=1}^{N}\left\{\ln h\left(\mathbf{x}_{n}, \mathbf{z}_{n}\right)+\mathbb{E}\left[\boldsymbol{\eta}^{\mathrm{T}}\right] \mathbf{u}\left(\mathbf{x}_{n}, \mathbf{z}_{n}\right)\right\}+\text { const } \end{aligned} \tag{10.115}$$
$$q^{\star}(\eta)=f\left(\nu_{N}, \boldsymbol{\chi}_{N}\right) g(\eta)^{\nu_{N}} \exp \left\{\nu_{N} \eta^{\mathrm{T}} \boldsymbol{\chi}_{N}\right\} \tag{10.119}$$
を用いて，特定の場合の結果
$$q^{\star}(\mathbf{Z})=\prod_{n=1}^{N} \prod_{k=1}^{K} r_{n k}^{z_{n k}} \tag{10.48}$$
$$q^{\star}(\boldsymbol{\pi})=\operatorname{Dir}(\boldsymbol{\pi} \mid \boldsymbol{\alpha}) \tag{10.57}$$
$$q^{\star}\left(\boldsymbol{\mu}_{k}, \mathbf{\Lambda}_{k}\right)=\mathcal{N}\left(\boldsymbol{\mu}_{k} \mid \mathbf{m}_{k},\left(\beta_{k} \mathbf{\Lambda}_{k}\right)^{-1}\right) \mathcal{W}\left(\mathbf{\Lambda}_{k} \mid \mathbf{W}_{k}, \nu_{k}\right) \tag{10.59}$$
を導け．

</div>

ベイズ混合ガウス分布における、指数型分布族のそれぞれの関数形を導出して、一般的な結果(10.115),(10.119)に代入していく。

１変数ガウス分布と、指数型分布族の標準形との対応関係は、演習2.57により(2.220)〜(2.223)のとおり導出済み。
多変数ガウス分布（混合分布ではない）との対応関係は、これを拡張して、$p(\mathbf{x}|\boldsymbol{\eta})=h(\mathbf{x})g(\boldsymbol{\eta})\exp [\boldsymbol{\eta}^T \mathbf{u}(\mathbf{x})]$において、

$$
\begin{aligned}
\boldsymbol{\eta}
:=\left[\begin{array}{c}
\boldsymbol{\eta}_1 \\
\boldsymbol{\eta}_2
\end{array}\right]
&\leftrightarrow
\left[\begin{array}{c}
\Lambda \boldsymbol{\mu} \\
-\frac{1}{2}\vec{\Lambda}
\end{array}\right] \\
\mathbf{u}(\mathbf{x}) &\leftrightarrow \left[\begin{array}{c}
\mathbf{x} \\
\mathbf{x}\mathbf{x}^T
\end{array}\right] \\
h(\mathbf{x})&\leftrightarrow \frac{1}{(2\pi)^{D/2}}\\
g(\boldsymbol{\eta})&\leftrightarrow |-2\boldsymbol\eta _2|^{1/2} \exp \left( \frac{1}{4}\boldsymbol{\eta}_1^T \boldsymbol\eta _2 ^{-1}\boldsymbol\eta _1\right)
\end{aligned}
$$

と書ける。ただし、行列の上に矢印（$\rightarrow$）が書かれているのは、行列の各要素を並べた$D \times D$次元のベクトルを意味する。後の式変形の都合で、$g(\boldsymbol{\eta})$の要素を$\boldsymbol{\eta}$と$\mathbf{u}(\mathbf{x})$に押し込めて、

$$
\begin{aligned}
\boldsymbol{\eta}
&\leftrightarrow
\left[\begin{array}{c}
\Lambda \boldsymbol{\mu} \\
-\frac{1}{2}\vec{\Lambda}\\
\boldsymbol{\mu}^T \boldsymbol\Lambda \boldsymbol\mu \\
\ln |\boldsymbol{\Lambda} |
\end{array}\right] \\
\mathbf{u}(\mathbf{x}) &\leftrightarrow \left[\begin{array}{c}
\mathbf{x} \\
\mathbf{x}\mathbf{x}^T\\
-\frac{1}{2}\\
\frac{1}{2}
\end{array}\right] \\
h(\mathbf{x})&\leftrightarrow \frac{1}{(2\pi)^{D/2}}\\
g(\boldsymbol{\eta})&\leftrightarrow 1
\end{aligned}
$$

と書き直す。

今考えているベイズ混合ガウスモデル:

$$
\begin{aligned}
p(\mathbf{X}, \mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol\Lambda )
&=p(\mathbf{X}| \mathbf{Z}, \boldsymbol{\mu}, \boldsymbol\Lambda )
p(\mathbf{Z}| \boldsymbol{\pi} )
p(\boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol\Lambda )\\
&=\left(\prod_{n=1}^N \prod_{k=1}^K \pi_k^{z_{nk}}\right)
\left(\prod_{n=1}^N \prod_{k=1}^K \mathcal{N} (\mathbf{x}_n|\boldsymbol\mu _k,\Lambda_k^{-1})^{z_{nk}} \right)
p(\boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol\Lambda )\\
&=\left(\prod_{n=1}^N \prod_{k=1}^K \left\{ \pi_k
\mathcal{N} (\mathbf{x}_n|\boldsymbol\mu _k,\Lambda_k^{-1})\right\}^{z_{nk}} \right)
p(\boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol\Lambda )\\
\end{aligned}
の形に徐々に近づけていく。まずは$\pi_k \mathcal{N} (\mathbf{x}_n|\boldsymbol\mu _k,\Lambda_k^{-1})$を指数型分布族の標準形に対応づけるには、
\begin{aligned}
\boldsymbol{\eta}
&\leftrightarrow
\left[\begin{array}{c}
\Lambda_k \boldsymbol{\mu}_k \\
-\frac{1}{2}\vec\Lambda_k\\
\boldsymbol{\mu}_k^T \boldsymbol\Lambda_k \boldsymbol\mu_k \\
\ln |\boldsymbol{\Lambda}_k|\\
\ln\pi_k
\end{array}\right] \\
\mathbf{u}(\mathbf{x}_n) &\leftrightarrow \left[\begin{array}{c}
\mathbf{x}_n \\
\overrightarrow{\mathbf{x}_n\mathbf{x}_n^T}\\
-\frac{1}{2}\\
\frac{1}{2}\\
1
\end{array}\right] \\
h(\mathbf{x}_n)&\leftrightarrow \frac{1}{(2\pi)^{D/2}}\\
g(\boldsymbol{\eta})&\leftrightarrow 1
\end{aligned}
次に、$\left\{ \pi_k \mathcal{N} (\mathbf{x}_n|\boldsymbol\mu _k,\Lambda_k^{-1})\right\}^{z_{nk}}$を指数型分布族の標準形に対応づけるには、
\begin{aligned}
\boldsymbol{\eta}
&\leftrightarrow
\left[\begin{array}{c}
\Lambda_k \boldsymbol{\mu}_k \\
-\frac{1}{2}\vec\Lambda_k\\
\boldsymbol{\mu}_k^T \boldsymbol\Lambda_k \boldsymbol\mu_k \\
\ln |\boldsymbol{\Lambda}_k|\\
\ln\pi_k
\end{array}\right] \\
\mathbf{u} (\mathbf{x}_n,z_{nk})&\leftrightarrow z_{nk} \left[\begin{array}{c}
\mathbf{x}_n \\
\overrightarrow{\mathbf{x}_n\mathbf{x}_n^T}\\
-\frac{1}{2}\\
\frac{1}{2}\\
1
\end{array}\right] \\
h(\mathbf{x}_n,z_{nk})&\leftrightarrow \left( \frac{1}{(2\pi)^{D/2}} \right)^{z_{nk}}\\
g(\boldsymbol{\eta})&\leftrightarrow 1
\end{aligned}
$$

最後に、$\prod_{k=1}^K \left\{ \pi_k \mathcal{N} (\mathbf{x}_n|\boldsymbol\mu _k,\Lambda_k^{-1})\right\}^{z_{nk}}$を指数型分布族の標準形に対応づけるには、

$$
\begin{aligned}
\boldsymbol{\eta}
&\leftrightarrow
\left[\begin{array}{c}
\Lambda_k \boldsymbol{\mu}_k \\
-\frac{1}{2}\vec\Lambda_k\\
\boldsymbol{\mu}_k^T \boldsymbol\Lambda_k \boldsymbol\mu_k \\
\ln |\boldsymbol{\Lambda}_k|\\
\ln\pi_k
\end{array}\right] _{k=1,\cdots,K}\\
\mathbf{u} (\mathbf{x}_n,\mathbf{z}_{n})&\leftrightarrow
\left[ z_{nk} \left[\begin{array}{c}
\mathbf{x}_n \\
\overrightarrow{\mathbf{x}_n\mathbf{x}_n^T}\\
-\frac{1}{2}\\
\frac{1}{2}\\
1
\end{array}
\right] \right] _{k=1,\cdots,K}\\
h(\mathbf{x}_n,\mathbf{z}_n)&\leftrightarrow \prod_{k=1}^K \left( \frac{1}{(2\pi)^{D/2}} \right)^{z_{nk}}\\
g(\boldsymbol{\eta})&\leftrightarrow 1
\end{aligned}
$$

ここで、$[\ \ \ ]_{k=1,\cdots,K}$とは、$k=1$に対応するベクトル、$k=2$に対応するベクトル$\cdots$と順に並べてできる長いベクトルを表す。

今得られた対応関係を(10.116)式に代入して、

$$
\begin{aligned}
q^\star (\mathbf{z}_n)
&= h(\mathbf{x}_n, \mathbf{z}_n) g(\mathbb{E}[\boldsymbol\eta])\exp \{\mathbb{E} [\boldsymbol{\eta}^T] \mathbf{u}(\mathbf{x}_n , \mathbf{z}_n )\}\\
&= \left\{ \prod_{k=1}^K \left(\frac{1}{(2\pi)^{D/2}}\right)^{z_{nk}}\right\}
\cdot 1 \cdot
\exp \left\{ \sum_{k=1}^K
\left( \mathbb{E}\left[\begin{array}{c}
\Lambda_k \boldsymbol{\mu}_k \\
-\frac{1}{2}\vec\Lambda_k\\
\boldsymbol{\mu}_k^T \boldsymbol\Lambda_k \boldsymbol\mu_k \\
\ln |\boldsymbol{\Lambda}_k|\\
\ln\pi_k
\end{array}\right]
\right)^T \left( z_{nk} \left[\begin{array}{c}
\mathbf{x}_n \\
\overrightarrow{\mathbf{x}_n\mathbf{x}_n^T}\\
-\frac{1}{2}\\
\frac{1}{2}\\
1
\end{array}
\right]
\right)
\right\}\\
&= \left\{ \prod_{k=1}^K \left(\frac{1}{(2\pi)^{D/2}}\right)^{z_{nk}}\right\}
\exp \left\{ \sum_{k=1}^K z_{nk}
\cdot\mathbb{E}_{\boldsymbol\mu_k , \boldsymbol\Lambda_k}\left[
\boldsymbol{\mu}_k^T \Lambda_k
\mathbf{x}_n
-\frac{1}{2}\mathbf{x}_n^T\Lambda_k
\mathbf{x}_n
-\frac{1}{2}
\boldsymbol{\mu}_k^T \boldsymbol\Lambda_k \boldsymbol\mu_k
+\frac{1}{2}
\ln |\boldsymbol{\Lambda}_k|
+\ln\pi_k
\right]
\right\}\\
&= \prod_{k=1}^K \left(\frac{1}{(2\pi)^{D/2}}
\exp \left\{ -\frac{1}{2}
\mathbb{E}_{\boldsymbol\mu_k , \boldsymbol\Lambda_k}\left[
(\mathbf{x}_n-\boldsymbol{\mu}_k)^T \Lambda_k  (\mathbf{x}_n-\boldsymbol{\mu}_k)\right]
+\frac{1}{2}
\mathbb{E}[\ln |\boldsymbol{\Lambda}_k|]
+\mathbb{E}[\ln\pi_k]
\right\}
\right)^{z_{nk}}\\
&= \prod_{k=1}^K \left(
\exp \left\{ - \frac{D}{2}\ln (2\pi)-\frac{1}{2}
\mathbb{E}_{\boldsymbol\mu_k , \boldsymbol\Lambda_k}\left[
(\mathbf{x}_n-\boldsymbol{\mu}_k)^T \Lambda_k  (\mathbf{x}_n-\boldsymbol{\mu}_k)\right]
+\frac{1}{2}
\mathbb{E}[\ln |\boldsymbol{\Lambda}_k|]
+\mathbb{E}[\ln\pi_k]
\right\}
\right)^{z_{nk}}\\
&=\prod_{k=1}^K \rho _{nk}^{z_{nk}}
\end{aligned}
$$

を得る。（最後の式変形は、(10.46)式の$\rho _{nk}$の定義より。）以上より、

$$
\begin{aligned}
q^\star (\mathbf{Z})
&= \prod_{n=1}^{N} q^\star (\mathbf{z}_n)\\
&= \prod_{n=1}^{N}\prod_{k=1}^K \rho _{nk}^{z_{nk}}
\end{aligned}
$$

と(10.48)式を得る。

----

次に、(10.119)式を用いて(10.57)式と(10.59)式を導く。

$$
\begin{aligned}
q^\star (\boldsymbol\eta )
&\propto g(\boldsymbol\eta)^{\nu_N} \exp \left[ \nu _N \boldsymbol \eta^T \boldsymbol{\chi} _N \right]\\
&= 1 \cdot \exp \left[ \boldsymbol\eta^T \left( \nu_0\boldsymbol\chi_0+\sum_{n=1}^N \mathbb{E}_{z_n}[\mathbf{u}(\mathbf{x}_n,\mathbf{z}_n)]\right)\right]\\
&= \exp \left(
\nu_0\boldsymbol\eta^T \boldsymbol\chi_0
+\sum_{n=1}^N\sum_{k=1}^K \mathbb{E}[z_{nk}] \left[\begin{array}{c}
\Lambda_k \boldsymbol{\mu}_k \\
-\frac{1}{2}\vec\Lambda_k\\
\boldsymbol{\mu}_k^T \boldsymbol\Lambda_k \boldsymbol\mu_k \\
\ln |\boldsymbol{\Lambda}_k|\\
\ln\pi_k
\end{array}\right]
^T \left[\begin{array}{c}
\mathbf{x}_n \\
\overrightarrow{\mathbf{x}_n\mathbf{x}_n^T}\\
-\frac{1}{2}\\
\frac{1}{2}\\
1
\end{array}
\right]
\right)\\
&= \exp \left[
\nu_0\boldsymbol\eta^T \boldsymbol\chi_0
+\sum_{n=1}^N\sum_{k=1}^K r_{nk} \left(
\boldsymbol{\mu}_k^T \Lambda_k
\mathbf{x}_n
-\frac{1}{2}\mathbf{x}_n^T\Lambda_k
\mathbf{x}_n
-\frac{1}{2}
\boldsymbol{\mu}_k^T \boldsymbol\Lambda_k \boldsymbol\mu_k
+\frac{1}{2}
\ln |\boldsymbol{\Lambda}_k|
+\ln\pi_k
\right)
\right]\\
&= \exp \left[
\nu_0\boldsymbol\eta^T \boldsymbol\chi_0
+\sum_{n=1}^N\sum_{k=1}^K r_{nk} \left( -\frac{1}{2}
(\mathbf{x}_n-\boldsymbol{\mu}_k)^T \Lambda_k  (\mathbf{x}_n-\boldsymbol{\mu}_k)
+\frac{1}{2}
\ln |\boldsymbol{\Lambda}_k|
+\ln\pi_k
\right)
\right]
\end{aligned}
$$

事前確率分布の項$\exp\left[\nu_0\boldsymbol\eta^T\boldsymbol\chi_0\right]$は、図10.5の事前確率分布

$$
\begin{aligned}
p(\boldsymbol\pi,\boldsymbol\mu,\boldsymbol\Lambda)
&= p(\boldsymbol\pi)p(\boldsymbol\mu|\boldsymbol\Lambda)p(\boldsymbol\Lambda)\\
&\propto \prod_{k=1}^K \pi_k ^{\alpha_0-1}
|\boldsymbol\Lambda_k |^{1/2}\exp \left[-\frac{1}{2}
(\boldsymbol\mu_k-\mathbf{m}_0)^T (\beta_0\boldsymbol\Lambda_k)
(\boldsymbol\mu_k-\mathbf{m}_0)\right]
|\boldsymbol\Lambda_k|^{(\nu_0-D-1)/2}\exp\left(-\frac{1}{2}{\rm Tr}(\mathbf{W}_0^{-1}\boldsymbol\Lambda_k) \right)\\
&=
\exp \left[\sum_{k=1}^K\left\{
 (\alpha_0-1)\ln \pi_k
-\frac{1}{2}
(\boldsymbol\mu_k-\mathbf{m}_0)^T (\beta_0\boldsymbol\Lambda_k)
(\boldsymbol\mu_k-\mathbf{m}_0)
+\frac{\nu_0-D}{2}
\ln
|\boldsymbol\Lambda_k|
-\frac{1}{2}{\rm Tr}(\mathbf{W}_0^{-1}\boldsymbol\Lambda_k) \right\}\right]
\end{aligned}
$$

に一致するように$\nu_0\boldsymbol\chi_0$を選ぶことは可能（指数型分布族の事前共役分布の形を所与とすれば、この事実は証明不要な気もするが、念のため本問の解答の最後で$\nu_0\boldsymbol\chi_0$の具体的な形を構築する）。

$$
\begin{aligned}
q^
\star (\boldsymbol\eta )
\propto &
\exp \left[\sum_{k=1}^K\left\{
 (\alpha_0-1)\ln \pi_k
-\frac{1}{2}
(\boldsymbol\mu_k-\mathbf{m}_0)^T (\beta_0\boldsymbol\Lambda_k)
(\boldsymbol\mu_k-\mathbf{m}_0)
+\frac{\nu_0-D}{2}
\ln
|\boldsymbol\Lambda_k|
-\frac{1}{2}{\rm Tr}(\mathbf{W}_0^{-1}\boldsymbol\Lambda_k) \right\}\right]\\
&\cdot \exp \left[
\sum_{n=1}^N\sum_{k=1}^K r_{nk} \left( -\frac{1}{2}
(\mathbf{x}_n-\boldsymbol{\mu}_k)^T \Lambda_k  (\mathbf{x}_n-\boldsymbol{\mu}_k)
+\frac{1}{2}
\ln |\boldsymbol{\Lambda}_k|
+\ln\pi_k
\right)
\right]
\end{aligned}
$$

この同時確率分布は$\boldsymbol\pi$に依存する項だけ積の形でくくり出せて、

$$
\begin{aligned}
q^\star (\boldsymbol\eta )
&\propto
\exp \left[\sum_{k=1}^K\left\{
 (\alpha_0-1)\ln \pi_k
+\sum_{n=1}^N r_{nk}
\ln\pi_k
\right\}
\right]\\
&=\exp \left[\sum_{k=1}^K\left\{
 (\alpha_0+N_k-1)\ln \pi_k
\right\}
\right]\\
&=\prod_{k=1}^K \pi_k^{\alpha_0+N_k-1}
\end{aligned}
$$
であり、(10.57)式のディリクレ分布が導かれた。

残りの項のうち、$\boldsymbol\mu_k$に依存する項のみをくくり出すと、
$$
\begin{aligned}
q^\star (\boldsymbol\eta )
\propto \ &
\exp \left[
-\frac{1}{2}\left\{ \sum_{k=1}^K \boldsymbol\mu_k^T \left(\beta_0 \boldsymbol\Lambda_k + \sum_{n=1}^N r_{nk}\boldsymbol\Lambda_k\right)\boldsymbol\mu_k
-2\left(\boldsymbol\mu_k^T\beta_0\boldsymbol\Lambda_k \mathbf{m}_0 + \sum_{n=1}^N r_{nk} \boldsymbol\mu_k^T \Lambda_k \mathbf{x}_n
\right)
\right\}
\right]\\
=:\ &\exp \left[
-\frac{1}{2}\left\{ \sum_{k=1}^K \boldsymbol\mu_k^T \left((\beta_0+N_k) \boldsymbol\Lambda_k \right)\boldsymbol\mu_k
-2\boldsymbol\mu_k^T\left(\boldsymbol\Lambda_k (\beta_0 \mathbf{m}_0 + N_{k} \overline{\mathbf{x}_k}
) \right)
\right\}
\right]\\
= \ &|\boldsymbol\Lambda_k|^{1/2} \exp \left[
-\frac{1}{2} \sum_{k=1}^K \left( \boldsymbol\mu_k  - \frac{\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k}}{\beta_0+N_k}\right)^T \left((\beta_0+N_k) \boldsymbol\Lambda_k \right)\left( \boldsymbol\mu_k  - \frac{\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k}}{\beta_0+N_k}\right)
\right]
\\
& \cdot |\boldsymbol\Lambda_k|^{-1/2}\exp \left[ \frac{1}{2} \frac{1}{\beta_0+N_k} (\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k})^T\Lambda_k(\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k})\right]\\
\end{aligned}
$$

１行目は、$\boldsymbol\mu_k$が(10.59)式のガウス分布に従うことを表す。

最後に、その他の項をくくり出すと、
$$
\begin{aligned}
q^\star (\boldsymbol\eta )
\propto &
\exp \left[\sum_{k=1}^K\left\{
-\frac{1}{2}
\mathbf{m}_0^T \beta_0\boldsymbol\Lambda_k
\mathbf{m}_0
+\frac{\nu_0-D}{2}
\ln
|\boldsymbol\Lambda_k|
-\frac{1}{2}{\rm Tr}(\mathbf{W}_0^{-1}\boldsymbol\Lambda_k)
+\sum_{n=1}^N r_{nk} \left( -\frac{1}{2}
\mathbf{x}_n^T \Lambda_k  \mathbf{x}_n
+\frac{1}{2}
\ln |\boldsymbol{\Lambda}_k|
\right)
\right\}
\right]
\\ \cdot & |\boldsymbol\Lambda_k|^{-1/2}\exp \left[ \frac{1}{2} \frac{1}{\beta_0+N_k} (\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k})^T\Lambda_k(\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k})\right]\\
=& \prod_{k=1}^K
|\boldsymbol\Lambda_k|^{\frac{\nu_0+N_k-D-1}{2}}
\exp \left[
-\frac{1}{2}
\left(
\mathbf{m}_0^T \beta_0\boldsymbol\Lambda_k
\mathbf{m}_0
+{\rm Tr}(\mathbf{W}_0^{-1}\boldsymbol\Lambda_k)
+\sum_{n=1}^N r_{nk}
\mathbf{x}_n^T \Lambda_k  \mathbf{x}_n
-\frac{1}{\beta_0+N_k} (\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k})^T\Lambda_k(\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k})
\right)
\right]\\
=& \prod_{k=1}^K
|\boldsymbol\Lambda_k|^{\frac{\nu_0+N_k-D-1}{2}}
\exp \left[
-\frac{1}{2}
\left\{
{\rm Tr} \left( \mathbf{m}_0 \mathbf{m}_0^T \beta_0\boldsymbol\Lambda_k
\right)
+{\rm Tr}\left(\mathbf{W}_0^{-1}\boldsymbol\Lambda_k\right)
+{\rm Tr} \left( \sum_{n=1}^N r_{nk}
\mathbf{x}_n \mathbf{x}_n^T \Lambda_k  \right)
-\frac{1}{\beta_0+N_k} {\rm Tr}\left(
(\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k})
(\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k})^T\Lambda_k
\right)
\right\}
\right]\\
=& \prod_{k=1}^K
|\boldsymbol\Lambda_k|^{\frac{\nu_0+N_k-D-1}{2}}
\exp \left[
-\frac{1}{2}
{\rm Tr}\left\{ \left( \beta_0 \mathbf{m}_0 \mathbf{m}_0^T
+\mathbf{W}_0^{-1} + \sum_{n=1}^N r_{nk}
\mathbf{x}_n \mathbf{x}_n^T -\frac{1}{\beta_0+N_k}
(\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k})
(\beta_0\mathbf{m}_0+N_k\overline{\mathbf{x}_k})^T
\right)\Lambda_k
\right\}
\right]
\\
\end{aligned}
$$
となる。最後の式は、$|\Lambda|^{*}\exp [-\frac{1}{2}$Tr$(*\Lambda)]$という形をしており、(10.59)式のウィシャート分布を得る。（一見すると(10.62)式の形と異なるように見えるが、$\mathbf{S}_k$の定義に戻って計算すると、上式と一致することが示せる。


----

**おまけ：**
${\nu}_0\boldsymbol\chi_0$の具体的な形状は、以下の通り。
$$
\begin{aligned}
{\nu}_0\boldsymbol\chi_0
&=
\left[\begin{array}{c}
\beta_0 \mathbf{m}_0 \\
\beta_0 \overrightarrow{\mathbf{m}_0 \mathbf{m}_0^T}+\overrightarrow{\mathbf{W}_0^{-1}}\\
-\frac{1}{2}\beta_0\\
\frac{\nu_0-D-1}{2}\\
\alpha_0-1
\end{array}\right] _{k=1,\cdots,K}
\end{aligned}
$$
念のため、上の式を再現できることを確認しておく。
$$
\begin{aligned}
{\nu}_0 \boldsymbol{\eta} ^T
\boldsymbol\chi_0
&=
\left[\begin{array}{c}
\Lambda_k \boldsymbol{\mu}_k \\
-\frac{1}{2}\vec\Lambda_k\\
\boldsymbol{\mu}_k^T \boldsymbol\Lambda_k \boldsymbol\mu_k \\
\ln |\boldsymbol{\Lambda}_k|\\
\ln\pi_k
\end{array}\right] _{k=1,\cdots,K}^T
\left[\begin{array}{c}
\beta_0 \mathbf{m}_0 \\
\beta_0 \overrightarrow{\mathbf{m}_0 \mathbf{m}_0^T}+\overrightarrow{\mathbf{W}_0^{-1}}\\
-\frac{1}{2}\beta_0\\
\frac{\nu_0-D-1}{2}\\
\alpha_0-1
\end{array}\right] _{k=1,\cdots,K}\\
&=
\sum_{k=1}^K\left\{
 (\alpha_0-1)\ln \pi_k
-\frac{1}{2}
(\boldsymbol\mu_k-\mathbf{m}_0)^T (\beta_0\boldsymbol\Lambda_k)
(\boldsymbol\mu_k-\mathbf{m}_0)
+\frac{\nu_0-D-1}{2}
\ln
|\boldsymbol\Lambda_k|
-\frac{1}{2}{\rm Tr}(\mathbf{W}_0^{-1}\boldsymbol\Lambda_k) \right\}
\end{aligned}
$$
となる。なお、最後のTr$(\mathbf{W}_0^{-1}\boldsymbol\Lambda_k)$の項への変形にあたって、一般の正方行列$A,B$について

$$
\begin{aligned}
{\rm Tr}[AB]={\rm Tr}\left[\left( \sum_j a_{ij}b_{jk}\right)_{ik} \right]
=\sum_{i, j}a_{ij}b_{ji}
\end{aligned}
$$

が成り立つこと、および$B$が対称行列であれば最右辺が$\sum_{i,j} a_{ij}b_{ij}$に一致することを用いた。

## 演習 10.29

<div class="panel-primary">

二階微分を計算することで，関数$f(x) = \ln (x)$は$0 \lt x \lt \infty$で上に凸であることを示せ．
$$g(\eta)=\min _{x}\{\eta x-f(x)\} \tag{10.133}$$
で定義される双対な関数$g(\eta)$の形を求め，
$$f(x)=\min _{\eta}\{\eta x-g(\eta)\} \tag{10.132}$$
に従って$\eta x - g(\eta)$を$\eta$について最小化すると，実際に関数$\ln(x)$が得られることを確かめよ．

</div>

※P.209のように$f(x)$と$g(\eta)$が双対の働きとなっていることを示す。

$f(x) = \ln(x)$の2階微分は$\displaystyle f''(x) = - \frac{1}{x^{2}}$である。これは$0 \lt x \lt \infty$で$f''(x) < 0$となるので上に凸である。

$(10.133)$式に代入して

$$
g(\eta)=\min _{x}\{\eta x-\ln(x)\}
$$

最小値を求めるため$x$について微分すると

$$
\frac{dg}{dx} = \eta - \frac{1}{x}
$$

$\displaystyle x=\frac{1}{\eta}$のとき最小となり、このとき$g(\eta) = 1+\ln(\eta)$となる。

今度はこれを$(10.132)$式に代入して$\displaystyle f(x) = \min _{\eta}\{\eta x-1-\ln(\eta)\}$となる。これも同様に$\eta$について微分すると

$$
\frac{df}{d\eta} = x - \frac{1}{\eta}
$$

これは$\displaystyle \eta = \frac{1}{x}$のとき最小となり、このとき

$$
f(x) = 1-\left( 1+\ln\left(\frac{1}{x}\right) \right) = \ln(x)
$$

となり題意通り$\ln(x)$が得られた。

## 演習 10.30

<div class="panel-primary">

二階微分を計算することで，対数ロジスティック関数$f(x)=-\ln \left(1+e^{-x}\right)$が上に凸であることを示せ．対数ロジスティック関数を点$x = \xi$のまわりで一次までテイラー展開することで，変分上界
$$\sigma(x) \leqslant \exp (\eta x-g(\eta)) \tag{10.137}$$
を直接導出せよ．

</div>

後の問題設定のため、対数ロジスティック関数である$f(x)$を

$$
\sigma(x) = \frac{1}{1+e^{-x}} \tag{10.134}
$$

を用いて

$$
f(x)=-\ln \left(1+e^{-x}\right)=\ln \left(\frac{1}{1+e^{-x}}\right)=\ln \sigma(x)
$$

と表しておく。これより

$$
\begin{aligned}
\frac{d \sigma}{d x} &=\frac{e^{-x}}{\left(1+e^{-x}\right)^{2}} = (\sigma(x))^2e^{-x} \\
&=\frac{1}{1+e^{-x}}-\frac{1}{\left(1+e^{-x}\right)^2} \\
&=\sigma(x)-(\sigma(x))^{2} \\
&=\sigma(x)(1-\sigma(x))
\end{aligned}
$$

である。これから$f(x)$が上に凸であること、すなわち$f''(x) \lt 0$を示す。

$$
f^{\prime}(x)=\frac{d}{d x} \ln \sigma(x)=\frac{1}{\sigma(x)} \frac{d}{d x} \sigma(x)=\frac{1}{\sigma(x)}(\sigma(x))^{2} e^{-x}=\sigma(x) e^{-x}
$$

$$
\begin{aligned} f^{\prime \prime}(x) &=\frac{d}{d x}\left(\sigma(x) e^{-x}\right) \\
&=\frac{d}{d x} \sigma(x) \cdot e^{-x}-\sigma(x) e^{-x} \\
&=\{\sigma(x)(1-\sigma(x))-\sigma(x)\} e^{-x} \\
&=-\{\sigma(x)\}^{2} e^{-x} \lt 0 \end{aligned}
$$

これより$f(x)$は上に凸であることが示された。

次に$\ln \sigma(x)$を$x=\xi$の周りで一次のテイラー展開を行うと

$$
\begin{aligned} \ln \sigma(x) &=\ln \sigma(\xi)+\left.\frac{d\ln \sigma(x)}{d x}\right|_{x=\xi}(x-\xi)+O\left(\xi^{2}\right) \\
&\simeq \ln \sigma(\xi)+\sigma(\xi) e^{-\xi}(x-\xi) \end{aligned}
$$

$\ln \sigma(x)$は上に凸（concave）な関数なので、このテイラー展開は

$$
\ln \sigma(x) \leq \ln \sigma(\xi)+\sigma(\xi) e^{-\xi}(x-\xi) \tag{A}
$$

となる。

変分上界を求めるために、10.5節の議論のように（$(10.127)$あたりの変形）$\eta = \sigma(\xi)e^{-\xi}$とおいたときの$\sigma(\xi)$と$\xi$を$\eta$で表すことを目指す。

$$
\begin{aligned} \eta &=\left(1+e^{-\xi}\right)^{-1} e^{-\xi} \\
&=\frac{e^{-\xi}}{1+e^{-\xi}} \\
&=1-\frac{1}{1+e^{-\xi}} \\
&=1-\sigma(\xi) \end{aligned}
$$

これより$\sigma(\xi) = 1 - \eta$となる。また、$\eta = \sigma(\xi)e^{-\xi}$の両辺の対数をとって

$$
\begin{aligned} \ln \eta &=\ln \sigma(\xi)-\xi \\ \xi &=\ln \sigma(\xi)-\ln \eta \\
&=\ln (1-\eta)-\ln \eta \end{aligned}
$$

となる。これらを$(\textrm{A})$に代入して

$$
\begin{aligned} \ln \sigma(x) & \leq \ln (1-\eta)+\eta(x-\ln (1-\eta)+\ln \eta) \\
&=\eta x+(1-n) \ln (1-\eta)+\eta \ln \eta \\
&=\eta x-g(\eta)\hspace{1em}(\because(10.136))
\end{aligned}
$$

これは変分上界

$$
\sigma(x) \leqslant \exp (\eta x-g(\eta)) \tag{10.137}
$$

と等価である。すなわち、題意の通りテイラー展開から直接$(10.137)$式が導出された。
## 演習 10.31

<div class="panel-primary">

$x$について二階微分を求めることで，関数$f(x) = -\ln(e^{x/2}+e^{-x/2})$は$x$の上に凸な関数であることを示せ．次に，変数$x^2$についての二階微分を考え，これが$x^2$については下に凸な関数で、あることを示せ．$f(x)$のグラフを$x$および$x^2$について描いてみよ．関数$f(x)$を変数$x^2$について$\xi^2$を中心として一次までテイラー展開することにより，ロジスティックシグモイド関数の下界
$$\sigma(x) \geqslant \sigma(\xi) \exp \left\{(x-\xi) / 2-\lambda(\xi)\left(x^{2}-\xi^{2}\right)\right\} \tag{10.144}$$
を直接導出せよ．

</div>

微分を計算する時の係数が煩わしいので、$x/2$を$x$と定義し直す。（証明すべき凸性に影響はない。最後の計算結果で元に戻す。）

+ $x$に関して上に凸であることの証明
$$
\begin{aligned}
f(x) &= -\ln(e^{x}+e^{-x})\\
f'(x) &= -\frac{e^{x}-e^{-x}}{e^x+e^{-x}}\\
f''(x) &= -\frac{(e^{x}+e^{-x})^2-(e^{x}-e^{-x})^2}{(e^{x}+e^{-x})^2}\\
&= -\frac{(2e^x)\cdot (2e^{-x})}{(e^{x}+e^{-x})^2}\\
&= -\frac{4}{(e^{x}+e^{-x})^2} < 0
\end{aligned}
$$

+ $x^2$に関して下に凸であることの証明
$y=x^2$とおく。$f(y)=-\ln (e^{\sqrt{y}}+e^{-\sqrt{y}})$を真面目に$y$で2階微分するのは面倒なので、以下のように解く。
$$
\begin{aligned}
\frac{d}{dy}f(x) &= \frac{dx}{dy}\frac{df(x)}{dx}\\
\frac{d^2}{dy^2}f(x) &= \frac{d}{dy}\left( \frac{dx}{dy} \frac{df(x)}{dx} \right)\\
&= \frac{d^2x}{dy^2}\frac{df(x)}{dx} + \frac{dx}{dy} \frac{d}{dy} \left( \frac{df(x)}{dx} \right)\\
&= \frac{d^2x}{dy^2}\frac{df(x)}{dx} + \left( \frac{dx}{dy} \right)^2 \cdot \frac{d^2 f(x)}{dx^2}\\
\end{aligned}
$$

ここで、

$$
\begin{aligned}
\frac{dx}{dy} &= \left( \frac{dy}{dx} \right)^{-1} = \left( \frac{d}{dx} x^2 \right)^{-1} = (2x)^{-1} = \frac{1}{2x} \\
\frac{d^2x}{dy^2} &= \frac{d}{dy} \left( \frac{dx}{dy} \right) = \frac{d}{dy} \left( \frac{1}{2x} \right)= \frac{dx}{dy}\frac{d}{dx} \left( \frac{1}{2x} \right)
= \frac{1}{2x} \left( -\frac{1}{2x^2}\right) = -\frac{1}{4x^3}\\
\end{aligned}
$$

であるから、

$$
\begin{aligned}
\frac{d^2}{dy^2}f(x) &=  \frac{d^2x}{dy^2}\frac{df(x)}{dx} + \left( \frac{dx}{dy} \right)^2 \cdot \frac{d^2 f(x)}{dx^2}\\
&= \left(-\frac{1}{4x^3} \right)\left(-\frac{e^x-e^{-x}}{e^x+e^{-x}} \right) + \left( \frac{1}{2x}\right)^2 \left( - \frac{4}{(e^x+e^{-x})^2}\right)\\
&=\frac{(e^x-e^{-x})(e^x+e^{-x})-4x}{4x^3 (e^x+e^{-x})^2}\\
&=\frac{e^{2x}-e^{-2x}-4x}{4x^3 (e^x+e^{-x})^2}
\end{aligned}
$$
ここで、分子が$x>0$のとき正、$x<0$のとき負であることは、微分して普通に示しても良いが、

$$
\begin{aligned}
e^{2x} &= 1+(2x)+ \frac{1}{2!}(2x)^2+\frac{1}{3!}(2x)^3+\frac{1}{4!}(2x)^4 +\frac{1}{5!}(2x)^5 +\cdots\\
e^{-2x} &= 1-(2x)+ \frac{1}{2!}(2x)^2-\frac{1}{3!}(2x)^3+\frac{1}{4!}(2x)^4 -\frac{1}{5!}(2x)^5 +\cdots\\
e^{2x}-e^{-2x} &= 4x+ 2\cdot \left( \frac{1}{3!}(2x)^3+\frac{1}{5!}(2x)^5\cdots \right)\\
\end{aligned}
$$
に注目すれば明らか。よって、右辺全体は$x>0$でも$x<0$でも正なので、$\frac{d^2}{dy^2}f(x)>0$と言える。

+ グラフを書いてみよ
$f(x)$のグラフを$x$について描く
![](https://i.imgur.com/K697SEc.jpg)
$f(x)$のグラフを$x^2$について描く
![](https://i.imgur.com/Kg2aNfs.jpg)


+ 下界(10.44)を直接導出する（$x$の定義は元に戻す）
$$
\begin{aligned}
f(x)&=f(x)|_{x=\xi} + (x^2-\xi^2) \left( \left. \frac{df(x)}{dy} \right|_{x=\xi} \right)+ \cdots\\
&\geq f(x)|_{x=\xi} + (x^2-\xi^2) \left(\left. \frac{df(x)}{dy} \right|_{x=\xi}\right)\\
&= f(\xi) + (x^2-\xi^2)\left( \frac{dx}{dy} \left.\frac{f(x)}{dx}\right|_{x=\xi}\right)\\
&= f(\xi) + (x^2-\xi^2)\left( -\frac{1}{4\xi} \tanh(\xi) \right)\\
&\equiv f(\xi) - \lambda(\xi) (x^2-\xi^2)\\
\end{aligned}
$$

となる（不等号は、$x^2$に関する凸性より）。従って、

$$
\begin{aligned}
\ln \sigma(x) &= \frac{x}{2} + f(x)\\
&\geq \frac{x}{2} + f(\xi) - \lambda(\xi) (x^2-\xi^2)\\
&= \frac{x-\xi}{2} + \left( \frac{\xi}{2}+f(\xi)\right) - \lambda(\xi) (x^2-\xi^2)\\
&= \frac{x-\xi}{2} + \ln \sigma (\xi) - \lambda(\xi) (x^2-\xi^2)\\
\end{aligned}
$$
両辺のexpをとって、(10.144)式を得る。

## 演習 10.32

<div class="panel-primary">

ロジスティック回帰の変分ベイズ推定を時系列に従って学習し，データ点が一回に一つだけ到着し，次のデータ点が到着するまでに処理して廃棄しなければならない場合について考える．このとき，事後分布のガウス近似は下界
$$p(t \mid \mathbf{w})=e^{a t} \sigma(-a) \geqslant e^{a t} \sigma(\xi) \exp \left\{-(a+\xi) / 2-\lambda(\xi)\left(a^{2}-\xi^{2}\right)\right\} \tag{10.151}$$
を用いることで常に保持できることを示せ．この場合，分布は事前分布で初期化され，データ点が取り込まれるごとに。対応する変分パラメータ$\xi_n$が最適化される．

</div>

※(方針)
(10.151)式を利用しガウス変分事後分布の逐次的な更新式が得られることを確認する

データN個のときの変分事後分布を

$$
q_N(\mathbf{w})=\mathcal{N}(\mathbf{w}\mid\mathbf{m}_N,\mathbf{S}_N^{-1})
$$

とする．N+1個めのデータが与えられたとき(10.151)より

$$
p(t_{N+1}|,\mathbf{w})=e^{\mathbf{w}^{\top} \phi_{N+1} t_{N+1}} \sigma\left(-\mathbf{w}^{\top} \phi_{N+1}\right) \geq e^{\mathbf{w}^{\top} \phi_{N+1} t_{N+1}} \sigma\left(\xi_{N+1}\right) \exp \left[-\left(\mathbf{w}^{\top} \phi_{N+1}+\xi_{N+1}\right) / 2-\lambda\left(\xi_{N+1}\right)\left\{\left(\mathbf{w}^{\top} \phi_{N+1}\right)^{2}-\xi_{N+1}^{2}\right\}\right].
$$

この式から

$$
p(t_{N+1},\mathbf{w})=p(t_{N+1}\mid\mathbf{w})p(\mathbf{w})\geq p(\mathbf{w})e^{\mathbf{w}^{\top} \phi_{N+1} t_{N+1}} \sigma\left(\xi_{N+1}\right) \exp \left[-\left(\mathbf{w}^{\top} \phi_{N+1}+\xi_{N+1}\right) / 2-\lambda\left(\xi_{N+1}\right)\left\{\left(\mathbf{w}^{\top} \phi_{N+1}\right)^{2}-\xi_{N+1}^{2}\right\}\right].
$$

を得る両辺の対数をとって

$$
\begin{aligned}
\ln p(t_{N+1}\mid\mathbf{w})p(\mathbf{w})&\geq\ln p(\mathbf{w})+\mathbf{w}^{\top} \phi_{N+1} t_{N+1}+\ln \sigma\left(\xi_{N+1}\right)-\left(\mathbf{w}^{\top} \phi_{N+1}+\xi_{N+1}\right) / 2-\lambda\left(\xi_{N+1}\right)\left\{\left(\mathbf{w}^{\top} \phi_{N+1}\right)^{2}-\xi_{N+1}^{2}\right\}\\
&\simeq -\frac{1}{2}(\mathbf{w}-\mathbf{m}_N)^{\top}\mathbf{S}_N^{-1}(\mathbf{w}-\mathbf{m}_N)+\mathbf{w}^{\top} \phi_{N+1}\left(t_{N+1}-\frac{1}{2}\right)-\lambda\left(\xi_{N+1}\right) \mathbf{w}^{\top} \phi_{N+1} \phi_{N+1}^{\top} \mathbf{w}+Const
\end{aligned}
$$

これは$\mathbf{w}$の二次形式になっているため，N+1個目のデータが与えられたときの変分事後分布を$q_{N+1}(\mathbf{w})$とするとガウス分布になり，平方完成することで

$$
q_{N+1}(\mathbf{w})=\mathcal{N}(\mathbf{w}\mid\mathbf{m}_{N+1},\mathbf{S}_{N+1}^{-1})
$$

$$
\mathbf{m}_{N+1}＝\mathbf{S}_{N+1}\left[\mathbf{S}_{N}^{-1} \mathbf{m}_{N}+\left(t_{N+1}-1 / 2\right) \boldsymbol{\phi}_{N+1}\right]
$$

$$
\mathbf{S}_{N+1}^{-1}＝2 \lambda\left(\xi_{N+1}\right) \boldsymbol{\phi}_{N+1} \boldsymbol{\phi}_{N+1}^{T}+\mathbf{S}_{N}^{-1}
$$

が得られる．

## 演習 10.33

<div class="panel-primary">

$$Q\left(\boldsymbol{\xi}, \boldsymbol{\xi}^{\text {old }}\right)=\sum_{n=1}^{N}\left\{\ln \sigma\left(\xi_{n}\right)-\xi_{n} / 2-\lambda\left(\xi_{n}\right)\left(\boldsymbol{\phi}_{n}^{\mathrm{T}} \mathbb{E}\left[\mathbf{w} \mathbf{w}^{\mathrm{T}}\right] \boldsymbol{\phi}_{n}-\xi_{n}^{2}\right)\right\}+\mathrm{const} . \tag{10.161}$$
で定義した量$Q\left(\boldsymbol{\xi}, \boldsymbol{\xi}^{\text {old }}\right)$を変分パラメータ$\xi_n$について微分することで，
$$\left(\xi_{n}^{\text {new }}\right)^{2}=\boldsymbol{\phi}_{n}^{\mathrm{T}} \mathbb{E}\left[\mathbf{w} \mathbf{w}^{\mathrm{T}}\right] \boldsymbol{\phi}_{n}=\boldsymbol{\phi}_{n}^{\mathrm{T}}\left(\mathbf{S}_{N}+\mathbf{m}_{N} \mathbf{m}_{N}^{\mathrm{T}}\right) \boldsymbol{\phi}_{n} \tag{10.163}$$
で与えられるベイズロジスティック回帰モデルの$\xi_n$の更新式を示せ．

</div>

### Preparation

- $\sigma(x)$の微分
$$
\begin{aligned}
\frac{\partial \sigma(x)}{\partial x} &= \frac{e^{-x}}{(1 + e^{-x})^2} \\
&= \sigma(x)(1 - \sigma(x)) \notag
\end{aligned}
$$

- $\log(\sigma(x))$の微分
$$
\begin{aligned}
\frac{\partial \log(\sigma(x))}{\partial x} &= (1 + e^{-x})\frac{e^{-x}}{(1 + e^{-x})^2} \\
&= \frac{e^{-x}}{1 + e^{-x}} = 1 - \sigma(x) \notag
\end{aligned}
$$

- $\lambda(\xi)$
$$
\lambda(\xi) = \frac{1}{2\xi}\left[\sigma(\xi) - \frac{1}{2}\right] \tag{10.150}
$$
- 分散の公式

$$
\begin{aligned}
\mathbf{S}_N &= \mathbb{E}[\mathbf{ww}^{\mathrm{T}}] - \mathbb{E}[\mathbf{w}]\mathbb{E}[\mathbf{w}^{\mathrm{T}}] \\
&= \mathbb{E}[\mathbf{ww}^{\mathrm{T}}] - \mathbf{m}_N\mathbf{m}^{\mathrm{T}}_N
\end{aligned}
$$

### Solution

$$
\begin{aligned}
\frac{\partial Q}{\partial \xi_n} &= (1 - \sigma(\xi_n)) - \frac{1}{2} + 2\xi_n\lambda(\xi_n) - \lambda'(\xi_n)(\mathbf{\phi}^{\mathrm{T}}_n\mathbb{E}\left[\mathbf{ww}^{\mathrm{T}}\right]\mathbf{\phi}_n - \xi^2_n) \\
&= -2\xi_n\lambda(\xi_n) + 2\xi_n\lambda(\xi_n) - \lambda'(\xi_n)(\mathbf{\phi}^{\mathrm{T}}_n\mathbb{E}\left[\mathbf{ww}^{\mathrm{T}}\right]\mathbf{\phi}_n - \xi^2_n) \\
&= 0
\end{aligned}
$$
よって、
$$
(\xi^{\mathrm{new}}_n)^2 = \mathbf{\phi}^{\mathrm{T}}_n\mathbb{E}\left[\mathbf{ww}^{\mathrm{T}}\right]\mathbf{\phi}_n = \mathbf{\phi}^{\mathrm{T}}_n\left(\mathbf{S}_N + \mathbf{m}_N\mathbf{m}^{\mathrm{T}}_N\right)\mathbf{\phi}_n
$$

## 演習 10.34

<div class="panel-primary">

この演習問題では，4.5節のベイスロジスティック回帰モデルの変分パラメータ$\boldsymbol{\xi}$の更新式を，
$$\begin{aligned} \mathcal{L}(\boldsymbol{\xi})&= \frac{1}{2} \ln \frac{\left|\mathbf{S}_{N}\right|}{\left|\mathbf{S}_{0}\right|}+\frac{1}{2} \mathbf{m}_{N}^{\mathrm{T}} \mathbf{S}_{N}^{-1} \mathbf{m}_{N}-\frac{1}{2} \mathbf{m}_{0}^{\mathrm{T}} \mathbf{S}_{0}^{-1} \mathbf{m}_{0} \\ &+\sum_{n=1}^{N}\left\{\ln \sigma\left(\xi_{n}\right)-\frac{1}{2} \xi_{n}+\lambda\left(\xi_{n}\right) \xi_{n}^{2}\right\} \end{aligned} \tag{10.164}$$
で与えられる下界を直接最大化することで導出する．これには$\mathcal{L}(\boldsymbol{\xi})$の$\xi_n$に附する微分を0としてみよ．行列式の対数の微分には結果
$$\frac{d}{d \alpha} \ln |\mathbf{A}|=\operatorname{Tr}\left(\mathbf{A}^{-1} \frac{d}{d \alpha} \mathbf{A}\right) \tag{3.117}$$
を，変分事後分布$q(\mathbf{w})$の平均と分散には
$$\mathbf{m}_{N}=\mathbf{S}_{N}\left(\mathbf{S}_{0}^{-1} \mathbf{m}_{0}+\sum_{n=1}^{N}\left(t_{n}-1 / 2\right) \phi_{n}\right) \tag{10.157}$$
$$\mathbf{S}_{N}^{-1}=\mathbf{S}_{0}^{-1}+2 \sum_{n=1}^{N} \lambda\left(\xi_{n}\right) \phi_{n} \phi_{n}^{\mathrm{T}} \tag{10.158}$$
の式を利用せよ．

</div>

### Preparation

- 公式
$$
\frac{\partial}{\partial x}(\mathbf{A}^{-1}) = -\mathbf{A}^{-1}\frac{\partial\mathbf{A}}{\partial x}\mathbf{A}^{-1} \tag{C.21}
$$
- 後で使う式変形
$$
\begin{aligned}
\mathbf{m}^{\mathrm{T}}_N\mathbf{S}^{-1}_{N}\mathbf{m}_N &= [\mathbf{S}_{N}\mathbf{S}^{-1}_{N}\mathbf{m}_N]^{\mathrm{T}}\mathbf{S}^{-1}_{N}[\mathbf{S}_{N}\mathbf{S}^{-1}_{N}\mathbf{m}_N] \\
&= [\mathbf{S}_{N}\mathbf{a}_N]^{\mathrm{T}}\mathbf{S}^{-1}_{N}[\mathbf{S}_{N}\mathbf{a}_N] \\
&= \mathbf{a}^{\mathrm{T}}_N\mathbf{S}^{-1}_{N}\mathbf{a}_N.
\end{aligned}
$$

ただし、
$$
\mathbf{a}_N = \mathbf{S}^{-1}_{N}\mathbf{m}_N.
$$

### Solution

$$
\begin{aligned}
\frac{\partial \mathcal{L}(\mathbf{\xi})}{\partial \xi_n} &= \frac{1}{2}\mathrm{Tr}\left(\mathbf{S}^{-1}_{N}\frac{\partial \mathbf{S}_{N}}{\partial \xi_n}\right) + \frac{1}{2} \mathrm{Tr}\left(\mathbf{a}_N\mathbf{a}^{\mathrm{T}}_N \frac{\partial \mathbf{S}_{N}}{\partial \xi_n}\right) + \lambda'(\xi_n)\xi^2_n \\
&= \frac{1}{2}\mathrm{Tr}\left((\mathbf{S}^{-1}_{N} + \mathbf{a}_N\mathbf{a}^{\mathrm{T}}_N)\frac{\partial \mathbf{S}_{N}}{\partial \xi_n}\right) + \lambda'(\xi_n)\xi^2_n \\
&= -\frac{1}{2}\mathrm{Tr}\left((\mathbf{S}^{-1}_{N} + \mathbf{a}_N\mathbf{a}^{\mathrm{T}}_N)\mathbf{S}_N[2\lambda'(\xi_n)\mathbf{\phi}_N\mathbf{\phi}^{\mathrm{T}}_N]\mathbf{S}_N\right) + \lambda'(\xi_n)\xi^2_n \\
&= -\lambda'(\xi_n)\left\{\mathrm{Tr}\left((\mathbf{S}^{-1}_{N} + \mathbf{a}_N\mathbf{a}^{\mathrm{T}}_N)\mathbf{S}_N\mathbf{\phi}_N\mathbf{\phi}^{\mathrm{T}}_N\mathbf{S}_N\right) - \xi^2_n\right\} \\
&= 0.
\end{aligned}
$$

よって、

$$
\begin{aligned}
\xi^2_n &= \mathrm{Tr}\left((\mathbf{S}^{-1}_{N} + \mathbf{a}_N\mathbf{a}^{\mathrm{T}}_N)\mathbf{S}_N\mathbf{\phi}_N\mathbf{\phi}^{\mathrm{T}}_N\mathbf{S}_N\right) \\
&= (\mathbf{S}_N\mathbf{\phi}_n)^{\mathrm{T}}(\mathbf{S}^{-1}_{N} + \mathbf{a}_N\mathbf{a}^{\mathrm{T}}_N)(\mathbf{S}_N\mathbf{\phi}_n) \\
&= \mathbf{\phi}^{\mathrm{T}}_n(\mathbf{S}_N + \mathbf{S}_N\mathbf{a}_N\mathbf{a}^{\mathrm{T}}_N\mathbf{S}_N)\mathbf{\phi}_n \\
&= \mathbf{\phi}^{\mathrm{T}}_n(\mathbf{S}_N + \mathbf{m}_N\mathbf{m}^{\mathrm{T}}_N)\mathbf{\phi}_n
\end{aligned}
$$

## 演習 10.35

<div class="panel-primary">

変分ベイズロジスティック回帰モデルの下界$\mathcal{L}(\boldsymbol{\xi})$についての結果
$$\begin{aligned} \mathcal{L}(\boldsymbol{\xi})&= \frac{1}{2} \ln \frac{\left|\mathbf{S}_{N}\right|}{\left|\mathbf{S}_{0}\right|}+\frac{1}{2} \mathbf{m}_{N}^{\mathrm{T}} \mathbf{S}_{N}^{-1} \mathbf{m}_{N}-\frac{1}{2} \mathbf{m}_{0}^{\mathrm{T}} \mathbf{S}_{0}^{-1} \mathbf{m}_{0} \\ &+\sum_{n=1}^{N}\left\{\ln \sigma\left(\xi_{n}\right)-\frac{1}{2} \xi_{n}+\lambda\left(\xi_{n}\right) \xi_{n}^{2}\right\} \end{aligned} \tag{10.164}$$
を導出せよ．これには$\mathcal{L}(\boldsymbol{\xi})$を定める積分
$$\ln p(\mathbf{t})=\ln \int p(\mathbf{t} \mid \mathbf{w}) p(\mathbf{w}) \mathrm{d} \mathbf{w} \geqslant \ln \int h(\mathbf{w}, \boldsymbol{\xi}) p(\mathbf{w}) \mathrm{d} \mathbf{w}=\mathcal{L}(\boldsymbol{\xi}) \tag{10.159}$$
の中で，ガウス事前分布の式に$q(\mathbf{w}) = \mathcal{N}(\mathbf{w}\mid \mathbf{m}_0, \mathbf{\Sigma}_0)$を，尤度関数に下界$h(\mathbf{w}, \boldsymbol{\xi})$を代入するのが最も簡単である．次に指数関数の中で$\mathbf{w}$に依存する項をまとめ，平方完成することでガウス分布の積分を導出せよ．多次元ガウス分布の正規化項についての標準的な結果を使ってこれを計算し，最後に対数をとって$(10.164)$を求めよ．

</div>

- $h(\mathbf{w}, \xi)p(\mathbf{w})$を計算する
$$
\begin{aligned}
h(\mathbf{w}, \xi)p(\mathbf{w}) &= \mathrm{N}(\mathbf{w}|\mathbf{m}_0, \mathbf{S}_0)\prod^N \sigma(\xi_n)\exp\{\mathbf{w}^{\mathrm{T}}\mathbf{\phi}_nt_n - (\mathbf{w}^{\mathrm{T}}\mathbf{\phi}_n + \xi_n)/2 - \lambda(\xi_n)([\mathbf{w}^{\mathrm{T}}\mathbf{\phi}]^2 - \xi^2_n)\} \\
&= \{(2\pi)^{-W/2} \cdot |\mathbf{S}_0|^{-1/2} \cdot \prod^N \sigma(\xi_n)\} \cdot \exp\{-\frac{1}{2}(\mathbf{w} - \mathbf{m}_0)^{\mathrm{T}}\mathbf{S}^{-1}_0(\mathbf{w} - \mathbf{m}_0)\} \\
& \ \ \ \cdot \prod^N \exp\{\mathbf{w}^{\mathrm{T}}\mathbf{\phi}_nt_n - (\mathbf{w}^{\mathrm{T}}\mathbf{\phi}_n + \xi_n)/2 - \lambda(\xi_n)([\mathbf{w}^{\mathrm{T}}\mathbf{\phi}]^2 - \xi^2_n)\} \\
&= \left\{(2\pi)^{-W/2} \cdot |\mathbf{S}_0|^{-1/2} \cdot \prod^N \sigma(\xi_n) \cdot \exp\left(-\frac{1}{2}\mathbf{m}^{\mathrm{T}}_0\mathbf{S}^{-1}_0\mathbf{m}_0 - \sum^N \frac{\xi_n}{2} + \sum^N \lambda(\xi_n)\xi^2_n\right)\right\} \\
& \ \ \ \cdot \exp\left\{-\frac{1}{2}\mathbf{w}^{\mathrm{T}}\left(\mathbf{S}^{-1}_0 + 2\sum^N\lambda(\xi_n)\mathbf{\phi}_n\mathbf{\phi}^{\mathrm{T}}_n\right)\mathbf{w} + \mathbf{w}^{\mathrm{T}}\left(\mathbf{S}^{-1}_0\mathbf{m}_0 + \sum^N \mathbf{\phi}_n\left(t_n - \frac{1}{2}\right)\right) \right\} \\
&= \left\{(2\pi)^{-W/2} \cdot |\mathbf{S}_0|^{-1/2} \cdot \prod^N \sigma(\xi_n) \cdot \exp\left(-\frac{1}{2}\mathbf{m}^{\mathrm{T}}_0\mathbf{S}^{-1}_0\mathbf{m}_0 - \sum^N \frac{\xi_n}{2} + \sum^N \lambda(\xi_n)\xi^2_n\right)\right\} \\
& \ \ \ \cdot \exp\left\{\frac{1}{2}\mathbf{w}^{\mathrm{T}}\mathrm{S}^{-1}_N\mathbf{w} + \mathbf{w}^{\mathrm{T}}\mathrm{S}^{-1}_N\mathbf{m}_N\right\} \ (\because (10.157)-(10.158)) \\
&= \left\{(2\pi)^{-W/2} \cdot |\mathbf{S}_0|^{-1/2} \cdot \prod^N \sigma(\xi_n) \cdot \exp\left(-\frac{1}{2}\mathbf{m}^{\mathrm{T}}_0\mathbf{S}^{-1}_0\mathbf{m}_0 - \sum^N \frac{\xi_n}{2} + \sum^N \lambda(\xi_n)\xi^2_n\right) + \frac{1}{2}\mathbf{m}^{\mathrm{T}}_N\mathbf{S}^{-1}_N\mathbf{m}_N\right\} \\
& \ \ \ \cdot \exp\left\{-\frac{1}{2}(\mathbf{w} - \mathbf{m}_N)^{\mathrm{T}}\mathrm{S}^{-1}_N(\mathbf{w} - \mathbf{m}_N)\right\}
\end{aligned}
$$

- $\mathbf{w}$で積分する
$$
\begin{aligned}
\int h(\mathbf{w}, \xi)p(\mathbf{w})d\mathbf{w} &= (2\pi)^{-W/2} \cdot |\mathbf{S}_0|^{-1/2} \\
& \ \ \ \cdot \prod^N \sigma(\xi_n) \cdot \exp\left(-\frac{1}{2}\mathbf{m}^{\mathrm{T}}_0\mathbf{S}^{-1}_0\mathbf{m}_0 - \sum^N \frac{\xi_n}{2} + \sum^N \lambda(\xi_n)\xi^2_n\right) + \frac{1}{2}\mathbf{m}^{\mathrm{T}}_N\mathbf{S}^{-1}_N\mathbf{m}_N \\
& \ \ \ \cdot (2\pi)^{W/2} \cdot |\mathbf{S}_N|^{1/2} \\
&= \left(\frac{|\mathbf{S}_N|}{|\mathbf{S}_0|}\right)^{1/2} \prod^N \sigma(\xi_n) \cdot \exp\left(-\frac{1}{2}\mathbf{m}^{\mathrm{T}}_0\mathbf{S}^{-1}_0\mathbf{m}_0 - \sum^N \frac{\xi_n}{2} + \sum^N \lambda(\xi_n)\xi^2_n\right) + \frac{1}{2}\mathbf{m}^{\mathrm{T}}_N\mathbf{S}^{-1}_N\mathbf{m}_N
\end{aligned}
$$

- 対数をとる

$$
\mathcal{L}(\xi) = \frac{1}{2}\log\frac{|\mathbf{S}_N|}{|\mathbf{S}_0|} - \frac{1}{2}\mathbf{m}^{\mathrm{T}}_0\mathbf{S}^{-1}_0\mathbf{m}_0 + \frac{1}{2} \mathbf{m}^{\mathrm{T}}_N\mathbf{S}^{-1}_N\mathbf{m}_N + \sum^N \left\{\log\sigma(\xi_n) - \frac{\xi_n}{2} + \lambda(\xi_n)\xi^2_n \right\}
$$


## 演習 10.36

<div class="panel-primary">

10.7節で議論したADFの近似法を考える．このとき.因子$f_j(\boldsymbol{\theta})$を含めることで，モデルエビデンスを

$$p_{j}(\mathcal{D}) \simeq p_{j-1}(\mathcal{D}) Z_{j} \tag{10.242}$$

のように更新できることを示せ．ここで$Z_j$は正規化定数であり
$$Z_{j}=\int f_{j}(\theta) q^{\backslash j}(\boldsymbol{\theta}) \mathrm{d} \boldsymbol{\theta} \tag{10.197}$$
で与えられる$p_0({\mathcal{D}} ) = 1$と初期化して上の結果を再帰的に適用することで，

$$p(\mathcal{D}) \simeq \prod_{j} Z_{j} \tag{10.243}$$

を導け．

</div>

※

## 演習 10.37

<div class="panel-primary">

10.7節のEP法のアルゴリスムについて考え，定義
$$p(\mathcal{D}, \theta)=\prod_{i} f_{i}(\boldsymbol{\theta}) \tag{10.188}$$
における因子の一つ$f_0(\boldsymbol{\theta})$が，近似分布$q(\boldsymbol{\theta})$と同じ形の指数分布族になっていると仮定する．このとき因子$\tilde{f}_0(\boldsymbol{\theta})$を$f_0(\boldsymbol{\theta})$で初期化すれば，EP法での$\tilde{f}_0(\boldsymbol{\theta})$の更新は$\tilde{f}_0(\boldsymbol{\theta})$を変えないことを示せ．典型的には，これは因子の一つが事前分布$p(\boldsymbol{\theta})$の場合に起こり，事前分布に対応する因子は一度だけ厳密な形で取り込まれ，以降は更新する必要はないことがわかる．

</div>

$q(\boldsymbol{\theta})$の初期値は
$$
q_{\mathrm{init}}(\boldsymbol{\theta}) = \tilde{f_0}(\boldsymbol{\theta})\prod_{i \neq 0}\tilde{f_i}(\boldsymbol{\theta})
$$
と表される。ここで、
$$
q^{\setminus 0}(\boldsymbol{\theta}) = \prod_{i \neq 0}\tilde{f_i}(\boldsymbol{\theta}).
$$
$q^{new}(\boldsymbol{\theta})$は、モーメント一致法を用いて、
$$
q^{new}(\boldsymbol{\theta}) = q^{\setminus 0}(\boldsymbol{\theta})f_0(\boldsymbol{\theta}).
$$
問題の設定より、$\tilde{f_0}(\boldsymbol{\theta})$の初期値は$f_0(\boldsymbol{\theta})$なので、
$$
q^{new}(\boldsymbol{\theta}) = q_{\mathrm{init}}(\boldsymbol{\theta}).
$$
また、
$$
Z_0 = \int q^{\setminus 0}(\boldsymbol{\theta})f_0(\boldsymbol{\theta})d\boldsymbol{\theta} = \int q_{\mathrm{init}}(\boldsymbol{\theta})d\boldsymbol{\theta} = 1.
$$
従って、(10.207)の更新式は、
$$
\tilde{f_0}(\boldsymbol{\theta}) = Z_0\frac{q^{new}(\boldsymbol{\theta})}{q^{\setminus 0}(\boldsymbol{\theta})} = f_0(\boldsymbol{\theta})
$$
となる。



## 演習 10.38

<div class="panel-primary">

この演習問題と次の演習問題では，雑音データ問題でのEP法の結果$(10.214)-(10.224)$を確かめる．除算を行う公式
$$q^{\backslash j}(\boldsymbol{\theta})=\frac{q(\boldsymbol{\theta})}{\widetilde{f}_{j}(\boldsymbol{\theta})} \tag{10.205}$$
から始めて，
$$\mathbf{m}^{\backslash n}=\mathbf{m}+v^{\backslash n} v_{n}^{-1}\left(\mathbf{m}-\mathbf{m}_{n}\right) \tag{10.214}$$
$$\left(v^{\backslash n}\right)^{-1}=v^{-1}-v_{n}^{-1}\tag{10.215}$$
を，指数関数の中を平方完成して平均と分散を見出すことで導け．また
$$Z_{j}=\int q^{\backslash j}(\boldsymbol{\theta}) f_{j}(\boldsymbol{\theta}) \mathrm{d} \boldsymbol{\theta} \tag{10.206}$$
で定義される正規化定数$Z_n$は，雑音データ問題については
$$Z_{n}=(1-w) \mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{m}^{\backslash n},\left(v^{\backslash n}+1\right) \mathbf{I}\right)+w \mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{0}, a \mathbf{I}\right) \tag{10.216}$$
で与えられることを示せ．これには一般的な結果
$$p(\mathbf{y})=\mathcal{N}\left(\mathbf{y} \mid \mathbf{A} \boldsymbol{\mu}+\mathbf{b}, \mathbf{L}^{-1}+\mathbf{A} \mathbf{\Lambda}^{-1} \mathbf{A}^{\mathrm{T}}\right) \tag{2.115}$$
を利用すればよい．

</div>

(10.205)、(10.212)、(10.213)式より、
$$
\begin{aligned}
q^{\setminus j}(\boldsymbol{\theta}) &= \frac{q(\boldsymbol{\theta})}{\tilde{f_j}(\boldsymbol{\theta})} = \frac{\mathcal{N}(\boldsymbol{\theta}|\mathbf{m}, v\mathbf{I})}{s_n \mathcal{N}(\boldsymbol{\theta}|\mathbf{m}_n, v_n\mathbf{I})} \\
&\propto \frac{\exp\left\{-\frac{1}{2}(\boldsymbol{\theta} - \mathrm{m})^{\mathrm{T}}(v\mathbf{I})^{-1}(\boldsymbol{\theta} - \mathrm{m})\right\}}{\exp\left\{-\frac{1}{2}(\boldsymbol{\theta} - \mathrm{m}_n)^{\mathrm{T}}(v_n\mathbf{I})^{-1}(\boldsymbol{\theta} - \mathrm{m}_n)\right\}} \\
&\propto \exp\left\{-\frac{1}{2}(\boldsymbol{\theta} - \mathrm{m})^{\mathrm{T}}(v\mathbf{I})^{-1}(\boldsymbol{\theta} - \mathrm{m}) + \frac{1}{2}(\boldsymbol{\theta} - \mathrm{m}_n)^{\mathrm{T}}(v_n\mathbf{I})^{-1}(\boldsymbol{\theta} - \mathrm{m}_n)\right\} \\
&= \exp\left\{-\frac{1}{2}(\boldsymbol{\theta}^{\mathrm{T}}\mathbf{A}\boldsymbol{\theta} + \boldsymbol{\theta}^{\mathrm{T}}\mathbf{B})\right\} + \mathrm{const}
\end{aligned}
$$
まず、

$$
\begin{aligned}
(\boldsymbol{\Sigma}^{\setminus n})^{-1} &= \mathbf{A} = (v\mathbf{I})^{-1} - (v_n\mathbf{I})^{-1} \\
&= (v^{-1} - v^{-1}_n)\mathbf{I}^{-1}
\end{aligned}
$$
また、
$$
-2(\boldsymbol{\Sigma}^{\setminus n})^{-1}\mathbf{m}^{\setminus n} = \mathbf{B} = 2\left(-(v\mathbf{I})^{-1}\mathbf{m} + (v_n\mathbf{I})^{-1}\mathbf{m}_n\right)
$$
より、
$$
\begin{aligned}
\mathbf{m}^{\setminus n} &= -(\boldsymbol{\Sigma}^{\setminus n})^{-1}\left(-(v\mathbf{I})^{-1}\mathbf{m} + (v_n\mathbf{I})^{-1}\mathbf{m}_n\right) \\
&= -(v^{\setminus n})\left(-v^{-1}\mathbf{m} + (v_n^{-1}\mathbf{m}_n\right) \\
&= v^{\setminus n}v^{-1}\mathbf{m} - \frac{v^{\setminus n}}{v_n}\mathbf{m}_n \\
&= v^{\setminus n}((v^{\setminus n})^{-1} - v^{-1}_n)\mathbf{m} - \frac{v^{\setminus n}}{v_n}\mathbf{m}_n \\
&= \mathbf{m} + \frac{v^{\setminus n}}{v_n}(\mathbf{m} - \mathbf{m}_n)
\end{aligned}
$$
次に、(10.206)、(10.209)式より、
$$
\begin{aligned}
Z_n &= \int q^{\setminus n}(\boldsymbol{\theta})f_n(\boldsymbol{\theta})d\boldsymbol{\theta} \\
&= \int \mathcal{N}(\boldsymbol{\theta}|\mathbf{m}^{\setminus n}, v^{\setminus n}\mathbf{I})\left\{(1 - w)\mathcal{N}(\mathbf{x}_n|\boldsymbol{\theta}, \mathbf{I}) + w\mathcal{N}(\mathbf{x}_n|\mathbf{0}, a\mathbf{I})\right\} \\
&= (1 - w)\int \mathcal{N}(\boldsymbol{\theta}|\mathbf{m}^{\setminus n}, v^{\setminus n}\mathbf{I})\mathcal{N}(\mathbf{x}_n|\boldsymbol{\theta}, \mathbf{I})d\boldsymbol{\theta} + w\int \mathcal{N}(\boldsymbol{\theta}|\mathbf{m}^{\setminus n}, v^{\setminus n}\mathbf{I})\mathcal{N}(\mathbf{x}_n|\mathbf{0}, a\mathbf{I})d\boldsymbol{\theta} \\
&= (1 - w) \mathcal{N}(\mathbf{x}_n|\mathbf{m}^{\setminus n}, (v^{\setminus n} + 1)\mathbf{I}) + w\mathcal{N}(\mathbf{x}_n|\mathbf{0}, a\mathbf{I}). (\because (2.113)-(2.115))
\end{aligned}
$$

## 演習 10.39

<div class="panel-primary">

雑音データ問題でのEP法における$q^{\text {new }}(\boldsymbol{\theta})$の平均と分散は
$$\mathbf{m}^{\text {new }}=\mathbf{m}^{\backslash n}+\rho_{n} \frac{v^{\backslash n}}{v^{\backslash n}+1}\left(\mathbf{x}_{n}-\mathbf{m}^{\backslash n}\right) \tag{10.217}$$
$$v^{\text {new }}=v^{\backslash n}-\rho_{n} \frac{\left(v^{\backslash n}\right)^{2}}{v^{\backslash n}+1}+\rho_{n}\left(1-\rho_{n}\right) \frac{\left(v^{\backslash n}\right)^{2}\left\|\mathbf{x}_{n}-\mathbf{m}^{\backslash n}\right\|^{2}}{D\left(v^{\backslash n}+1\right)^{2}} \tag{10.218}$$
で与えられることを示せ．このためには，最初に$q^{\text {new }}(\boldsymbol{\theta})$の下での$\boldsymbol{\theta}$と$\boldsymbol{\theta}\boldsymbol{\theta}^{\mathrm T}$の期待値が

$$\begin{aligned} \mathbb{E}[\boldsymbol{\theta}] &=\mathbf{m}^{\backslash n}+v^{\backslash n} \nabla_{\mathbf{m} \backslash n} \ln Z_{n} \\ \mathbb{E}\left[\boldsymbol{\theta}^{\mathrm{T}} \boldsymbol{\theta}\right] &=2\left(v^{\backslash n}\right)^{2} \nabla_{v^{\backslash n}} \ln Z_{n}+2 \mathbb{E}[\boldsymbol{\theta}]^{\mathrm{T}} \mathbf{m}^{\backslash n}-\left\|\mathrm{m}^{\backslash n}\right\|^{2}+v^{\backslash n} D \end{aligned}$$

となることを証明し，$Z_n$についての結果
$$Z_{n}=(1-w) \mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{m}^{\backslash n},\left(v^{\backslash n}+1\right) \mathbf{I}\right)+w \mathcal{N}\left(\mathbf{x}_{n} \mid \mathbf{0}, a \mathbf{I}\right) \tag{10.216}$$
を用いる．次に，
$$\widetilde{f}_{j}(\boldsymbol{\theta})=Z_{j} \frac{q^{\text {new }}(\boldsymbol{\theta})}{q \backslash j(\theta)} \tag{10.207}$$
を用いて指数関数の中を平方完成することで$(10.220)-(10.222)$の結果を証明せよ．最後に，$(10.208)$を用いて$(10.223)$の結果を導け．

</div>

### Preparation

- 正規分布の微分

$$
\begin{aligned}
\frac{\partial \mathcal{N}(x|\mu, \sigma^2)}{\partial \mu} &= \mathcal{N}(x|\mu, \sigma^2)\cdot\frac{x - \mu}{\sigma^2} \\
\frac{\partial \mathcal{N}(x|\mu, \sigma^2)}{\partial \sigma^2} &= \mathcal{N}(x|\mu, \sigma^2)\cdot\left(\frac{(x - \mu)^2}{(\sigma^2)^2} - \frac{1}{\sigma^2}\right) \\
\end{aligned}
$$

- $\rho_n$

$$
\begin{aligned}
\rho_n &= \frac{1}{Z_n}(1 - w)\mathcal{N}(\mathbf{x}_n|\mathbf{m}^{\setminus n}, (v^{\setminus n} + 1)\mathbf{I}) \\
&= \frac{1}{Z_n}(1 - w)\frac{Z_n - w\mathcal{N}(\mathbf{x}_n|\mathbf{0}, a\mathbf{I})}{1 - w} \ (\because (10.216)) \\
&= 1 - \frac{w}{Z_n}\mathcal{N}(\mathbf{x}_n|\mathbf{0}, a\mathbf{I}).
\end{aligned}
$$

### Solution
まず、

$$
\begin{aligned}
\nabla_{\mathbf{m}^{\setminus n}} \ln Z_n &= \frac{1}{Z_n}\nabla_{\mathbf{m}^{\setminus n}} \int q^{\setminus n}(\boldsymbol{\theta}) f_n(\boldsymbol{\theta}) d\boldsymbol{\theta} \\
&= \frac{1}{Z_n}\int q^{\setminus n}(\boldsymbol{\theta}) f_n(\boldsymbol{\theta})\left\{-\frac{1}{v^{\setminus n}}(\mathbf{m}^{\setminus n} - \boldsymbol{\theta})\right\} d\boldsymbol{\theta} \\
&= -\frac{\mathbf{m}^{\setminus n}}{v^{\setminus n}} + \frac{\mathbb{E}(\boldsymbol{\theta})}{v^{\setminus n}} \ (\because (10.203)???)
\end{aligned}
$$

上式を整理すると、

$$
\begin{aligned}
\mathbb{E}(\boldsymbol{\theta}) &= \mathbf{m}^{\setminus n} + v^{\setminus n}\nabla_{\mathbf{m}^{\setminus n}} \ln Z_n \\
&= \mathbf{m}^{\setminus n} + v^{\setminus n} \frac{1}{Z_n} (1 - w)\mathcal{N}(\mathbf{x}_n|\mathbf{m}^{\setminus n}, (v^{\setminus n} + 1)\mathbf{I})\cdot\frac{\mathbf{x}_n - \mathbf{m}^{\setminus n}}{v^{\setminus n} + 1} \\
&= \mathbf{m}^{\setminus n} + v^{\setminus n}\rho_n\frac{\mathbf{x}_n - \mathbf{m}^{\setminus n}}{v^{\setminus n} + 1}
\end{aligned}
$$

同様に、

$$
\begin{aligned}
\nabla_{v^{\setminus n}} \ln Z_n &= \frac{1}{Z_n}\nabla_{v^{\setminus n}} \int q^{\setminus n}(\boldsymbol{\theta}) f_n(\boldsymbol{\theta}) d\boldsymbol{\theta} \\
&= \frac{1}{Z_n} \int q^{\setminus n}(\boldsymbol{\theta}) f_n(\boldsymbol{\theta})\left\{\frac{1}{2(v^{\setminus n})^2}(\mathbf{m}^{\setminus n} - \boldsymbol{\theta})^{\mathrm{T}}(\mathbf{m}^{\setminus n} - \boldsymbol{\theta}) - \frac{D}{2v^{\setminus n}}\right\} \\
&= \frac{1}{2(v^{\setminus n})^2}\left\{\mathbb{E}(\boldsymbol{\theta}^{\mathrm{T}}\boldsymbol{\theta}) - 2\mathbb{E}(\boldsymbol{\theta}^{\mathrm{T}})\mathbf{m}^{\setminus n} + \|\mathbf{m}^{\setminus n}\|^2 \right\} - \frac{D}{2v^{\setminus n}}.
\end{aligned}
$$

整理すると、

$$
\mathbb{E}(\boldsymbol{\theta}^{\mathrm{T}}\boldsymbol{\theta}) = 2(v^{\setminus n})^2 \nabla_{v^{\setminus n}} \ln Z_n + 2\mathbb{E}(\boldsymbol{\theta}^{\mathrm{T}})\mathbf{m}^{\setminus n} - \|\mathbf{m}^{\setminus n}\|^2 + Dv^{\setminus n}
$$
となる。また、

$$
\begin{aligned}
\nabla_{v^{\setminus n}} \ln Z_n &= \frac{1}{Z_n} (1 - w)\mathcal{N}(\mathbf{x}_n|\mathbf{m}^{\setminus n}, (v^{\setminus n} + 1)\mathbf{I}) \left(\frac{1}{2(v^{\setminus n} + 1)^2}\|\mathbf{x}_n - \mathbf{m}^{\setminus n}\|^2 - \frac{D}{2(v^{\setminus n} + 1)}\right) \\
&= \rho_n \left(\frac{1}{2(v^{\setminus n} + 1)^2}\|\mathbf{x}_n - \mathbf{m}^{\setminus n}\|^2 - \frac{D}{2(v^{\setminus n} + 1)}\right) \\
\end{aligned}
$$

以上の結果と、
$$
v\mathbf{I} = \mathbb{E}(\boldsymbol{\theta}\boldsymbol{\theta}^{\mathrm{T}}) - \mathbb{E}(\boldsymbol{\theta})\mathbb{E}(\boldsymbol{\theta^{\mathrm{T}}})
$$
を組み合わせることで、(10.218)式を得る。
